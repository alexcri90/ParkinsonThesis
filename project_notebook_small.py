# -*- coding: utf-8 -*-
"""Project_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X6gN4LGz_0WSR-T-6mJlORJrP6mie06V

# Setup
"""

# Cell 1: Install dependencies
# Uncomment and run the following command if dependencies are not already installed.
# %pip install scikit-learn scikit-image SimpleITK nibabel nilearn albumentations seaborn pandas numpy matplotlib tqdm pydicom scipy
# %pip install umap-learn

# Cell 2: Import statements and environment setup
import torch

def configure_gpu():
    """
    Configures GPU settings:
    - Detects CUDA device
    - Enables CUDNN benchmarking for improved performance on NVIDIA 4070Ti
    """
    if torch.cuda.is_available():
        device = torch.device("cuda")
        # Enable CUDNN benchmark for optimized convolution algorithm selection
        torch.backends.cudnn.benchmark = True
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
    else:
        raise EnvironmentError("CUDA-compatible GPU not found. Please check your GPU configuration.")

def print_gpu_memory_stats():
    """
    Prints current GPU memory usage for monitoring.
    """
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024 ** 2)
        reserved = torch.cuda.memory_reserved() / (1024 ** 2)
        print(f"GPU Memory Allocated: {allocated:.2f} MB")
        print(f"GPU Memory Reserved: {reserved:.2f} MB")
    else:
        print("CUDA not available.")

# Configure GPU on startup
configure_gpu()
print_gpu_memory_stats()

import warnings
warnings.filterwarnings('ignore')

# Cell 3: GPU Setup and Memory Management
import os
import logging
import warnings
import pandas as pd

# Configure logging for quality assurance (logs will be written to data_ingestion.log)
logging.basicConfig(level=logging.INFO, filename="data_ingestion.log", filemode="w",
                    format="%(asctime)s - %(levelname)s - %(message)s")

def collect_files(base_dir):
    """
    Recursively collects DICOM files only from the expected folders:
    - PPMI_Images_PD: Label "PD"
    - PPMI_Images_SWEDD: Label "SWEDD"
    - PPMI_Images_Cont: Label "Control"

    Excludes any file containing "br_raw" in its path and logs all skipped folders.

    :param base_dir: Base directory containing the Images folder.
    :return: (included_files, excluded_files)
             included_files: list of tuples (full_path, label)
             excluded_files: list of file paths that were excluded.
    """
    included_files = []
    excluded_files = []

    # Define the expected folders and corresponding labels
    expected_folders = {
        "PPMI_Images_PD": "PD",
        "PPMI_Images_SWEDD": "SWEDD",
        "PPMI_Images_Cont": "Control"
    }

    # Iterate over immediate subdirectories in base_dir
    for folder in os.listdir(base_dir):
        folder_path = os.path.join(base_dir, folder)
        if os.path.isdir(folder_path) and folder in expected_folders:
            logging.info(f"Processing folder: {folder_path}")
            # Recursively traverse the expected folder
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    if file.endswith(".dcm"):
                        full_path = os.path.join(root, file)
                        # Exclude any file with "br_raw" in its full path
                        if "br_raw" in full_path:
                            excluded_files.append(full_path)
                            logging.info(f"Excluding raw file: {full_path}")
                        else:
                            included_files.append((full_path, expected_folders[folder]))
        else:
            logging.info(f"Skipping folder: {folder_path}")

    return included_files, excluded_files

def generate_dataframe(included_files):
    """
    Creates a DataFrame from the list of validated file paths.

    :param included_files: List of tuples (file_path, label)
    :return: DataFrame with columns 'file_path' and 'label'
    """
    df = pd.DataFrame(included_files, columns=["file_path", "label"])
    return df

def save_qa_report(total_files, included_count, excluded_count, output_path="data_ingestion_QA_report.csv"):
    """
    Generates and saves a QA report of the file collection process.

    :param total_files: Total number of DICOM files encountered.
    :param included_count: Count of files included after filtering.
    :param excluded_count: Count of files excluded.
    :param output_path: File path for the QA report CSV.
    """
    exclusion_ratio = excluded_count / total_files if total_files > 0 else 0
    qa_report = {
        "total_files": total_files,
        "included_files": included_count,
        "excluded_files": excluded_count,
        "exclusion_ratio": exclusion_ratio,
    }
    qa_df = pd.DataFrame([qa_report])
    qa_df.to_csv(output_path, index=False)
    logging.info("QA report saved to %s", output_path)

    if exclusion_ratio > 0.5:
        warnings.warn(f"High proportion of raw files excluded: {exclusion_ratio:.2%}")

"""## Data Ingestion"""

# Cell 4: Data Ingestion Pipeline
import pydicom
import numpy as np

def load_dicom(file_path):
    """
    Loads and processes a DICOM file:
    - Reads the file using pydicom.
    - Converts the pixel array to float32.
    - Applies RescaleSlope and RescaleIntercept if available.

    :param file_path: Path to the DICOM file.
    :return: Tuple (processed_pixel_array, dicom_metadata)
    """
    try:
        ds = pydicom.dcmread(file_path)
    except Exception as e:
        raise IOError(f"Error reading DICOM file {file_path}: {e}")

    # Extract pixel array and convert to float32
    pixel_array = ds.pixel_array.astype(np.float32)

    # Apply rescaling if attributes are present
    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):
        slope = ds.RescaleSlope
        intercept = ds.RescaleIntercept
        pixel_array = pixel_array * slope + intercept

    return pixel_array, ds

# Cell 5: Execute Data Ingestion Pipeline
# Define the base directory containing the "Images" folder (adjust if necessary)
base_dir = "Images"

# Collect files from only the expected subdirectories
included_files, excluded_files = collect_files(base_dir)

# Create a DataFrame for the validated file paths and their labels
df = generate_dataframe(included_files)

# Final validation: Ensure that no "br_raw" files are included
if df["file_path"].str.contains("br_raw").any():
    raise ValueError("Validation failed: 'br_raw' files detected in the final dataset!")

# Save the validated file paths to CSV for reproducibility
df.to_csv("validated_file_paths.csv", index=False)
print("Validated file paths saved to validated_file_paths.csv")

# Generate and save the QA report
total_files = len(included_files) + len(excluded_files)
save_qa_report(total_files, len(included_files), len(excluded_files))
print("QA report generated and saved as data_ingestion_QA_report.csv")

"""## Data Visualization"""

# Cell 6: Visualize One Axial, Coronal, and Sagittal Slice for a Random Patient per Group

import pandas as pd
import random
import matplotlib.pyplot as plt
import numpy as np

# Read the validated file paths CSV generated earlier
df = pd.read_csv("validated_file_paths.csv")

# Function to extract the three orthogonal slices from a 3D volume
def extract_slices(volume):
    """
    Given a 3D volume, returns one axial, one coronal, and one sagittal slice.
    Assumes volume shape is (depth, height, width).
    """
    d, h, w = volume.shape
    axial = volume[d // 2, :, :]         # Axial: slice along depth
    coronal = volume[:, h // 2, :]        # Coronal: slice along height
    sagittal = volume[:, :, w // 2]       # Sagittal: slice along width
    return axial, coronal, sagittal

# List of groups and their expected labels
groups = {"PD": "PD", "SWEDD": "SWEDD", "Control": "Control"}

# Create a figure with one row per group and three columns for the views
fig, axes = plt.subplots(nrows=len(groups), ncols=3, figsize=(12, 4 * len(groups)))
fig.suptitle("Axial, Coronal, and Sagittal Slices for a Random Patient per Group", fontsize=16)

for i, (group_key, group_label) in enumerate(groups.items()):
    # Filter DataFrame for the current group
    group_df = df[df["label"] == group_label]
    if group_df.empty:
        print(f"No data found for group {group_label}")
        continue

    # Select a random file from the group
    random_file = group_df.sample(1)["file_path"].values[0]
    print(f"Loading file for group {group_label}: {random_file}")

    # Load the DICOM volume using the previously defined load_dicom() function
    volume, _ = load_dicom(random_file)

    # Verify the volume is 3D (if not, skip or raise an error)
    if volume.ndim != 3:
        raise ValueError(f"Expected 3D volume, got shape {volume.shape} for file: {random_file}")

    axial, coronal, sagittal = extract_slices(volume)

    # Plot Axial slice
    ax = axes[i, 0]
    ax.imshow(axial, cmap="gray")
    ax.set_title(f"{group_label} - Axial")
    ax.axis("off")

    # Plot Coronal slice
    ax = axes[i, 1]
    ax.imshow(coronal, cmap="gray")
    ax.set_title(f"{group_label} - Coronal")
    ax.axis("off")

    # Plot Sagittal slice
    ax = axes[i, 2]
    ax.imshow(sagittal, cmap="gray")
    ax.set_title(f"{group_label} - Sagittal")
    ax.axis("off")

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""## Data Preprocessing

### Intensity Normalization and Volume Preprocessing
"""

# Cell 7: Data Preprocessing – Intensity Normalization & Volume Processing

import numpy as np

def intensity_normalization(volume):
    """
    Normalizes intensity values:
    - Truncates negative values (sets them to 0)
    - Applies min-max scaling to bring values between 0 and 1 per volume.

    :param volume: Input 3D volume as a numpy array.
    :return: Normalized volume.
    """
    volume = np.clip(volume, a_min=0, a_max=None)
    vol_min, vol_max = volume.min(), volume.max()
    if vol_max > vol_min:
        volume = (volume - vol_min) / (vol_max - vol_min)
    else:
        volume = volume - vol_min  # volume is constant
    return volume

def resize_volume(volume, target_shape=(128, 128, 128)):
    """
    Resizes the volume to the target shape using zero-padding or center cropping while preserving aspect ratio.

    :param volume: Input 3D volume (numpy array) with shape (d, h, w).
    :param target_shape: Desired output shape (d_out, h_out, w_out).
    :return: Resized volume with shape target_shape.
    """
    current_shape = volume.shape
    resized = volume.copy()

    # For each dimension, either pad or crop to the target size
    for i in range(3):
        current = resized.shape[i]
        target = target_shape[i]
        if current < target:
            # Calculate padding sizes
            pad_total = target - current
            pad_before = pad_total // 2
            pad_after = pad_total - pad_before
            pad_width = [(0, 0), (0, 0), (0, 0)]
            pad_width[i] = (pad_before, pad_after)
            resized = np.pad(resized, pad_width=pad_width, mode="constant", constant_values=0)
        elif current > target:
            # Center crop
            start = (current - target) // 2
            end = start + target
            if i == 0:
                resized = resized[start:end, :, :]
            elif i == 1:
                resized = resized[:, start:end, :]
            elif i == 2:
                resized = resized[:, :, start:end]
    return resized

# Example usage (for testing on one volume):
volume, _ = load_dicom(random_file)  # random_file selected previously
norm_vol = intensity_normalization(volume)
resized_vol = resize_volume(norm_vol)
print("Original shape:", volume.shape, "Resized shape:", resized_vol.shape)

"""### Brain Masking"""

# Cell 8: Data Preprocessing – Brain Masking

import numpy as np
import matplotlib.pyplot as plt
from skimage.filters import threshold_otsu
from skimage.morphology import binary_closing, ball

def resize_volume(volume, target_shape=(128, 128, 128)):
    """
    Resizes the volume to the target shape using zero-padding or center cropping.

    Args:
        volume: Input 3D volume as numpy array with shape (d, h, w)
        target_shape: Desired output shape as tuple (d_new, h_new, w_new)

    Returns:
        Resized volume with shape target_shape
    """
    def get_pad_amounts(current_size, target_size):
        """Helper to calculate padding amounts"""
        if current_size >= target_size:
            return 0, 0
        diff = target_size - current_size
        pad_before = diff // 2
        pad_after = diff - pad_before
        return pad_before, pad_after

    current_shape = volume.shape
    resized = volume.copy()

    # Calculate padding/cropping for each dimension
    pads = [get_pad_amounts(current_shape[i], target_shape[i]) for i in range(3)]

    # Apply padding if needed
    if any(sum(p) > 0 for p in pads):
        resized = np.pad(
            resized,
            pad_width=pads,
            mode="constant",
            constant_values=0
        )

    # Apply cropping if needed
    for i in range(3):
        if current_shape[i] > target_shape[i]:
            # Calculate slicing indices
            start = (current_shape[i] - target_shape[i]) // 2
            end = start + target_shape[i]
            # Apply slice
            if i == 0:
                resized = resized[start:end, :, :]
            elif i == 1:
                resized = resized[:, start:end, :]
            else:
                resized = resized[:, :, start:end]

    return resized

def process_volume(volume, target_shape=(128, 128, 128)):
    """
    Process a 3D volume by:
    1. Normalizing intensity (truncating negatives and min-max scaling)
    2. Resizing to target_shape
    3. Generating a brain mask via Otsu thresholding and morphological closing

    Args:
        volume: Input 3D volume
        target_shape: Desired output shape (depth, height, width)

    Returns:
        norm_vol: Normalized and resized volume
        mask: Brain mask
        masked_vol: Masked volume
    """
    # 1. Intensity normalization
    volume = np.clip(volume, a_min=0, a_max=None)
    vmin, vmax = volume.min(), volume.max()
    if vmax > vmin:
        norm_vol = (volume - vmin) / (vmax - vmin)
    else:
        norm_vol = volume - vmin

    # 2. Resize the normalized volume
    norm_vol = resize_volume(norm_vol, target_shape=target_shape)

    # 3. Compute brain mask
    thresh = threshold_otsu(norm_vol)
    mask = norm_vol > thresh
    mask = binary_closing(mask, footprint=ball(2))
    masked_vol = norm_vol * mask

    return norm_vol, mask, masked_vol

# Demonstration: Load one sample DICOM file (using the first file in your validated DataFrame)
sample_file = df.iloc[0]["file_path"]
original_volume, _ = load_dicom(sample_file)

# Process the volume with our new function
norm_vol, mask, masked_vol = process_volume(original_volume, target_shape=(128,128,128))

# Extract an axial (middle) slice from both the normalized volume and the masked volume
axial_norm = norm_vol[norm_vol.shape[0]//2, :, :]
axial_masked = masked_vol[masked_vol.shape[0]//2, :, :]

# Plot side-by-side for comparison
fig, axes = plt.subplots(1, 2, figsize=(12, 6))
axes[0].imshow(axial_norm, cmap="gray")
axes[0].set_title("Normalized Axial Slice")
axes[0].axis("off")

axes[1].imshow(axial_masked, cmap="gray")
axes[1].set_title("Masked Axial Slice")
axes[1].axis("off")

plt.tight_layout()
plt.show()

"""## Dataloader Creation (with Shape Validation)"""

# Cell 9: Dataset Implementation with Shape Validation
import torch
from torch.utils.data import Dataset, DataLoader
from tqdm.notebook import tqdm
import gc
import numpy as np
import os
import psutil
from sklearn.model_selection import train_test_split

class DaTScanDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.df = dataframe
        self.transform = transform
        self._calculate_dataset_statistics()

    def _calculate_dataset_statistics(self):
        """Calculate dataset statistics with optimized processing"""
        chunk_size = 50  # Increased chunk size
        stats_list = []

        for i in tqdm(range(0, len(self.df), chunk_size), desc="Computing dataset stats"):
            chunk = self.df.iloc[i:min(i+chunk_size, len(self.df))]
            chunk_stats = []

            # Process each file in the chunk
            for _, row in chunk.iterrows():
                try:
                    volume, _ = load_dicom(row["file_path"])
                    chunk_stats.append({
                        'min': volume.min(),
                        'max': volume.max()
                    })
                except Exception as e:
                    print(f"Error processing file {row['file_path']}: {e}")

            # Batch process the chunk statistics
            if chunk_stats:
                min_vals = [stat['min'] for stat in chunk_stats]
                max_vals = [stat['max'] for stat in chunk_stats]
                stats_list.append({
                    'min': min(min_vals),
                    'max': max(max_vals)
                })

            # Garbage collection only once per chunk
            gc.collect()
            torch.cuda.empty_cache()

        # Compute final statistics
        if stats_list:
            self.stats = {
                'min': min(stat['min'] for stat in stats_list),
                'max': max(stat['max'] for stat in stats_list)
            }
        else:
            self.stats = {'min': 0, 'max': 1}  # Default values if no valid stats

    def __len__(self):
        """Return the total number of samples in the dataset"""
        return len(self.df)

    def _validate_and_fix_volume(self, volume):
        """
        Validate volume shape and fix if necessary.
        Ensures the volume is 3D with shape (depth, height, width).
        """
        # Convert to numpy array if not already
        if isinstance(volume, torch.Tensor):
            volume = volume.numpy()

        # Check dimensionality
        if volume.ndim == 2:
            # If 2D, add a depth dimension
            volume = volume[np.newaxis, :, :]
        elif volume.ndim > 3:
            # If more than 3D, squeeze any unit dimensions
            volume = np.squeeze(volume)
            # If still more than 3D, take the first 3 dimensions
            if volume.ndim > 3:
                volume = volume[:3, :, :]

        # Verify final shape
        if volume.ndim != 3:
            raise ValueError(f"Unable to convert volume to 3D. Current shape: {volume.shape}")

        return volume

    def __getitem__(self, idx):
        try:
            file_path = self.df.iloc[idx]["file_path"]

            # Load DICOM
            volume, _ = load_dicom(file_path)

            # Validate and fix volume shape
            try:
                volume = self._validate_and_fix_volume(volume)
            except Exception as e:
                print(f"Error validating volume shape for {file_path}: {e}")
                print(f"Initial volume shape: {volume.shape}")
                raise

            # Process volume
            norm_vol, mask, masked_vol = process_volume(volume, target_shape=(128, 128, 128))

            # Clean up original data
            del volume, norm_vol, mask
            gc.collect()

            # Convert to tensor
            volume_tensor = torch.from_numpy(np.expand_dims(masked_vol, axis=0)).float()

            del masked_vol
            gc.collect()

            return {
                "volume": volume_tensor,
                "label": self.df.iloc[idx]["label"],
                "path": file_path
            }

        except Exception as e:
            print(f"Error loading file {file_path}: {str(e)}")
            print(f"Stack trace:")
            import traceback
            traceback.print_exc()
            return None

def create_dataloaders(df, batch_size=2, train_split=0.8):
    """Create train and validation dataloaders with stratified split"""
    # Stratified split to maintain group distributions
    train_df, val_df = train_test_split(
        df,
        test_size=1-train_split,
        stratify=df['label'],
        random_state=42
    )

    print("\nTraining set distribution:")
    print(train_df['label'].value_counts())
    print("\nValidation set distribution:")
    print(val_df['label'].value_counts())

    # Create datasets
    train_dataset = DaTScanDataset(train_df)
    val_dataset = DaTScanDataset(val_df)

    # Create dataloaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,  # No multiprocessing for debugging
        pin_memory=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,  # No multiprocessing for debugging
        pin_memory=True
    )

    return train_loader, val_loader

def print_memory_stats():
    """Print memory usage statistics"""
    if torch.cuda.is_available():
        print("\nGPU Memory Usage:")
        print(f"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        print(f"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")
    print(f"CPU Memory Usage: {psutil.Process().memory_info().rss / 1024**2:.2f} MB")

# Test the dataset and dataloaders
if __name__ == "__main__":
    print("Creating dataloaders...")
    train_loader, val_loader = create_dataloaders(df, batch_size=2)

    print(f"Number of training batches: {len(train_loader)}")
    print(f"Number of validation batches: {len(val_loader)}")

    # Test the first few batches with detailed logging
    print("\nTesting first few batches from training loader...")
    print_memory_stats()

    try:
        for i, batch in enumerate(tqdm(train_loader, desc="Processing batches")):
            if batch is not None:
                print(f"\nBatch {i+1}:")
                print(f"Volume shape: {batch['volume'].shape}")
                print(f"Label: {batch['label']}")
                print_memory_stats()
            else:
                print(f"Batch {i+1} is None!")

            if i >= 2:  # Test first 3 batches
                break

            gc.collect()
            torch.cuda.empty_cache()

    except Exception as e:
        print(f"Error during batch processing: {str(e)}")
        import traceback
        traceback.print_exc()

"""## 3. AE Semi-Supervised

### Model Setup
"""

# Cell 27: Semi-Supervised Model Architecture
# Common imports
import os
import time
from pathlib import Path
import json
import numpy as np
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm
from collections import OrderedDict

# PyTorch imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.cuda.amp as amp

# Sklearn imports
from sklearn.metrics import confusion_matrix, classification_report

# Visualization
import seaborn as sns

class SemiSupervisedAE(nn.Module):
    """
    Semi-supervised autoencoder with classification branch.
    Optimized for 128³ medical volumes on NVIDIA 4070Ti.
    """
    def __init__(self, latent_dim=256, num_classes=3):
        super().__init__()
        self.encoder = SSEncoder(latent_dim)
        self.decoder = SSDecoder(latent_dim)
        self.classifier = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
        torch.backends.cudnn.benchmark = True

    def forward(self, x):
        # Encode input
        z, skip_connections = self.encoder(x)

        # Generate reconstruction
        reconstruction = self.decoder(z, skip_connections)

        # Generate classification
        classification = self.classifier(z)

        return reconstruction, classification, z

class ConvBlock(nn.Module):
    """Memory-efficient convolutional block."""
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.block = nn.Sequential(OrderedDict([
            ('conv', nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)),
            ('bn', nn.BatchNorm3d(out_channels)),
            ('relu', nn.ReLU(inplace=True))
        ]))

    def forward(self, x):
        return self.block(x)

class SSEncoder(nn.Module):
    """Encoder network with shared features for reconstruction and classification."""
    def __init__(self, latent_dim=256):
        super().__init__()

        # Initial feature extraction
        self.init_conv = ConvBlock(1, 16)  # 128 -> 128

        # Downsampling path
        self.down1 = nn.Sequential(
            ConvBlock(16, 32, stride=2),    # 128 -> 64
            ConvBlock(32, 32)
        )

        self.down2 = nn.Sequential(
            ConvBlock(32, 64, stride=2),    # 64 -> 32
            ConvBlock(64, 64)
        )

        self.down3 = nn.Sequential(
            ConvBlock(64, 128, stride=2),   # 32 -> 16
            ConvBlock(128, 128)
        )

        self.down4 = nn.Sequential(
            ConvBlock(128, 256, stride=2),  # 16 -> 8
            ConvBlock(256, 256)
        )

        # Project to latent space
        self.flatten_size = 256 * 8 * 8 * 8
        self.fc = nn.Linear(self.flatten_size, latent_dim)

    def forward(self, x):
        x = self.init_conv(x)
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)

        # Flatten and project to latent space
        flat = torch.flatten(d4, start_dim=1)
        z = self.fc(flat)

        return z, (d1, d2, d3, d4)

class SSDecoder(nn.Module):
    """Decoder network for reconstruction."""
    def __init__(self, latent_dim=256):
        super().__init__()

        self.flatten_size = 256 * 8 * 8 * 8
        self.fc = nn.Linear(latent_dim, self.flatten_size)

        # Upsampling path
        self.up1 = nn.Sequential(
            nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2),  # 8 -> 16
            ConvBlock(128, 128)
        )

        self.up2 = nn.Sequential(
            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),   # 16 -> 32
            ConvBlock(64, 64)
        )

        self.up3 = nn.Sequential(
            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),    # 32 -> 64
            ConvBlock(32, 32)
        )

        self.up4 = nn.Sequential(
            nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2),    # 64 -> 128
            ConvBlock(16, 16)
        )

        # Final convolution
        self.final_conv = nn.Conv3d(16, 1, kernel_size=1)

    def forward(self, z, skip_connections):
        # Reshape from latent space
        x = self.fc(z)
        x = x.view(-1, 256, 8, 8, 8)

        # Unpack skip connections
        d1, d2, d3, d4 = skip_connections

        # Upsampling with skip connections
        x = self.up1(x + d4)
        x = self.up2(x + d3)
        x = self.up3(x + d2)
        x = self.up4(x + d1)

        # Final convolution with sigmoid activation
        x = torch.sigmoid(self.final_conv(x))

        return x

# Cell 28: Training Configuration
class SSAEConfig:
    """Configuration for semi-supervised training."""
    def __init__(self):
        # Model parameters
        self.latent_dim = 256
        self.num_classes = 3
        self.learning_rate = 1e-4

        # Loss weights
        self.recon_weight = 1.0
        self.class_weight = 0.5

        # Training parameters
        self.batch_size = 8
        self.epochs = 100
        self.accumulation_steps = 4

        # Early stopping
        self.patience = 10
        self.min_delta = 1e-6

        # Optimization
        self.use_amp = True
        self.num_workers = 4
        self.pin_memory = True

        # Checkpoint configuration
        self.checkpoint_dir = 'checkpoints'
        self.model_name = 'ssae'
        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)

class SSAELoss:
    """Combined loss for semi-supervised training."""
    def __init__(self, recon_weight=1.0, class_weight=0.5):
        self.recon_weight = recon_weight
        self.class_weight = class_weight
        self.recon_criterion = nn.MSELoss()
        self.class_criterion = nn.CrossEntropyLoss()

    def __call__(self, recon, target, class_pred, class_target):
        recon_loss = self.recon_criterion(recon, target)
        class_loss = self.class_criterion(class_pred, class_target)

        total_loss = (self.recon_weight * recon_loss +
                     self.class_weight * class_loss)

        return total_loss, recon_loss, class_loss

# Cell 29: Label Processing
def process_labels(labels):
    """Convert string labels to tensor indices."""
    label_map = {'Control': 0, 'PD': 1, 'SWEDD': 2}
    return torch.tensor([label_map[label] for label in labels])

def create_class_weights(dataloader):
    """Calculate class weights for balanced training."""
    label_counts = torch.zeros(3)
    for batch in dataloader:
        labels = process_labels(batch['label'])
        for label in labels:
            label_counts[label] += 1

    total = label_counts.sum()
    class_weights = total / (3 * label_counts)
    return class_weights

# Cell 30: Checkpoint Handler
class SSAECheckpointHandler:
    """Handles saving and loading of model checkpoints."""
    def __init__(self, checkpoint_dir, model_name):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.model_name = model_name
        self.checkpoint_path = self.checkpoint_dir / f"{model_name}_checkpoint.pth"
        self.metadata_path = self.checkpoint_dir / f"{model_name}_metadata.json"

    def save(self, model, optimizer, scheduler, epoch, metrics):
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'metrics': metrics
        }
        torch.save(checkpoint, self.checkpoint_path)

        metadata = {
            'last_epoch': epoch,
            'metrics': metrics,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(self.metadata_path, 'w') as f:
            json.dump(metadata, f, indent=4)

    def load(self, model, optimizer, scheduler):
        if not self.checkpoint_path.exists():
            return None

        checkpoint = torch.load(self.checkpoint_path)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if scheduler and checkpoint['scheduler_state_dict']:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        return checkpoint['epoch'], checkpoint['metrics']

# Cell 31: Training Loop
import torch.cuda.amp as amp
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

def train_ssae(model, train_loader, val_loader, config=None):
    """Training loop with memory optimization for NVIDIA 4070Ti."""
    if config is None:
        config = SSAEConfig()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Initialize components
    criterion = SSAELoss(config.recon_weight, config.class_weight)
    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)
    scaler = amp.GradScaler(enabled=config.use_amp)
    checkpoint_handler = SSAECheckpointHandler(config.checkpoint_dir, config.model_name)

    # Training tracking
    best_val_loss = float('inf')
    patience_counter = 0
    metrics = {
        'train_losses': [], 'val_losses': [],
        'train_recon': [], 'val_recon': [],
        'train_class': [], 'val_class': [],
        'train_acc': [], 'val_acc': []
    }

    # Load checkpoint if available
    start_epoch = 0
    checkpoint_data = checkpoint_handler.load(model, optimizer, scheduler)
    if checkpoint_data:
        start_epoch, metrics = checkpoint_data
        print(f"Resuming training from epoch {start_epoch + 1}")

    try:
        for epoch in range(start_epoch, config.epochs):
            # Training phase
            model.train()
            train_loss = train_recon = train_class = 0
            correct_preds = total_preds = 0

            train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs} [Train]')

            for i, batch in enumerate(train_pbar):
                try:
                    volumes = batch['volume'].to(device, non_blocking=True)
                    labels = process_labels(batch['label']).to(device)

                    # Forward pass with mixed precision
                    with amp.autocast(enabled=config.use_amp):
                        recon, class_pred, _ = model(volumes)
                        loss, recon_l, class_l = criterion(recon, volumes, class_pred, labels)
                        loss = loss / config.accumulation_steps

                    # Backward pass
                    scaler.scale(loss).backward()

                    # Gradient accumulation
                    if (i + 1) % config.accumulation_steps == 0:
                        scaler.step(optimizer)
                        scaler.update()
                        optimizer.zero_grad()

                    # Track metrics
                    train_loss += loss.item() * config.accumulation_steps
                    train_recon += recon_l.item()
                    train_class += class_l.item()

                    # Track accuracy
                    pred = class_pred.argmax(dim=1)
                    correct_preds += (pred == labels).sum().item()
                    total_preds += labels.size(0)

                    # Update progress bar
                    train_pbar.set_postfix({
                        'loss': loss.item() * config.accumulation_steps,
                        'recon': recon_l.item(),
                        'class': class_l.item(),
                        'acc': correct_preds/total_preds
                    })

                    # Clean up
                    del volumes, labels, recon, class_pred
                    torch.cuda.empty_cache()

                except RuntimeError as e:
                    if "out of memory" in str(e):
                        print(f"\nOOM in batch {i}. Cleaning up...")
                        if 'volumes' in locals():
                            del volumes
                        if 'recon' in locals():
                            del recon
                        torch.cuda.empty_cache()
                        continue
                    raise e

            # Validation phase
            model.eval()
            val_loss = val_recon = val_class = 0
            val_correct = val_total = 0
            all_preds = []
            all_labels = []

            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{config.epochs} [Val]')


            with torch.no_grad():
                for batch in val_pbar:
                    try:
                        volumes = batch['volume'].to(device)
                        labels = process_labels(batch['label']).to(device)

                        recon, class_pred, _ = model(volumes)
                        loss, recon_l, class_l = criterion(recon, volumes, class_pred, labels)

                        val_loss += loss.item()
                        val_recon += recon_l.item()
                        val_class += class_l.item()

                        # Track predictions for metrics
                        pred = class_pred.argmax(dim=1)
                        val_correct += (pred == labels).sum().item()
                        val_total += labels.size(0)

                        all_preds.extend(pred.cpu().numpy())
                        all_labels.extend(labels.cpu().numpy())

                        val_pbar.set_postfix({
                            'loss': loss.item(),
                            'acc': val_correct/val_total
                        })

                        del volumes, labels, recon, class_pred
                        torch.cuda.empty_cache()

                    except RuntimeError as e:
                        if "out of memory" in str(e):
                            print("\nOOM during validation. Cleaning up...")
                            if 'volumes' in locals():
                                del volumes
                            if 'recon' in locals():
                                del recon
                            torch.cuda.empty_cache()
                            continue
                        raise e

            # Calculate epoch metrics
            train_metrics = {
                'loss': train_loss / len(train_loader),
                'recon': train_recon / len(train_loader),
                'class': train_class / len(train_loader),
                'acc': correct_preds / total_preds
            }

            val_metrics = {
                'loss': val_loss / len(val_loader),
                'recon': val_recon / len(val_loader),
                'class': val_class / len(val_loader),
                'acc': val_correct / val_total
            }

            # Update tracking metrics
            metrics['train_losses'].append(train_metrics['loss'])
            metrics['val_losses'].append(val_metrics['loss'])
            metrics['train_recon'].append(train_metrics['recon'])
            metrics['val_recon'].append(val_metrics['recon'])
            metrics['train_class'].append(train_metrics['class'])
            metrics['val_class'].append(val_metrics['class'])
            metrics['train_acc'].append(train_metrics['acc'])
            metrics['val_acc'].append(val_metrics['acc'])

            # Update learning rate
            scheduler.step(val_metrics['loss'])

            # Save checkpoint
            checkpoint_handler.save(model, optimizer, scheduler, epoch, metrics)

            # Print epoch summary
            print(f"\nEpoch {epoch+1}/{config.epochs}")
            print("Training Metrics:")
            print(f"Loss: {train_metrics['loss']:.6f}")
            print(f"Recon Loss: {train_metrics['recon']:.6f}")
            print(f"Class Loss: {train_metrics['class']:.6f}")
            print(f"Accuracy: {train_metrics['acc']:.2%}")

            print("\nValidation Metrics:")
            print(f"Loss: {val_metrics['loss']:.6f}")
            print(f"Recon Loss: {val_metrics['recon']:.6f}")
            print(f"Class Loss: {val_metrics['class']:.6f}")
            print(f"Accuracy: {val_metrics['acc']:.2%}")

            # Early stopping check
            if val_metrics['loss'] < best_val_loss - config.min_delta:
                best_val_loss = val_metrics['loss']
                patience_counter = 0
                # Save best model
                torch.save(model.state_dict(),
                         os.path.join(config.checkpoint_dir, f'{config.model_name}_best.pth'))
            else:
                patience_counter += 1
                if patience_counter >= config.patience:
                    print(f"\nEarly stopping triggered at epoch {epoch+1}")
                    break

            # Print memory stats
            print("\nGPU Memory Stats:")
            print_gpu_memory_stats()

    except KeyboardInterrupt:
        print("\nTraining interrupted by user!")

    finally:
        # Plot training history
        plot_training_history(metrics)

    return metrics

def plot_training_history(metrics):
    """Plot training and validation metrics history."""
    plt.figure(figsize=(15, 10))

    # Plot losses
    plt.subplot(2, 2, 1)
    plt.plot(metrics['train_losses'], label='Train Loss')
    plt.plot(metrics['val_losses'], label='Val Loss')
    plt.title('Total Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot reconstruction loss
    plt.subplot(2, 2, 2)
    plt.plot(metrics['train_recon'], label='Train Recon')
    plt.plot(metrics['val_recon'], label='Val Recon')
    plt.title('Reconstruction Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot classification loss
    plt.subplot(2, 2, 3)
    plt.plot(metrics['train_class'], label='Train Class')
    plt.plot(metrics['val_class'], label='Val Class')
    plt.title('Classification Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot accuracy
    plt.subplot(2, 2, 4)
    plt.plot(metrics['train_acc'], label='Train Acc')
    plt.plot(metrics['val_acc'], label='Val Acc')
    plt.title('Classification Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Cell 32: Model Evaluation
def evaluate_model(model, val_loader, config=None):
    """Comprehensive model evaluation including reconstruction and classification metrics."""
    if config is None:
        config = SSAEConfig()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    # Initialize metrics
    val_recon_loss = 0
    val_class_loss = 0
    all_preds = []
    all_labels = []
    reconstructions = []
    originals = []

    criterion = SSAELoss(config.recon_weight, config.class_weight)

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Evaluating"):
            volumes = batch['volume'].to(device)
            labels = process_labels(batch['label']).to(device)

            recon, class_pred, _ = model(volumes)
            _, recon_l, class_l = criterion(recon, volumes, class_pred, labels)

            val_recon_loss += recon_l.item()
            val_class_loss += class_l.item()

            pred = class_pred.argmax(dim=1)
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Store some examples for visualization
            if len(reconstructions) < 5:
                reconstructions.append(recon.cpu().numpy())
                originals.append(volumes.cpu().numpy())

    # Calculate average losses
    avg_recon_loss = val_recon_loss / len(val_loader)
    avg_class_loss = val_class_loss / len(val_loader)

    # Print classification report
    label_names = ['Control', 'PD', 'SWEDD']
    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, target_names=label_names))

    # Plot confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_names,
                yticklabels=label_names)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

    # Visualize reconstructions
    visualize_reconstructions(originals, reconstructions, label_names,
                            [label_names[l] for l in all_labels[:5]])

    return {
        'recon_loss': avg_recon_loss,
        'class_loss': avg_class_loss,
        'predictions': all_preds,
        'true_labels': all_labels
    }

def visualize_reconstructions(originals, reconstructions, label_names, true_labels):
    """Visualize original vs reconstructed volumes."""
    num_samples = len(originals)
    plt.figure(figsize=(15, 3*num_samples))

    for i in range(num_samples):
        orig = originals[i][0]
        recon = reconstructions[i][0]

        # Get middle slices
        orig_axial = orig[orig.shape[0]//2, :, :]
        orig_sagittal = orig[:, orig.shape[1]//2, :]
        orig_coronal = orig[:, :, orig.shape[2]//2]

        recon_axial = recon[recon.shape[0]//2, :, :]
        recon_sagittal = recon[:, recon.shape[1]//2, :]
        recon_coronal = recon[:, :, recon.shape[2]//2]

        # Plot original
        plt.subplot(num_samples, 6, i*6 + 1)
        plt.imshow(orig_axial, cmap='gray')
        plt.title(f'Original Axial\n{true_labels[i]}' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 2)
        plt.imshow(orig_sagittal, cmap='gray')
        plt.title('Original Sagittal' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 3)
        plt.imshow(orig_coronal, cmap='gray')
        plt.title('Original Coronal' if i == 0 else '')
        plt.axis('off')

        # Plot reconstruction
        plt.subplot(num_samples, 6, i*6 + 4)
        plt.imshow(recon_axial, cmap='gray')
        plt.title('Reconstructed Axial' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 5)
        plt.imshow(recon_sagittal, cmap='gray')
        plt.title('Reconstructed Sagittal' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 6)
        plt.imshow(recon_coronal, cmap='gray')
        plt.title('Reconstructed Coronal' if i == 0 else '')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Cell 33: Smart Training Cell
def initialize_training():
    """Initialize or resume training based on checkpoint existence."""
    config = SSAEConfig()
    model = SemiSupervisedAE(
        latent_dim=config.latent_dim,
        num_classes=config.num_classes
    )

    # Check for existing checkpoint
    checkpoint_path = Path(config.checkpoint_dir) / f"{config.model_name}_checkpoint.pth"
    if checkpoint_path.exists():
        print("\nFound existing checkpoint. Resuming training...")
    else:
        print("\nNo checkpoint found. Starting new training...")

    return model, config

if __name__ == "__main__":
    training_completed = False

    try:
        # Initialize or resume
        model, config = initialize_training()

        # Start or resume training
        metrics = train_ssae(model, train_loader, val_loader, config)

        # Set flag for successful completion
        training_completed = True

    except KeyboardInterrupt:
        print("\nTraining interrupted by user. Progress has been saved to checkpoint.")
        print("Run this cell again to resume training from the last checkpoint.")
    except Exception as e:
        print(f"\nError during execution: {str(e)}")
        import traceback
        traceback.print_exc()

    # Only run evaluation if training completed normally
    if training_completed:
        try:
            print("\nTraining completed successfully. Starting evaluation...")
            evaluation_results = evaluate_model(model, val_loader, config)
            print("\nEvaluation completed. Results saved in 'evaluation_results'")
        except Exception as e:
            print(f"\nError during evaluation: {str(e)}")
            traceback.print_exc()

# Cell 34: Semi-Supervised Model Reconstruction and Evaluation
import torch
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
from tqdm.notebook import tqdm
import seaborn as sns
from skimage.metrics import structural_similarity as ssim

def load_trained_ssae(checkpoint_dir, model_name='ssae'):
    """
    Load trained semi-supervised model and metadata without modifying previous cells.

    Args:
        checkpoint_dir (str): Directory containing checkpoints
        model_name (str): Name of the model checkpoint

    Returns:
        model: Loaded model
        metadata: Training metadata
    """
    checkpoint_path = Path(checkpoint_dir) / f"{model_name}_checkpoint.pth"
    metadata_path = Path(checkpoint_dir) / f"{model_name}_metadata.json"

    # Initialize model with same configuration as training
    model = SemiSupervisedAE(latent_dim=256, num_classes=3)

    # Load checkpoint
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # Load metadata if available
    metadata = None
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)

    return model, metadata

def compute_slice_metrics(original_slice, reconstructed_slice):
    """
    Compute quality metrics for a single slice.

    Args:
        original_slice: Original image slice
        reconstructed_slice: Reconstructed image slice

    Returns:
        dict: Dictionary containing MSE and SSIM metrics
    """
    mse = np.mean((original_slice - reconstructed_slice) ** 2)
    ssim_score = ssim(original_slice, reconstructed_slice, data_range=1.0)

    return {
        'MSE': mse,
        'SSIM': ssim_score
    }

# Cell 35: Reconstruction Visualization Functions
def extract_orthogonal_slices(volume):
    """
    Extract axial, sagittal, and coronal slices from the middle of the volume.

    Args:
        volume: 3D volume array

    Returns:
        tuple: (axial_slice, sagittal_slice, coronal_slice)
    """
    d, h, w = volume.shape
    axial = volume[d//2, :, :]      # Top-down view
    sagittal = volume[:, h//2, :]    # Side view
    coronal = volume[:, :, w//2]     # Front view

    return axial, sagittal, coronal

def visualize_reconstruction_comparison(original, reconstructed, metrics, title="Sample Reconstruction Comparison"):
    """
    Create side-by-side visualization of original and reconstructed slices.

    Args:
        original: Original volume
        reconstructed: Reconstructed volume
        metrics: Dictionary containing evaluation metrics
        title: Plot title
    """
    # Extract slices
    orig_axial, orig_sagittal, orig_coronal = extract_orthogonal_slices(original)
    recon_axial, recon_sagittal, recon_coronal = extract_orthogonal_slices(reconstructed)

    # Create figure
    fig = plt.figure(figsize=(15, 8))
    plt.suptitle(title, fontsize=16, y=1.05)

    # Plot original slices
    views = ['Axial', 'Sagittal', 'Coronal']
    orig_slices = [orig_axial, orig_sagittal, orig_coronal]
    recon_slices = [recon_axial, recon_sagittal, recon_coronal]

    for idx, (view, orig_slice, recon_slice) in enumerate(zip(views, orig_slices, recon_slices)):
        # Original
        plt.subplot(2, 3, idx + 1)
        plt.imshow(orig_slice, cmap='gray')
        plt.title(f'Original {view}')
        plt.axis('off')

        # Reconstructed
        plt.subplot(2, 3, idx + 4)
        plt.imshow(recon_slice, cmap='gray')
        plt.title(f'Reconstructed {view}\nMSE: {metrics[view]["MSE"]:.4f}\nSSIM: {metrics[view]["SSIM"]:.4f}')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Cell 36: Evaluation Pipeline
def evaluate_ssae_reconstruction(model, val_loader, samples_per_group=2):
    """
    Evaluate semi-supervised model reconstruction on validation set.

    Args:
        model: Trained semi-supervised model
        val_loader: Validation data loader
        samples_per_group: Number of samples to visualize per patient group
    """
    device = next(model.parameters()).device
    model.eval()

    # Initialize storage for group-wise metrics
    group_metrics = {
        'Control': {'mse': [], 'samples': 0},
        'PD': {'mse': [], 'samples': 0},
        'SWEDD': {'mse': [], 'samples': 0}
    }

    # Track visualized samples per group
    visualized_samples = {
        'Control': 0,
        'PD': 0,
        'SWEDD': 0
    }

    print("Evaluating reconstruction quality...")

    with torch.no_grad():
        for batch in tqdm(val_loader):
            # Check if we have enough samples from each group
            if all(count >= samples_per_group for count in visualized_samples.values()):
                break

            # Move data to GPU
            volumes = batch['volume'].to(device)
            labels = batch['label']  # Original string labels

            # Get reconstructions
            reconstructions, classifications, _ = model(volumes)

            # Process each sample in the batch
            for idx in range(volumes.shape[0]):
                current_group = labels[idx]

                # Skip if we already have enough samples from this group
                if visualized_samples[current_group] >= samples_per_group:
                    continue

                # Get original and reconstructed volumes
                orig_vol = volumes[idx, 0].cpu().numpy()
                recon_vol = reconstructions[idx, 0].cpu().numpy()

                # Calculate metrics for each view
                metrics = {}
                for view, (orig_slice, recon_slice) in zip(
                    ['Axial', 'Sagittal', 'Coronal'],
                    zip(*[extract_orthogonal_slices(vol) for vol in [orig_vol, recon_vol]])
                ):
                    metrics[view] = compute_slice_metrics(orig_slice, recon_slice)

                # Visualize comparison
                visualize_reconstruction_comparison(
                    orig_vol,
                    recon_vol,
                    metrics,
                    f"Patient Group: {current_group} - Sample {visualized_samples[current_group] + 1}"
                )

                # Update group metrics
                mse = np.mean((volumes[idx, 0].cpu().numpy() -
                             reconstructions[idx, 0].cpu().numpy()) ** 2)
                group_metrics[current_group]['mse'].append(mse)
                group_metrics[current_group]['samples'] += 1
                visualized_samples[current_group] += 1

            # Clean up GPU memory
            del volumes, reconstructions
            torch.cuda.empty_cache()

    # Print group-wise metrics
    print("\nReconstruction Metrics by Patient Group:")
    for group in group_metrics:
        if group_metrics[group]['samples'] > 0:
            avg_mse = np.mean(group_metrics[group]['mse'])
            print(f"\n{group}:")
            print(f"Number of samples: {group_metrics[group]['samples']}")
            print(f"Average MSE: {avg_mse:.6f}")
            print(f"RMSE: {np.sqrt(avg_mse):.6f}")

    return group_metrics

# Cell 37: Run Evaluation
if __name__ == "__main__":
    try:
        # Load trained model
        print("Loading trained semi-supervised model...")
        model, metadata = load_trained_ssae('checkpoints')
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        # Run evaluation with samples per group
        print("\nStarting reconstruction evaluation...")
        group_metrics = evaluate_ssae_reconstruction(model, val_loader, samples_per_group=2)

        # Visualize group-wise metrics
        groups = list(group_metrics.keys())
        mse_values = [np.mean(group_metrics[g]['mse']) for g in groups]

        plt.figure(figsize=(10, 6))
        plt.bar(groups, mse_values)
        plt.title('Average MSE by Patient Group')
        plt.ylabel('Mean Squared Error')
        plt.grid(True, alpha=0.3)
        plt.show()

        # Clean up
        torch.cuda.empty_cache()
        print("\nEvaluation completed successfully!")

    except Exception as e:
        print(f"Error during evaluation: {str(e)}")
        import traceback
        traceback.print_exc()

"""## 4. VAE Semi-Supervised

### Model Setup
"""

# Cell 38: Semi-Supervised VAE Model Architecture
import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict
import torch.cuda.amp as amp

class SSVAE(nn.Module):
    """
    Semi-Supervised Variational Autoencoder combining reconstruction,
    latent sampling, and classification objectives.
    Optimized for 128³ medical volumes on NVIDIA 4070Ti.
    """
    def __init__(self, latent_dim=256, num_classes=3):
        super().__init__()
        self.encoder = SSVAEEncoder(latent_dim)
        self.decoder = SSVAEDecoder(latent_dim)
        self.classifier = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
        torch.backends.cudnn.benchmark = True

    def reparameterize(self, mu, log_var):
        """Reparameterization trick for VAE sampling."""
        if self.training:
            std = torch.exp(0.5 * log_var)
            eps = torch.randn_like(std)
            return mu + eps * std
        return mu

    def forward(self, x):
        # Encode input
        mu, log_var, skip_connections = self.encoder(x)

        # Sample from latent distribution
        z = self.reparameterize(mu, log_var)

        # Generate reconstruction and classification
        reconstruction = self.decoder(z, skip_connections)
        classification = self.classifier(z)

        return reconstruction, classification, mu, log_var

class ConvBlock(nn.Module):
    """Memory-efficient convolutional block."""
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.block = nn.Sequential(OrderedDict([
            ('conv', nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)),
            ('bn', nn.BatchNorm3d(out_channels)),
            ('relu', nn.ReLU(inplace=True))
        ]))

    def forward(self, x):
        return self.block(x)

class SSVAEEncoder(nn.Module):
    """Encoder network with probabilistic latent space."""
    def __init__(self, latent_dim=256):
        super().__init__()

        # Initial feature extraction
        self.init_conv = ConvBlock(1, 16)  # 128 -> 128

        # Downsampling path
        self.down1 = nn.Sequential(
            ConvBlock(16, 32, stride=2),    # 128 -> 64
            ConvBlock(32, 32)
        )

        self.down2 = nn.Sequential(
            ConvBlock(32, 64, stride=2),    # 64 -> 32
            ConvBlock(64, 64)
        )

        self.down3 = nn.Sequential(
            ConvBlock(64, 128, stride=2),   # 32 -> 16
            ConvBlock(128, 128)
        )

        self.down4 = nn.Sequential(
            ConvBlock(128, 256, stride=2),  # 16 -> 8
            ConvBlock(256, 256)
        )

        # Project to latent parameters
        self.flatten_size = 256 * 8 * 8 * 8
        self.fc_mu = nn.Linear(self.flatten_size, latent_dim)
        self.fc_var = nn.Linear(self.flatten_size, latent_dim)

    def forward(self, x):
        x = self.init_conv(x)
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)

        # Flatten and project to latent parameters
        flat = torch.flatten(d4, start_dim=1)
        mu = self.fc_mu(flat)
        log_var = self.fc_var(flat)

        return mu, log_var, (d1, d2, d3, d4)

class SSVAEDecoder(nn.Module):
    """Decoder network with skip connections."""
    def __init__(self, latent_dim=256):
        super().__init__()

        self.flatten_size = 256 * 8 * 8 * 8
        self.fc = nn.Linear(latent_dim, self.flatten_size)

        # Upsampling path
        self.up1 = nn.Sequential(
            nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2),  # 8 -> 16
            ConvBlock(128, 128)
        )

        self.up2 = nn.Sequential(
            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),   # 16 -> 32
            ConvBlock(64, 64)
        )

        self.up3 = nn.Sequential(
            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),    # 32 -> 64
            ConvBlock(32, 32)
        )

        self.up4 = nn.Sequential(
            nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2),    # 64 -> 128
            ConvBlock(16, 16)
        )

        # Final convolution
        self.final_conv = nn.Conv3d(16, 1, kernel_size=1)

    def forward(self, z, skip_connections):
        # Reshape from latent space
        x = self.fc(z)
        x = x.view(-1, 256, 8, 8, 8)

        # Unpack skip connections
        d1, d2, d3, d4 = skip_connections

        # Upsampling with skip connections
        x = self.up1(x + d4)
        x = self.up2(x + d3)
        x = self.up3(x + d2)
        x = self.up4(x + d1)

        # Final convolution with sigmoid activation
        x = torch.sigmoid(self.final_conv(x))

        return x

# Cell 39: Training Configuration and Loss Functions
class SSVAEConfig:
    """Configuration for SSVAE training."""
    def __init__(self):
        # Model parameters
        self.latent_dim = 256
        self.num_classes = 3
        self.learning_rate = 1e-4

        # Loss weights
        self.recon_weight = 1.0
        self.kl_weight = 0.1
        self.class_weight = 0.5

        # Training parameters
        self.batch_size = 8  # Optimized for 12GB VRAM
        self.epochs = 100
        self.accumulation_steps = 4

        # Early stopping
        self.patience = 10
        self.min_delta = 1e-6

        # Optimization
        self.use_amp = True
        self.num_workers = 4
        self.pin_memory = True

        # Checkpoint configuration
        self.checkpoint_dir = 'checkpoints'
        self.model_name = 'ssvae'
        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)

class SSVAELoss:
    """Combined loss for semi-supervised VAE training."""
    def __init__(self, recon_weight=1.0, kl_weight=0.1, class_weight=0.5):
        self.recon_weight = recon_weight
        self.kl_weight = kl_weight
        self.class_weight = class_weight
        self.recon_criterion = nn.MSELoss()
        self.class_criterion = nn.CrossEntropyLoss()

    def __call__(self, recon, target, class_pred, class_target, mu, log_var):
        # Reconstruction loss
        recon_loss = self.recon_criterion(recon, target)

        # KL divergence
        kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())

        # Classification loss
        class_loss = self.class_criterion(class_pred, class_target)

        # Total loss
        total_loss = (self.recon_weight * recon_loss +
                     self.kl_weight * kl_loss +
                     self.class_weight * class_loss)

        return total_loss, recon_loss, kl_loss, class_loss

# Cell 40: Checkpoint Handler
class SSVAECheckpointHandler:
    """Handles saving and loading of model checkpoints."""
    def __init__(self, checkpoint_dir, model_name):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.model_name = model_name
        self.checkpoint_path = self.checkpoint_dir / f"{model_name}_checkpoint.pth"
        self.metadata_path = self.checkpoint_dir / f"{model_name}_metadata.json"

    def save(self, model, optimizer, scheduler, epoch, metrics):
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'metrics': metrics
        }
        torch.save(checkpoint, self.checkpoint_path)

        metadata = {
            'last_epoch': epoch,
            'metrics': metrics,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(self.metadata_path, 'w') as f:
            json.dump(metadata, f, indent=4)

    def load(self, model, optimizer, scheduler):
        if not self.checkpoint_path.exists():
            return None

        checkpoint = torch.load(self.checkpoint_path)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if scheduler and checkpoint['scheduler_state_dict']:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        return checkpoint['epoch'], checkpoint['metrics']

# Cell 41: Training Loop
def train_ssvae(model, train_loader, val_loader, config=None):
    """Training loop with memory optimization for NVIDIA 4070Ti."""
    if config is None:
        config = SSVAEConfig()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Initialize components
    criterion = SSVAELoss(
        config.recon_weight,
        config.kl_weight,
        config.class_weight
    )
    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    scaler = amp.GradScaler(enabled=config.use_amp)
    checkpoint_handler = SSVAECheckpointHandler(config.checkpoint_dir, config.model_name)

    # Training tracking
    best_val_loss = float('inf')
    patience_counter = 0
    metrics = {
        'train_losses': [], 'val_losses': [],
        'train_recon': [], 'val_recon': [],
        'train_kl': [], 'val_kl': [],
        'train_class': [], 'val_class': [],
        'train_acc': [], 'val_acc': []
    }

    # Load checkpoint if available
    start_epoch = 0
    checkpoint_data = checkpoint_handler.load(model, optimizer, scheduler)
    if checkpoint_data:
        start_epoch, metrics = checkpoint_data
        print(f"Resuming training from epoch {start_epoch + 1}")

    try:
        for epoch in range(start_epoch, config.epochs):
            # Training phase
            model.train()
            train_loss = train_recon = train_kl = train_class = 0
            correct_preds = total_preds = 0

            train_pbar = tqdm(train_loader,
                            desc=f'Epoch {epoch+1}/{config.epochs} [Train]')

            for i, batch in enumerate(train_pbar):
                try:
                    volumes = batch['volume'].to(device, non_blocking=True)
                    labels = process_labels(batch['label']).to(device)

                    # Forward pass with mixed precision
                    with amp.autocast(enabled=config.use_amp):
                        recon, class_pred, mu, log_var = model(volumes)
                        loss, recon_l, kl_l, class_l = criterion(
                            recon, volumes, class_pred, labels, mu, log_var
                        )
                        loss = loss / config.accumulation_steps

                    # Backward pass
                    scaler.scale(loss).backward()

                    # Gradient accumulation
                    if (i + 1) % config.accumulation_steps == 0:
                        scaler.step(optimizer)
                        scaler.update()
                        optimizer.zero_grad()

                    # Track metrics
                    train_loss += loss.item() * config.accumulation_steps
                    train_recon += recon_l.item()
                    train_kl += kl_l.item()
                    train_class += class_l.item()

                    # Track accuracy
                    pred = class_pred.argmax(dim=1)
                    correct_preds += (pred == labels).sum().item()
                    total_preds += labels.size(0)

                    # Update progress bar
                    train_pbar.set_postfix({
                        'loss': loss.item() * config.accumulation_steps,
                        'recon': recon_l.item(),
                        'kl': kl_l.item(),
                        'class': class_l.item(),
                        'acc': correct_preds/total_preds
                    })

                    # Clean up
                    del volumes, labels, recon, class_pred, mu, log_var
                    torch.cuda.empty_cache()

                except RuntimeError as e:
                    if "out of memory" in str(e):
                        print(f"\nOOM in batch {i}. Cleaning up...")
                        if 'volumes' in locals():
                            del volumes
                        if 'recon' in locals():
                            del recon
                        torch.cuda.empty_cache()
                        continue
                    raise e

            # Validation phase
            model.eval()
            val_loss = val_recon = val_kl = val_class = 0
            val_correct = val_total = 0
            all_preds = []
            all_labels = []

            val_pbar = tqdm(val_loader,
                          desc=f'Epoch {epoch+1}/{config.epochs} [Val]')

            with torch.no_grad():
                for batch in val_pbar:
                    try:
                        volumes = batch['volume'].to(device)
                        labels = process_labels(batch['label']).to(device)

                        recon, class_pred, mu, log_var = model(volumes)
                        loss, recon_l, kl_l, class_l = criterion(
                            recon, volumes, class_pred, labels, mu, log_var
                        )

                        val_loss += loss.item()
                        val_recon += recon_l.item()
                        val_kl += kl_l.item()
                        val_class += class_l.item()

                        # Track predictions for metrics
                        pred = class_pred.argmax(dim=1)
                        val_correct += (pred == labels).sum().item()
                        val_total += labels.size(0)

                        all_preds.extend(pred.cpu().numpy())
                        all_labels.extend(labels.cpu().numpy())

                        val_pbar.set_postfix({
                            'loss': loss.item(),
                            'acc': val_correct/val_total
                        })

                        del volumes, labels, recon, class_pred, mu, log_var
                        torch.cuda.empty_cache()

                    except RuntimeError as e:
                        if "out of memory" in str(e):
                            print("\nOOM during validation. Cleaning up...")
                            if 'volumes' in locals():
                                del volumes
                            if 'recon' in locals():
                                del recon
                            torch.cuda.empty_cache()
                            continue
                        raise e

            # Calculate epoch metrics
            avg_train_loss = train_loss / len(train_loader)
            avg_train_recon = train_recon / len(train_loader)
            avg_train_kl = train_kl / len(train_loader)
            avg_train_class = train_class / len(train_loader)
            train_acc = correct_preds / total_preds

            avg_val_loss = val_loss / len(val_loader)
            avg_val_recon = val_recon / len(val_loader)
            avg_val_kl = val_kl / len(val_loader)
            avg_val_class = val_class / len(val_loader)
            val_acc = val_correct / val_total

            # Update tracking metrics
            metrics['train_losses'].append(avg_train_loss)
            metrics['val_losses'].append(avg_val_loss)
            metrics['train_recon'].append(avg_train_recon)
            metrics['val_recon'].append(avg_val_recon)
            metrics['train_kl'].append(avg_train_kl)
            metrics['val_kl'].append(avg_val_kl)
            metrics['train_class'].append(avg_train_class)
            metrics['val_class'].append(avg_val_class)
            metrics['train_acc'].append(train_acc)
            metrics['val_acc'].append(val_acc)

            # Update learning rate
            scheduler.step(avg_val_loss)

            # Save checkpoint
            checkpoint_handler.save(model, optimizer, scheduler, epoch, metrics)

            # Print epoch summary
            print(f"\nEpoch {epoch+1}/{config.epochs}")
            print("Training Metrics:")
            print(f"Total Loss: {avg_train_loss:.6f}")
            print(f"Recon Loss: {avg_train_recon:.6f}")
            print(f"KL Loss: {avg_train_kl:.6f}")
            print(f"Class Loss: {avg_train_class:.6f}")
            print(f"Accuracy: {train_acc:.2%}")

            print("\nValidation Metrics:")
            print(f"Total Loss: {avg_val_loss:.6f}")
            print(f"Recon Loss: {avg_val_recon:.6f}")
            print(f"KL Loss: {avg_val_kl:.6f}")
            print(f"Class Loss: {avg_val_class:.6f}")
            print(f"Accuracy: {val_acc:.2%}")

            # Print classification report for validation set
            label_names = ['Control', 'PD', 'SWEDD']
            print("\nClassification Report:")
            print(classification_report(all_labels, all_preds,
                                     target_names=label_names))

            # Early stopping check
            if avg_val_loss < best_val_loss - config.min_delta:
                best_val_loss = avg_val_loss
                patience_counter = 0
                # Save best model
                torch.save(
                    model.state_dict(),
                    os.path.join(config.checkpoint_dir, f'{config.model_name}_best.pth')
                )
            else:
                patience_counter += 1
                if patience_counter >= config.patience:
                    print(f"\nEarly stopping triggered at epoch {epoch+1}")
                    break

            # Print memory stats
            print_gpu_memory_stats()

    except KeyboardInterrupt:
        print("\nTraining interrupted by user!")

    finally:
        # Plot training history
        plot_training_history(metrics)

    return metrics

def plot_training_history(metrics):
    """Plot training and validation metrics history."""
    plt.figure(figsize=(15, 12))

    # Plot total loss
    plt.subplot(3, 2, 1)
    plt.plot(metrics['train_losses'], label='Train Loss')
    plt.plot(metrics['val_losses'], label='Val Loss')
    plt.title('Total Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot reconstruction loss
    plt.subplot(3, 2, 2)
    plt.plot(metrics['train_recon'], label='Train Recon')
    plt.plot(metrics['val_recon'], label='Val Recon')
    plt.title('Reconstruction Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot KL divergence
    plt.subplot(3, 2, 3)
    plt.plot(metrics['train_kl'], label='Train KL')
    plt.plot(metrics['val_kl'], label='Val KL')
    plt.title('KL Divergence')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot classification loss
    plt.subplot(3, 2, 4)
    plt.plot(metrics['train_class'], label='Train Class')
    plt.plot(metrics['val_class'], label='Val Class')
    plt.title('Classification Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot accuracy
    plt.subplot(3, 2, 5)
    plt.plot(metrics['train_acc'], label='Train Acc')
    plt.plot(metrics['val_acc'], label='Val Acc')
    plt.title('Classification Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Cell 42: Model Evaluation
def evaluate_ssvae(model, val_loader, config=None):
    """Comprehensive model evaluation including reconstruction and classification metrics."""
    if config is None:
        config = SSVAEConfig()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    # Initialize metrics
    val_recon_loss = 0
    val_kl_loss = 0
    val_class_loss = 0
    all_preds = []
    all_labels = []
    reconstructions = []
    originals = []
    latent_vectors = []

    criterion = SSVAELoss(
        config.recon_weight,
        config.kl_weight,
        config.class_weight
    )

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Evaluating"):
            volumes = batch['volume'].to(device)
            labels = process_labels(batch['label']).to(device)

            recon, class_pred, mu, log_var = model(volumes)
            loss, recon_l, kl_l, class_l = criterion(
                recon, volumes, class_pred, labels, mu, log_var
            )

            val_recon_loss += recon_l.item()
            val_kl_loss += kl_l.item()
            val_class_loss += class_l.item()

            pred = class_pred.argmax(dim=1)
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Store latent vectors for visualization
            latent_vectors.append(mu.cpu().numpy())

            # Store some examples for visualization
            if len(reconstructions) < 5:
                reconstructions.append(recon.cpu().numpy())
                originals.append(volumes.cpu().numpy())

    # Calculate average losses
    avg_recon_loss = val_recon_loss / len(val_loader)
    avg_kl_loss = val_kl_loss / len(val_loader)
    avg_class_loss = val_class_loss / len(val_loader)

    # Print classification report
    label_names = ['Control', 'PD', 'SWEDD']
    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, target_names=label_names))

    # Plot confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_names,
                yticklabels=label_names)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

    # Visualize reconstructions
    visualize_reconstructions(originals, reconstructions, label_names,
                            [label_names[l] for l in all_labels[:5]])

    # Visualize latent space
    latent_vectors = np.concatenate(latent_vectors)
    visualize_latent_space(latent_vectors, all_labels, label_names)

    return {
        'recon_loss': avg_recon_loss,
        'kl_loss': avg_kl_loss,
        'class_loss': avg_class_loss,
        'predictions': all_preds,
        'true_labels': all_labels,
        'latent_vectors': latent_vectors
    }

def visualize_reconstructions(originals, reconstructions, label_names, true_labels):
    """Visualize original vs reconstructed volumes."""
    num_samples = len(originals)
    plt.figure(figsize=(15, 3*num_samples))

    for i in range(num_samples):
        orig = originals[i][0]
        recon = reconstructions[i][0]

        # Get middle slices
        orig_axial = orig[orig.shape[0]//2, :, :]
        orig_sagittal = orig[:, orig.shape[1]//2, :]
        orig_coronal = orig[:, :, orig.shape[2]//2]

        recon_axial = recon[recon.shape[0]//2, :, :]
        recon_sagittal = recon[:, recon.shape[1]//2, :]
        recon_coronal = recon[:, :, recon.shape[2]//2]

        # Plot original
        plt.subplot(num_samples, 6, i*6 + 1)
        plt.imshow(orig_axial, cmap='gray')
        plt.title(f'Original Axial\n{true_labels[i]}' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 2)
        plt.imshow(orig_sagittal, cmap='gray')
        plt.title('Original Sagittal' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 3)
        plt.imshow(orig_coronal, cmap='gray')
        plt.title('Original Coronal' if i == 0 else '')
        plt.axis('off')

        # Plot reconstruction
        plt.subplot(num_samples, 6, i*6 + 4)
        plt.imshow(recon_axial, cmap='gray')
        plt.title('Reconstructed Axial' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 5)
        plt.imshow(recon_sagittal, cmap='gray')
        plt.title('Reconstructed Sagittal' if i == 0 else '')
        plt.axis('off')

        plt.subplot(num_samples, 6, i*6 + 6)
        plt.imshow(recon_coronal, cmap='gray')
        plt.title('Reconstructed Coronal' if i == 0 else '')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

def visualize_latent_space(latent_vectors, labels, label_names):
    """Visualize latent space using dimensionality reduction."""
    # Reduce dimensionality using t-SNE
    tsne = TSNE(n_components=2, random_state=42)
    reduced_vecs = tsne.fit_transform(latent_vectors)

    # Create scatter plot
    plt.figure(figsize=(10, 8))
    for i, label in enumerate(np.unique(labels)):
        mask = labels == label
        plt.scatter(reduced_vecs[mask, 0], reduced_vecs[mask, 1],
                   label=label_names[label], alpha=0.6)

    plt.title('t-SNE Visualization of Latent Space')
    plt.xlabel('t-SNE Dimension 1')
    plt.ylabel('t-SNE Dimension 2')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Also visualize using PCA for comparison
    pca = PCA(n_components=2)
    pca_vecs = pca.fit_transform(latent_vectors)

    plt.figure(figsize=(10, 8))
    for i, label in enumerate(np.unique(labels)):
        mask = labels == label
        plt.scatter(pca_vecs[mask, 0], pca_vecs[mask, 1],
                   label=label_names[label], alpha=0.6)

    plt.title('PCA Visualization of Latent Space')
    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')
    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')
    plt.legend()
    plt.grid(True)
    plt.show()

# Cell 43: Smart Training Cell
from tqdm.notebook import tqdm  # Ensure we use the notebook version of tqdm
import torch
import os
from pathlib import Path

def initialize_training():
    """Initialize or resume training based on checkpoint existence."""
    config = SSVAEConfig()
    model = SSVAE(
        latent_dim=config.latent_dim,
        num_classes=config.num_classes
    )

    # Check for existing checkpoint
    checkpoint_path = Path(config.checkpoint_dir) / f"{config.model_name}_checkpoint.pth"
    if checkpoint_path.exists():
        print("\nFound existing checkpoint. Starting from checkpoint...")
    else:
        print("\nNo checkpoint found. Starting new training...")

    return model, config

def process_labels(labels):
    """Convert string labels to tensor indices."""
    label_map = {'Control': 0, 'PD': 1, 'SWEDD': 2}
    return torch.tensor([label_map[label] for label in labels])

def create_class_weights(dataloader):
    """Calculate class weights for balanced training."""
    print("Calculating class weights...")
    label_counts = torch.zeros(3)
    for batch in tqdm(dataloader, desc="Processing batches"):
        labels = process_labels(batch['label'])
        for label in labels:
            label_counts[label] += 1

    total = label_counts.sum()
    class_weights = total / (3 * label_counts)
    return class_weights

print("Initializing training process...")

# Initialize model and configuration
model, config = initialize_training()

# Calculate class weights
print("\nCalculating class weights for balanced training...")
class_weights = create_class_weights(train_loader)
print(f"\nClass weights:")
print(f"Control: {class_weights[0]:.2f}")
print(f"PD: {class_weights[1]:.2f}")
print(f"SWEDD: {class_weights[2]:.2f}")

# Move model to GPU and update loss function with class weights
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
class_weights = class_weights.to(device)

print("\nStarting training process...")
# Start training
metrics = train_ssvae(model, train_loader, val_loader, config)

print("\nTraining completed. Starting evaluation...")
# Run evaluation
evaluation_results = evaluate_ssvae(model, val_loader, config)
print("\nEvaluation completed. Results saved in 'evaluation_results'")

# Cell 44: Synthetic Data Generation
def generate_synthetic_samples(model, condition='PD', num_samples=5):
    """Generate synthetic brain scans by sampling from the latent space."""
    device = next(model.parameters()).device
    model.eval()

    # Get latent representations of real brains for the target condition
    real_vectors = []
    with torch.no_grad():
        for batch in val_loader:
            if len(real_vectors) >= 100:  # Collect up to 100 samples
                break

            volumes = batch['volume'].to(device)
            labels = process_labels(batch['label'])
            mask = labels == {'Control': 0, 'PD': 1, 'SWEDD': 2}[condition]

            if not mask.any():
                continue

            recon, _, mu, log_var = model(volumes[mask])
            real_vectors.append(mu.cpu().numpy())

    real_vectors = np.concatenate(real_vectors)

    # Fit a multivariate normal to the real vectors
    mu_vector = np.mean(real_vectors, axis=0)
    cov_matrix = np.cov(real_vectors.T)

    # Sample from the distribution
    synthetic_vectors = np.random.multivariate_normal(
        mu_vector,
        cov_matrix + 1e-6 * np.eye(cov_matrix.shape[0]),
        size=num_samples
    )

    # Generate images from the sampled vectors
    synthetic_vectors = torch.tensor(synthetic_vectors, dtype=torch.float32).to(device)
    with torch.no_grad():
        dummy_skip_connections = [
            torch.zeros(num_samples, 32, 64, 64, 64, device=device),
            torch.zeros(num_samples, 64, 32, 32, 32, device=device),
            torch.zeros(num_samples, 128, 16, 16, 16, device=device),
            torch.zeros(num_samples, 256, 8, 8, 8, device=device)
        ]
        synthetic_images = model.decoder(synthetic_vectors, dummy_skip_connections)

    # Visualize results
    plt.figure(figsize=(15, 3*num_samples))
    for i in range(num_samples):
        brain = synthetic_images[i, 0].cpu().numpy()

        # Get middle slices
        axial = brain[brain.shape[0]//2, :, :]
        sagittal = brain[:, brain.shape[1]//2, :]
        coronal = brain[:, :, brain.shape[2]//2]

        # Plot axial view
        plt.subplot(num_samples, 3, i*3 + 1)
        plt.imshow(axial, cmap='gray')
        plt.title(f'Synthetic {condition} - Axial' if i == 0 else '')
        plt.axis('off')

        # Plot sagittal view
        plt.subplot(num_samples, 3, i*3 + 2)
        plt.imshow(sagittal, cmap='gray')
        plt.title(f'Synthetic {condition} - Sagittal' if i == 0 else '')
        plt.axis('off')

        # Plot coronal view
        plt.subplot(num_samples, 3, i*3 + 3)
        plt.imshow(coronal, cmap='gray')
        plt.title(f'Synthetic {condition} - Coronal' if i == 0 else '')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

    return synthetic_images

# Example usage for synthetic data generation
if __name__ == "__main__":
    # Load trained model
    model, _ = load_trained_model('checkpoints', 'ssvae')
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Generate synthetic samples for each condition
    print("\nGenerating synthetic Control samples...")
    synthetic_control = generate_synthetic_samples(model, condition='Control')

    print("\nGenerating synthetic PD samples...")
    synthetic_pd = generate_synthetic_samples(model, condition='PD')

    print("\nGenerating synthetic SWEDD samples...")
    synthetic_swedd = generate_synthetic_samples(model, condition='SWEDD')

# Cell 45: Semi-Supervised Model Reconstruction and Evaluation
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
from tqdm.notebook import tqdm
from skimage.metrics import structural_similarity as ssim
from scipy.stats import entropy

def load_trained_ssvae(checkpoint_dir='checkpoints', model_name='ssvae'):
    """
    Load trained Semi-Supervised VAE model and associated metadata.
    """
    checkpoint_path = Path(checkpoint_dir) / f"{model_name}_checkpoint.pth"
    metadata_path = Path(checkpoint_dir) / f"{model_name}_metadata.json"

    if not checkpoint_path.exists():
        raise FileNotFoundError(f"No checkpoint found at {checkpoint_path}")

    # Initialize model
    model = SSVAE()
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # Load training history
    with open(metadata_path, 'r') as f:
        metadata = json.load(f)

    return model, metadata

def generate_reconstructions_with_uncertainty(model, val_loader, num_samples=5, mc_samples=10):
    """
    Generate reconstructions with uncertainty estimates using Monte Carlo sampling.
    """
    device = next(model.parameters()).device
    reconstructions = []
    uncertainties = []
    originals = []
    labels = []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Generating reconstructions"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']

            # Generate multiple reconstructions for each input
            batch_reconstructions = []
            for _ in range(mc_samples):
                recon, _, mu, log_var = model(volumes)
                batch_reconstructions.append(recon.cpu().numpy())

            # Calculate mean and variance of reconstructions
            batch_reconstructions = np.stack(batch_reconstructions)
            mean_recon = np.mean(batch_reconstructions, axis=0)
            uncertainty = np.std(batch_reconstructions, axis=0)

            # Store results
            reconstructions.extend(mean_recon)
            uncertainties.extend(uncertainty)
            originals.extend(volumes.cpu().numpy())
            labels.extend(batch_labels)

            if len(reconstructions) >= num_samples:
                break

    return (np.array(originals[:num_samples]),
            np.array(reconstructions[:num_samples]),
            np.array(uncertainties[:num_samples]),
            labels[:num_samples])

def compute_evaluation_metrics(original, reconstruction, uncertainty):
    """
    Compute various evaluation metrics for reconstruction quality.
    """
    metrics = {}

    # MSE
    mse = np.mean((original - reconstruction) ** 2)
    metrics['MSE'] = mse

    # SSIM (compute for middle slices)
    axial_ssim = ssim(original[original.shape[0]//2],
                      reconstruction[reconstruction.shape[0]//2])
    sagittal_ssim = ssim(original[:, original.shape[1]//2],
                         reconstruction[:, reconstruction.shape[1]//2])
    coronal_ssim = ssim(original[:, :, original.shape[2]//2],
                        reconstruction[:, :, reconstruction.shape[2]//2])
    metrics['SSIM'] = {
        'axial': axial_ssim,
        'sagittal': sagittal_ssim,
        'coronal': coronal_ssim
    }

    # Uncertainty statistics
    metrics['Uncertainty'] = {
        'mean': np.mean(uncertainty),
        'std': np.std(uncertainty),
        'max': np.max(uncertainty)
    }

    return metrics

def visualize_reconstructions_with_uncertainty(originals, reconstructions, uncertainties, labels):
    """
    Visualize original, reconstructed, and uncertainty maps for each sample.
    """
    num_samples = len(originals)
    plt.figure(figsize=(20, 5*num_samples))

    for idx in range(num_samples):
        orig = originals[idx, 0]
        recon = reconstructions[idx, 0]
        uncert = uncertainties[idx, 0]

        # Get middle slices
        slices_orig = [
            orig[orig.shape[0]//2, :, :],
            orig[:, orig.shape[1]//2, :],
            orig[:, :, orig.shape[2]//2]
        ]
        slices_recon = [
            recon[recon.shape[0]//2, :, :],
            recon[:, recon.shape[1]//2, :],
            recon[:, :, recon.shape[2]//2]
        ]
        slices_uncert = [
            uncert[uncert.shape[0]//2, :, :],
            uncert[:, uncert.shape[1]//2, :],
            uncert[:, :, uncert.shape[2]//2]
        ]

        views = ['Axial', 'Sagittal', 'Coronal']

        for i, (view, orig_slice, recon_slice, uncert_slice) in enumerate(zip(
            views, slices_orig, slices_recon, slices_uncert)):

            # Original
            plt.subplot(num_samples, 9, idx*9 + i*3 + 1)
            plt.imshow(orig_slice, cmap='gray')
            if idx == 0:
                plt.title(f'Original {view}')
            if i == 0:
                plt.ylabel(f'Sample {idx+1}\n({labels[idx]})')
            plt.axis('off')

            # Reconstruction
            plt.subplot(num_samples, 9, idx*9 + i*3 + 2)
            plt.imshow(recon_slice, cmap='gray')
            if idx == 0:
                plt.title(f'Reconstructed {view}')
            plt.axis('off')

            # Uncertainty
            plt.subplot(num_samples, 9, idx*9 + i*3 + 3)
            plt.imshow(uncert_slice, cmap='viridis')
            if idx == 0:
                plt.title(f'Uncertainty {view}')
            plt.colorbar()
            plt.axis('off')

        # Compute and display metrics
        metrics = compute_evaluation_metrics(orig, recon, uncert)
        print(f"\nMetrics for Sample {idx+1} ({labels[idx]}):")
        print(f"MSE: {metrics['MSE']:.6f}")
        print(f"SSIM (Axial): {metrics['SSIM']['axial']:.6f}")
        print(f"SSIM (Sagittal): {metrics['SSIM']['sagittal']:.6f}")
        print(f"SSIM (Coronal): {metrics['SSIM']['coronal']:.6f}")
        print(f"Mean Uncertainty: {metrics['Uncertainty']['mean']:.6f}")

    plt.tight_layout()
    plt.show()

# Run the evaluation
if __name__ == "__main__":
    try:
        print("Loading trained Semi-Supervised VAE model...")
        model, metadata = load_trained_ssvae()
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        print("\nGenerating reconstructions with uncertainty estimates...")
        originals, reconstructions, uncertainties, labels = generate_reconstructions_with_uncertainty(
            model, val_loader, num_samples=5
        )

        print("\nVisualizing reconstructions and uncertainty maps...")
        visualize_reconstructions_with_uncertainty(
            originals, reconstructions, uncertainties, labels
        )

    except Exception as e:
        print(f"Error during evaluation: {str(e)}")
        import traceback
        traceback.print_exc()

# Cell 46: Region-based Uncertainty Analysis
def analyze_regional_uncertainty(originals, reconstructions, uncertainties, labels):
    """
    Analyze uncertainty patterns in different brain regions.
    """
    # Define regions of interest (approximate coordinates for DaTSCAN)
    regions = {
        'Left Striatum': (slice(54, 74), slice(54, 74), slice(44, 64)),
        'Right Striatum': (slice(54, 74), slice(54, 74), slice(64, 84)),
        'Background': (slice(0, 20), slice(0, 20), slice(0, 20))
    }

    region_metrics = {region: [] for region in regions}

    for idx in range(len(originals)):
        orig = originals[idx, 0]
        recon = reconstructions[idx, 0]
        uncert = uncertainties[idx, 0]

        for region_name, coords in regions.items():
            # Extract regional data
            orig_region = orig[coords]
            recon_region = recon[coords]
            uncert_region = uncert[coords]

            # Compute metrics
            metrics = {
                'mse': np.mean((orig_region - recon_region) ** 2),
                'mean_uncertainty': np.mean(uncert_region),
                'max_uncertainty': np.max(uncert_region),
                'uncertainty_std': np.std(uncert_region)
            }
            region_metrics[region_name].append(metrics)

    # Plot regional analysis
    plt.figure(figsize=(15, 5))

    # MSE by region
    plt.subplot(131)
    boxplot_data = [[metrics['mse'] for metrics in region_metrics[region]]
                    for region in regions]
    plt.boxplot(boxplot_data, labels=regions.keys())
    plt.title('MSE by Region')
    plt.xticks(rotation=45)
    plt.ylabel('MSE')

    # Mean uncertainty by region
    plt.subplot(132)
    boxplot_data = [[metrics['mean_uncertainty'] for metrics in region_metrics[region]]
                    for region in regions]
    plt.boxplot(boxplot_data, labels=regions.keys())
    plt.title('Mean Uncertainty by Region')
    plt.xticks(rotation=45)
    plt.ylabel('Mean Uncertainty')

    # Max uncertainty by region
    plt.subplot(133)
    boxplot_data = [[metrics['max_uncertainty'] for metrics in region_metrics[region]]
                    for region in regions]
    plt.boxplot(boxplot_data, labels=regions.keys())
    plt.title('Max Uncertainty by Region')
    plt.xticks(rotation=45)
    plt.ylabel('Max Uncertainty')

    plt.tight_layout()
    plt.show()

    # Print summary statistics
    print("\nRegional Analysis Summary:")
    for region in regions:
        metrics = region_metrics[region]
        print(f"\n{region}:")
        print(f"Mean MSE: {np.mean([m['mse'] for m in metrics]):.6f}")
        print(f"Mean Uncertainty: {np.mean([m['mean_uncertainty'] for m in metrics]):.6f}")
        print(f"Max Uncertainty: {np.mean([m['max_uncertainty'] for m in metrics]):.6f}")

# Run the regional analysis
if __name__ == "__main__":
    try:
        print("\nPerforming region-based uncertainty analysis...")
        analyze_regional_uncertainty(originals, reconstructions, uncertainties, labels)
    except Exception as e:
        print(f"Error during regional analysis: {str(e)}")
        traceback.print_exc()

