<architecture>
    <introduction>
        The objective of this project is to validate and test various unsupervised models for latent space representation of Dopamine Transporter Imaging (DATSCAN) in Parkinson's Disease. By leveraging unsupervised learning techniques, the goal is to uncover intrinsic patterns and features within the imaging data that could enhance the understanding of Parkinson's Disease progression.
    </introduction>
    <data_understanding>
        <data_sources>
            <source_1>
                <name>Parkinson's Progression Markers Initiative (PPMI)</name>
                <description>The PPMI dataset is a large, multicenter study that aims to identify biomarkers of Parkinson's Disease progression.</description>
                <link>https://www.ppmi-info.org/</link>
            </source_1>
        </data_sources>
        <dataset_description>
            <dicom_structure>
                The dataset is organized in a nested structure, as follows:
                - **Images Folder**: Contains three subfolders:
                    - **PPMI_Images_PD**: Folder for PD images.
                    - **PPMI_Images_SWEDD**: Folder for SWEDD images.
                    - **PPMI_Images_Cont**: Folder for Control images.
                - **Patient ID Folder**: Each patient has a unique numerical code as the folder name.
                - **Reconstructed_DaTSCAN Folder**: A folder named "Reconstructed_DaTSCAN".
                - **Exam Date Folders**: Each exam is stored in a folder named with the format `YYYY_MM_DD_hh_mm_ss.v` (Year, Month, Day, Hours, Minutes, Seconds, Version).
                - **Exam Identifier Folder**: Named with `I<exam_code>`, for example, `I123456`.
                - **DICOM File**: The image file, named like `S<some_numbers>_I<some_numbers>.dcm`.
            </dicom_structure>
            <example_path>
                Images/PPMI_Images_PD/3000/Reconstructed_DaTSCAN/2011-01-20_16_28_47.0/I323662/PPMI_3000_NM_Reconstructed_DaTSCAN_Br_20120814154829508_1_S117534_I323662.dcm
            </example_path>
        </dataset_description>
    </data_understanding>
    <ingestion_and_preprocessing>
        <data_loading>
            Develop a script to recursively traverse the nested folder structure to locate all DICOM files. Use libraries like pydicom to read DICOM files into NumPy arrays.
        </data_loading>
        <data_preprocessing>
            - Intensity Normalization: 
                - Set minimum to 0
                - Truncate negative values
                - Normalize pixel intensities using min-max scaling
            - Volume Processing:
                - Maintain full 128x128x128 brain volume
                - Preserve all anatomical information including striatum and surrounding regions
                - Apply consistent processing across the entire volume
            - Dimension Standardization:
                - Target shape: (128, 128, 128)
                - Preserve aspect ratio using zero-padding instead of stretching
                - Apply padding symmetrically around the brain region
            - Brain Masking:
                - Apply threshold-based brain masks to focus on brain tissue
                - Remove non-brain regions while preserving anatomical proportions
            - Data Validation:
                - Verify volume integrity and proper padding
                - Confirm intensity normalization effectiveness
                - Validate anatomical preservation
        </data_preprocessing>
    </ingestion_and_preprocessing>
    <eda>
        <statistical_analysis>
            - Descriptive Statistics: Compute mean, median, standard deviation, and other summary statistics for the dataset.
            - Distribution Analysis: 
                - Examine the distribution of pixel intensities and voxel values
                - Analyze variance distribution across the full volume
                - Special focus on striatal region characteristics
            - Correlation Analysis: Investigate relationships between different regions of the brain.
        </statistical_analysis>
        <visualization>
            - Image Visualization:
                - Display sample volumes to understand data quality and variability
                - Visualize padding and aspect ratio preservation
                - Show full brain volume characteristics
            - Variance Analysis:
                - Plot variance distributions across all dimensions
                - Identify regions of high information content
                - Map intensity patterns across the volume
            - Quality Control:
                - Visualize preprocessing steps' impact
                - Verify anatomical preservation
                - Confirm proper padding implementation
        </visualization>
    </eda>
    <model>
        <selection>
            <unsupervised_models>
                - Autoencoders: Train deep autoencoders to learn latent representations of the imaging data.
                - Variational Autoencoders (VAEs): Utilize VAEs to model the underlying distribution of the data.
                - Generative Adversarial Networks (GANs): Explore Deep Convolutional GANs for generating synthetic images and learning latent features.
                - Principal Component Analysis (PCA): Apply PCA for dimensionality reduction and feature extraction.
                - t-Distributed Stochastic Neighbor Embedding (t-SNE): Use t-SNE for visualizing high-dimensional data in 2D or 3D space.
                - UMAP: Employ Uniform Manifold Approximation and Projection (UMAP) for nonlinear dimensionality reduction.
            </unsupervised_models>
            <model_architecture>
                - Input Layer: 
                    - Shape: (1, 128, 128, 128) for full brain volumes
                    - Single channel grayscale images
                    - Zero-padded to maintain aspect ratio
                - Encoder:
                    - Convolutional layers with stride 2 for downsampling
                    - Residual connections for better gradient flow
                    - Batch normalization and ReLU activation
                    - Self-attention mechanism for spatial relationships
                - Latent Space:
                    - Dense bottleneck layer
                    - Reparameterization for VAE
                    - Size optimized for reconstruction quality
                - Decoder:
                    - Mirror encoder architecture
                    - Transposed convolutions for upsampling
                    - Batch normalization and ReLU activation
                    - Final sigmoid activation for intensity scaling
            </model_architecture>
        </selection>
        <training>
            - Training Setup: 
                - Use frameworks like TensorFlow or PyTorch
                - Leverage GPU acceleration on NVIDIA 4070Ti
                - Implement memory-efficient batch processing
            - Hyperparameters:
                - Batch size optimized for GPU memory (2-4 for full volumes)
                - Learning rate with scheduling
                - KL divergence weight annealing
            - Optimization:
                - Adam optimizer with weight decay
                - Gradient clipping for stability
                - Early stopping based on validation loss
            - Memory Management:
                - Efficient data loading with proper memory pinning
                - GPU memory monitoring and optimization
                - Batch size adjustment based on available resources
        </training>
        <evaluation>
            - Reconstruction Error:
                - Mean Squared Error for image fidelity
                - Structural Similarity Index (SSIM)
                - Analysis across full brain volume
            - Latent Space Analysis:
                - Visualization using dimensionality reduction
                - Cluster analysis for patient groups
                - Feature importance in the latent space
            - Clinical Relevance:
                - Correlation with disease progression
                - Group separation analysis
                - Feature interpretability
                - Special attention to striatal region patterns
        </evaluation>
    </model>
    <workflow_pipeline>
        <data_pipeline>
            Step 1: Data loading and preprocessing of full brain volumes
            Step 2: EDA with emphasis on whole-brain analysis
        </data_pipeline>
        <model_pipeline>
            Step 3: Define model architectures for 128Â³ volumes
            Step 4: Training scripts with memory optimization
            Step 5: Evaluation scripts for comprehensive analysis
        </model_pipeline>
        <results_pipeline>
            Step 6: Aggregation of results across models
            Step 7: Reporting tools for findings documentation
        </results_pipeline>
    </workflow_pipeline>
</architecture>