# -*- coding: utf-8 -*-
"""Project_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zkbb1EDlzyb3Th4K0IOr--4MKPeUN-z5

# Setup
"""

# Cell 1: Install dependencies
# Uncomment and run the following command if dependencies are not already installed.
# %pip install scikit-learn scikit-image SimpleITK nibabel nilearn albumentations seaborn pandas numpy matplotlib tqdm pydicom scipy
# %pip install umap-learn

# CUDA verification
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
    print(f"CUDA device capability: {torch.cuda.get_device_capability(0)}")

# Cell 2: Import statements and environment setup
import torch

def configure_gpu():
    """
    Configures GPU settings:
    - Detects CUDA device
    - Enables CUDNN benchmarking for improved performance on NVIDIA 4070Ti
    """
    if torch.cuda.is_available():
        device = torch.device("cuda")
        # Enable CUDNN benchmark for optimized convolution algorithm selection
        torch.backends.cudnn.benchmark = True
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
    else:
        raise EnvironmentError("CUDA-compatible GPU not found. Please check your GPU configuration.")

def print_gpu_memory_stats():
    """
    Prints current GPU memory usage for monitoring.
    """
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024 ** 2)
        reserved = torch.cuda.memory_reserved() / (1024 ** 2)
        print(f"GPU Memory Allocated: {allocated:.2f} MB")
        print(f"GPU Memory Reserved: {reserved:.2f} MB")
    else:
        print("CUDA not available.")

# Configure GPU on startup
configure_gpu()
print_gpu_memory_stats()

import warnings
warnings.filterwarnings('ignore')

# Cell 3: GPU Setup and Memory Management
import os
import logging
import warnings
import pandas as pd

# Configure logging for quality assurance (logs will be written to data_ingestion.log)
logging.basicConfig(level=logging.INFO, filename="data_ingestion.log", filemode="w",
                    format="%(asctime)s - %(levelname)s - %(message)s")

def collect_files(base_dir):
    """
    Recursively collects DICOM files only from the expected folders:
    - PPMI_Images_PD: Label "PD"
    - PPMI_Images_SWEDD: Label "SWEDD"
    - PPMI_Images_Cont: Label "Control"

    Excludes any file containing "br_raw" in its path and logs all skipped folders.

    :param base_dir: Base directory containing the Images folder.
    :return: (included_files, excluded_files)
             included_files: list of tuples (full_path, label)
             excluded_files: list of file paths that were excluded.
    """
    included_files = []
    excluded_files = []

    # Define the expected folders and corresponding labels
    expected_folders = {
        "PPMI_Images_PD": "PD",
        "PPMI_Images_SWEDD": "SWEDD",
        "PPMI_Images_Cont": "Control"
    }

    # Iterate over immediate subdirectories in base_dir
    for folder in os.listdir(base_dir):
        folder_path = os.path.join(base_dir, folder)
        if os.path.isdir(folder_path) and folder in expected_folders:
            logging.info(f"Processing folder: {folder_path}")
            # Recursively traverse the expected folder
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    if file.endswith(".dcm"):
                        full_path = os.path.join(root, file)
                        # Exclude any file with "br_raw" in its full path
                        if "br_raw" in full_path:
                            excluded_files.append(full_path)
                            logging.info(f"Excluding raw file: {full_path}")
                        else:
                            included_files.append((full_path, expected_folders[folder]))
        else:
            logging.info(f"Skipping folder: {folder_path}")

    return included_files, excluded_files

def generate_dataframe(included_files):
    """
    Creates a DataFrame from the list of validated file paths.

    :param included_files: List of tuples (file_path, label)
    :return: DataFrame with columns 'file_path' and 'label'
    """
    df = pd.DataFrame(included_files, columns=["file_path", "label"])
    return df

def save_qa_report(total_files, included_count, excluded_count, output_path="data_ingestion_QA_report.csv"):
    """
    Generates and saves a QA report of the file collection process.

    :param total_files: Total number of DICOM files encountered.
    :param included_count: Count of files included after filtering.
    :param excluded_count: Count of files excluded.
    :param output_path: File path for the QA report CSV.
    """
    exclusion_ratio = excluded_count / total_files if total_files > 0 else 0
    qa_report = {
        "total_files": total_files,
        "included_files": included_count,
        "excluded_files": excluded_count,
        "exclusion_ratio": exclusion_ratio,
    }
    qa_df = pd.DataFrame([qa_report])
    qa_df.to_csv(output_path, index=False)
    logging.info("QA report saved to %s", output_path)

    if exclusion_ratio > 0.5:
        warnings.warn(f"High proportion of raw files excluded: {exclusion_ratio:.2%}")

"""## Data Ingestion"""

# !pip install pydicom
# !pip install nibabel

# Cell 4: Data Ingestion Pipeline
import pydicom
import numpy as np

def load_dicom(file_path):
    """
    Loads and processes a DICOM file:
    - Reads the file using pydicom.
    - Converts the pixel array to float32.
    - Applies RescaleSlope and RescaleIntercept if available.

    :param file_path: Path to the DICOM file.
    :return: Tuple (processed_pixel_array, dicom_metadata)
    """
    try:
        ds = pydicom.dcmread(file_path)
    except Exception as e:
        raise IOError(f"Error reading DICOM file {file_path}: {e}")

    # Extract pixel array and convert to float32
    pixel_array = ds.pixel_array.astype(np.float32)

    # Apply rescaling if attributes are present
    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):
        slope = ds.RescaleSlope
        intercept = ds.RescaleIntercept
        pixel_array = pixel_array * slope + intercept

    return pixel_array, ds

# Cell 5: Execute Data Ingestion Pipeline
# Define the base directory containing the "Images" folder (adjust if necessary)
base_dir = "Images"

# Collect files from only the expected subdirectories
included_files, excluded_files = collect_files(base_dir)

# Create a DataFrame for the validated file paths and their labels
df = generate_dataframe(included_files)

# Final validation: Ensure that no "br_raw" files are included
if df["file_path"].str.contains("br_raw").any():
    raise ValueError("Validation failed: 'br_raw' files detected in the final dataset!")

# Save the validated file paths to CSV for reproducibility
df.to_csv("validated_file_paths.csv", index=False)
print("Validated file paths saved to validated_file_paths.csv")

# Generate and save the QA report
total_files = len(included_files) + len(excluded_files)
save_qa_report(total_files, len(included_files), len(excluded_files))
print("QA report generated and saved as data_ingestion_QA_report.csv")

"""## Data Visualization"""

# Cell 6: Visualize One Axial, Coronal, and Sagittal Slice for a Random Patient per Group

import pandas as pd
import random
import matplotlib.pyplot as plt
import numpy as np
import nibabel as nib

# Read the validated file paths CSV generated earlier
df = pd.read_csv("validated_file_paths.csv")

# Function to extract the three orthogonal slices from a 3D volume
def extract_slices(volume):
    """
    Given a 3D volume, returns one axial, one coronal, and one sagittal slice.
    Assumes volume shape is (depth, height, width).
    """
    d, h, w = volume.shape
    axial = volume[32, :, :]         # Axial: slice along depth
    coronal = volume[:, 50, :]        # Coronal: slice along height
    sagittal = volume[:, :, 55]       # Sagittal: slice along width
    return axial, coronal, sagittal

# List of groups and their expected labels
groups = {"PD": "PD", "SWEDD": "SWEDD", "Control": "Control"}
maskH = nib.load('rmask_ICV.nii')
mask = maskH.get_fdata()>0.5
mask = np.transpose(mask,[2, 1, 0])
mask = np.flip(mask,axis=1)
# Create a figure with one row per group and three columns for the views
fig, axes = plt.subplots(nrows=len(groups), ncols=3, figsize=(12, 4 * len(groups)))
fig.suptitle("Axial, Coronal, and Sagittal Slices for a Random Patient per Group", fontsize=16)

for i, (group_key, group_label) in enumerate(groups.items()):
    # Filter DataFrame for the current group
    group_df = df[df["label"] == group_label]
    if group_df.empty:
        print(f"No data found for group {group_label}")
        continue

    # Select a random file from the group
    random_file = group_df.sample(1)["file_path"].values[0]
    print(f"Loading file for group {group_label}: {random_file}")

    # Load the DICOM volume using the previously defined load_dicom() function
    volume, _ = load_dicom(random_file)

    # Verify the volume is 3D (if not, skip or raise an error)
    if volume.ndim != 3:
        raise ValueError(f"Expected 3D volume, got shape {volume.shape} for file: {random_file}")

    axial, coronal, sagittal = extract_slices(volume)

    # Plot Axial slice
    ax = axes[i, 0]
    ax.imshow(axial, cmap="gray")
    ax.set_title(f"{group_label} - Axial")
    ax.axis("off")

    # Plot Coronal slice
    ax = axes[i, 1]
    ax.imshow(coronal, cmap="gray")
    ax.set_title(f"{group_label} - Coronal")
    ax.axis("off")

    # Plot Sagittal slice
    ax = axes[i, 2]
    ax.imshow(sagittal, cmap="gray")
    ax.set_title(f"{group_label} - Sagittal")
    ax.axis("off")

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""## Data Preprocessing

### Intensity Normalization and Volume Preprocessing

### Brain Masking
"""

#!pip install scikit-image

# Cell 7: Data Preprocessing – Brain Masking

import numpy as np
import matplotlib.pyplot as plt
from skimage.filters import threshold_otsu
from skimage.morphology import binary_closing, ball

def resize_volume(volume, target_shape=(64, 128, 128)):
    """
    Resizes the volume to the target shape using zero-padding or center cropping.

    Args:
        volume: Input 3D volume as numpy array with shape (d, h, w)
        target_shape: Desired output shape as tuple (d_new, h_new, w_new)

    Returns:
        Resized volume with shape target_shape
    """
    def get_pad_amounts(current_size, target_size):
        """Helper to calculate padding amounts"""
        if current_size >= target_size:
            return 0, 0
        diff = target_size - current_size
        pad_before = diff // 2
        pad_after = diff - pad_before
        return pad_before, pad_after

    current_shape = volume.shape
    resized = volume.copy()

    # Calculate padding/cropping for each dimension
    pads = [get_pad_amounts(current_shape[i], target_shape[i]) for i in range(3)]

    # Apply padding if needed
    if any(sum(p) > 0 for p in pads):
        resized = np.pad(
            resized,
            pad_width=pads,
            mode="constant",
            constant_values=0
        )

    # Apply cropping if needed
    for i in range(3):
        if current_shape[i] > target_shape[i]:
            # Calculate slicing indices
            start = (current_shape[i] - target_shape[i]) // 2
            end = start + target_shape[i]
            # Apply slice
            if i == 0:
                resized = resized[start:end, :, :]
            elif i == 1:
                resized = resized[:, start:end, :]
            else:
                resized = resized[:, :, start:end]

    return resized

def process_volume(volume, target_shape=(64, 128, 128)):
    """
    Process a 3D volume by:
    1. Normalizing intensity (truncating negatives and min-max scaling)
    2. Resizing to target_shape
    3. Generating a brain mask via Otsu thresholding and morphological closing

    Args:
        volume: Input 3D volume
        target_shape: Desired output shape (depth, height, width)

    Returns:
        norm_vol: Normalized and resized volume
        mask: Brain mask
        masked_vol: Masked volume
    """
    # 1. Intensity normalization
    # volume = np.clip(volume, a_min=0, a_max=None)
    # vmin, vmax = volume.min(), volume.max()
    # if vmax > vmin:
    #     norm_vol = (volume - vmin) / (vmax - vmin)
    # else:
    #     norm_vol = volume - vmin


    # 2. Resize the normalized volume
    norm_vol = resize_volume(volume-volume.min(), target_shape=target_shape)
    mask = np.zeros((64,128,128),dtype=bool)
    mask[20:40,82:103,43:82]=1
    norm_vol /= np.mean(norm_vol[mask])

    # 3. Compute brain mask
    thresh = threshold_otsu(norm_vol)
    mask = norm_vol > thresh
    mask = binary_closing(mask, footprint=ball(2))
    masked_vol = norm_vol * mask

    return norm_vol, mask, masked_vol

# Demonstration: Load one sample DICOM file (using the first file in your validated DataFrame)
sample_file = df.iloc[0]["file_path"]
original_volume, _ = load_dicom(sample_file)
original_volume = original_volume[9:73,:,:]

# Process the volume with our new function
norm_vol, mask, masked_vol = process_volume(original_volume, target_shape=(64,128,128))

print(original_volume.shape)
print(norm_vol.shape)

# Extract an axial (middle) slice from both the normalized volume and the masked volume
axial_norm = norm_vol[norm_vol.shape[0]//2, :, :]
axial_masked = masked_vol[masked_vol.shape[0]//2, :, :]

# Plot side-by-side for comparison
fig, axes = plt.subplots(1, 2, figsize=(12, 6))
axes[0].imshow(axial_norm, cmap="gray")
axes[0].set_title("Normalized Axial Slice")
axes[0].axis("off")

axes[1].imshow(axial_masked, cmap="gray")
axes[1].set_title("Masked Axial Slice")
axes[1].axis("off")

plt.tight_layout()
plt.show()

# Cell 8: Data Preprocessing – Visualization (heatmap)
plt.imshow(norm_vol[32,:,:])
plt.colorbar()

"""## Dataloader Creation (with Shape Validation)"""

# !pip install ipywidgets

# Cell 9: Dataset Implementation with GPU Memory Management
import torch
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import gc
import numpy as np
import os
import psutil
import time
from sklearn.model_selection import train_test_split

def print_memory_stats():
    """Print memory usage statistics"""
    if torch.cuda.is_available():
        print("\nGPU Memory Usage:")
        print(f"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        print(f"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")
    print(f"CPU Memory Usage: {psutil.Process().memory_info().rss / 1024**2:.2f} MB")

class OnDemandDataset(Dataset):
    """
    Memory-efficient dataset that loads volumes on demand rather than all at once
    """
    def __init__(self, dataframe, transform=None):
        self.df = dataframe
        self.transform = transform

        # Load mask once
        try:
            maskH = nib.load('rmask_ICV.nii')
            self.mask = maskH.get_fdata() > 0.5
            self.mask = np.transpose(self.mask, [2, 1, 0])
            self.mask = np.flip(self.mask, axis=1)
            print("✅ Brain mask loaded successfully")
        except Exception as e:
            print(f"⚠️ Warning: Could not load brain mask: {e}")
            print("⚠️ Creating a dummy mask instead")
            self.mask = np.ones((128, 128, 128), dtype=bool)

        # Verify all paths exist
        missing_files = []
        for idx, row in dataframe.iterrows():
            if not os.path.exists(row["file_path"]):
                missing_files.append(row["file_path"])

        if missing_files:
            print(f"⚠️ Warning: {len(missing_files)} files not found!")
            print(f"First few missing files: {missing_files[:3]}")
        else:
            print(f"✅ All {len(dataframe)} file paths are valid")

    def __len__(self):
        """Return the total number of samples in the dataset"""
        return len(self.df)

    def __getitem__(self, idx):
        """Load a single volume on demand"""
        try:
            # Get file path
            file_path = self.df.iloc[idx]["file_path"]

            # Load and process volume
            volume, _ = load_dicom(file_path)

            # Apply mask
            volume -= volume.min()
            volume = volume * self.mask

            # Apply processing
            norm_vol, _, _ = process_volume(volume[9:73, :, :], target_shape=(64, 128, 128))

            # Convert to tensor
            volume_tensor = torch.from_numpy(np.expand_dims(norm_vol, axis=0)).float()

            return {
                "volume": volume_tensor,
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }
        except Exception as e:
            print(f"Error processing file {self.df.iloc[idx]['file_path']}: {e}")
            # Return a zero tensor as fallback
            return {
                "volume": torch.zeros((1, 64, 128, 128), dtype=torch.float32),
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }

class BatchLoadDataset(Dataset):
    """
    Memory-efficient dataset that processes data in small batches
    and caches the processed results
    """
    def __init__(self, dataframe, batch_size=32, transform=None):
        self.df = dataframe
        self.transform = transform
        self.data_cache = {}  # Cache for processed data

        # Load mask once
        try:
            maskH = nib.load('rmask_ICV.nii')
            self.mask = maskH.get_fdata() > 0.5
            self.mask = np.transpose(self.mask, [2, 1, 0])
            self.mask = np.flip(self.mask, axis=1)
            print("✅ Brain mask loaded successfully")
        except Exception as e:
            print(f"⚠️ Warning: Could not load brain mask: {e}")
            print("⚠️ Creating a dummy mask instead")
            self.mask = np.ones((128, 128, 128), dtype=bool)

        # Pre-process data in batches to avoid memory issues
        total_batches = (len(dataframe) + batch_size - 1) // batch_size
        print(f"Pre-processing {len(dataframe)} samples in {total_batches} batches...")

        for batch_idx in tqdm(range(total_batches)):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(dataframe))

            for idx in range(start_idx, end_idx):
                try:
                    file_path = dataframe.iloc[idx]["file_path"]

                    # Load DICOM
                    volume, _ = load_dicom(file_path)
                    volume -= volume.min()
                    volume = volume * self.mask

                    # Process volume
                    norm_vol, _, _ = process_volume(volume[9:73, :, :], target_shape=(64, 128, 128))

                    # Store in cache (using index as key)
                    self.data_cache[idx] = norm_vol

                except Exception as e:
                    print(f"Error processing file {dataframe.iloc[idx]['file_path']}: {e}")
                    self.data_cache[idx] = np.zeros((64, 128, 128), dtype=np.float32)

            # Force garbage collection after each batch
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # Print memory stats every few batches
            if batch_idx % 5 == 0:
                print_memory_stats()

        print("✅ Data pre-processing complete")

    def __len__(self):
        """Return the total number of samples in the dataset"""
        return len(self.df)

    def __getitem__(self, idx):
        """Get a cached pre-processed volume"""
        try:
            # Get the pre-processed volume from cache
            norm_vol = self.data_cache[idx]

            # Convert to tensor
            volume_tensor = torch.from_numpy(np.expand_dims(norm_vol, axis=0)).float()

            return {
                "volume": volume_tensor,
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }
        except Exception as e:
            print(f"Error retrieving item {idx}: {e}")
            # Return a zero tensor as fallback
            return {
                "volume": torch.zeros((1, 64, 128, 128), dtype=torch.float32),
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }

def create_dataloaders(df, batch_size=4, train_split=0.8, on_demand=True):
    """Create train and validation dataloaders with stratified split"""
    # Stratified split to maintain group distributions
    train_df, val_df = train_test_split(
        df,
        test_size=1-train_split,
        stratify=df['label'],
        random_state=42
    )

    print("\nTraining set distribution:")
    print(train_df['label'].value_counts())
    print("\nValidation set distribution:")
    print(val_df['label'].value_counts())

    # Create datasets with appropriate strategy
    if on_demand:
        print("Using on-demand data loading strategy (lighter on memory but slower)")
        train_dataset = OnDemandDataset(train_df)
        val_dataset = OnDemandDataset(val_df)
    else:
        print("Using batch pre-processing strategy (faster but more memory intensive)")
        train_dataset = BatchLoadDataset(train_df)
        val_dataset = BatchLoadDataset(val_df)

    # Create dataloaders with optimized settings
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,  # Reduced from 6 to prevent hanging
        pin_memory=True,
        persistent_workers=False  # Changed from True to avoid memory issues
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,  # Reduced from 6 to prevent hanging
        pin_memory=True,
        persistent_workers=False  # Changed from True to avoid memory issues
    )

    return train_loader, val_loader

# Test the dataloader with a small batch
if __name__ == "__main__":
    print("Testing dataloader with small batch...")
    start_time = time.time()

    # Create dataloaders with a smaller batch size for testing
    train_loader, val_loader = create_dataloaders(df, batch_size=2, on_demand=True)

    # Try to load a single batch
    print("Fetching a single batch...")
    for batch in train_loader:
        print(f"Batch loaded successfully!")
        print(f"Batch shape: {batch['volume'].shape}")
        print(f"Labels: {batch['label']}")
        break

    print(f"Dataloader test completed in {time.time() - start_time:.2f} seconds")
    print_memory_stats()

"""# Exploratory Data Analysis (EDA)"""

# !pip install seaborn

# Cell 10: Optimized EDA Implementation with Stratified Sampling
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tqdm import tqdm
from collections import defaultdict
import torch
import time
import gc
import random

def create_memory_efficient_dataloaders(df, batch_size=2, train_split=0.8):
    """
    Create train and validation dataloaders with optimized memory usage
    """
    # Reuse the create_dataloaders function from Cell 9
    return create_dataloaders(df, batch_size=batch_size, train_split=train_split, on_demand=True)

def analyze_dataset_statistics_efficiently(dataloader, max_samples=100, min_samples_per_group=15):
    """
    Analyzes dataset statistics with improved memory efficiency and ensures
    stratified sampling across all patient groups.

    Args:
        dataloader: The dataloader to sample from
        max_samples: Maximum total samples to process
        min_samples_per_group: Minimum samples to collect per group

    Returns:
        Dictionary of statistical measures with proper group representation
    """
    print("Analyzing dataset statistics (stratified, memory-efficient version)...")
    stats = defaultdict(list)
    samples_by_group = defaultdict(int)

    # First pass: Count occurrences of each group
    group_counts = {}
    print("Scanning dataset to count groups...")
    for batch in tqdm(dataloader, desc="Counting groups"):
        labels = batch['label']
        for label in labels:
            if label not in group_counts:
                group_counts[label] = 0
            group_counts[label] += 1

    print(f"Found groups: {group_counts}")

    # Second pass: Collect samples with stratification
    all_samples = []
    all_labels = []
    all_paths = []

    try:
        print("Collecting stratified samples...")
        for batch in tqdm(dataloader, desc="Collecting samples"):
            volumes = batch['volume']
            labels = batch['label']
            paths = batch['path']

            # Process each volume in the batch
            for vol_idx, (volume, label, path) in enumerate(zip(volumes, labels, paths)):
                # If we have enough samples from this group, skip unless we need more total samples
                if (samples_by_group[label] >= min_samples_per_group and
                    sum(samples_by_group.values()) >= max_samples):
                    continue

                # Add this sample
                all_samples.append(volume)
                all_labels.append(label)
                all_paths.append(path)
                samples_by_group[label] += 1

            # Memory cleanup after each batch
            del volumes, labels, paths
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # Check if we've collected enough samples from each group
            if all(samples_by_group[group] >= min_samples_per_group for group in group_counts):
                if sum(samples_by_group.values()) >= max_samples:
                    print(f"Collected sufficient samples from all groups")
                    break

    except Exception as e:
        print(f"Error during sample collection: {str(e)}")
        import traceback
        traceback.print_exc()

    # Process collected samples
    print(f"Processing {len(all_samples)} collected samples...")
    print(f"Samples per group: {dict(samples_by_group)}")

    for volume, label, path in zip(all_samples, all_labels, all_paths):
        # Extract statistics
        vol_data = volume.numpy().flatten()

        # Compute statistics
        stats['mean'].append(float(np.mean(vol_data)))
        stats['std'].append(float(np.std(vol_data)))
        stats['min'].append(float(np.min(vol_data)))
        stats['max'].append(float(np.max(vol_data)))
        stats['label'].append(label)
        stats['path'].append(path)

    # Convert to DataFrame for easier analysis
    stats_df = pd.DataFrame(stats)
    print(f"Successfully analyzed {len(stats_df)} samples")

    # Verify group representation
    group_dist = stats_df['label'].value_counts()
    print("Group distribution in analyzed samples:")
    print(group_dist)

    return stats_df

def plot_intensity_distributions(stats_df):
    """
    Creates violin plots of intensity distributions by group
    """
    plt.figure(figsize=(15, 6))

    # Plot intensity distributions
    plt.subplot(1, 2, 1)
    sns.violinplot(data=stats_df, x='label', y='mean', palette='viridis')
    plt.title('Distribution of Mean Intensities by Group')
    plt.xlabel('Group')
    plt.ylabel('Mean Intensity')
    plt.xticks(rotation=45)

    plt.subplot(1, 2, 2)
    sns.violinplot(data=stats_df, x='label', y='std', palette='viridis')
    plt.title('Distribution of Intensity Standard Deviations by Group')
    plt.xlabel('Group')
    plt.ylabel('Standard Deviation')
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.show()

def plot_group_statistics(stats_df):
    """
    Plots statistical summaries by group using lightweight operations
    """
    plt.figure(figsize=(15, 5))

    # Group counts
    plt.subplot(1, 3, 1)
    group_counts = stats_df['label'].value_counts()
    sns.barplot(x=group_counts.index, y=group_counts.values, palette='viridis')
    plt.title('Sample Count by Group')
    plt.xlabel('Group')
    plt.ylabel('Count')
    plt.xticks(rotation=45)

    # Box plots - more memory efficient than complex plots
    plt.subplot(1, 3, 2)
    sns.boxplot(data=stats_df, x='label', y='mean', palette='viridis')
    plt.title('Mean Intensity Distribution')
    plt.xlabel('Group')
    plt.ylabel('Mean Intensity')
    plt.xticks(rotation=45)

    # Simple boxplot instead of violin plot
    plt.subplot(1, 3, 3)
    sns.boxplot(data=stats_df, x='label', y='std', palette='viridis')
    plt.title('Intensity Variance Distribution')
    plt.xlabel('Group')
    plt.ylabel('Standard Deviation')
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.show()

def visualize_sample_slices(stats_df, dataloader, samples_per_group=1):
    """
    Visualizes a limited number of samples from each group
    with efficient memory handling, selecting from the pre-processed samples.
    Shows anatomically interesting slices (axial=32, coronal=50, sagittal=55 and 70)
    instead of central slices.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Get unique groups
    groups = stats_df['label'].unique()

    # Dictionary to hold samples for each group
    samples_data = {}

    # Select paths from stats_df, stratified by group
    selected_paths = {}
    for group in groups:
        group_paths = stats_df[stats_df['label'] == group]['path'].values
        if len(group_paths) > 0:
            selected_paths[group] = random.sample(list(group_paths),
                                                min(samples_per_group, len(group_paths)))

    # Find these samples in the dataloader
    for batch in dataloader:
        volumes = batch['volume']
        paths = batch['path']
        labels = batch['label']

        for i, (vol, path, label) in enumerate(zip(volumes, paths, labels)):
            # Check if this path is in our selected paths
            for group, group_paths in selected_paths.items():
                if path in group_paths:
                    # Store the sample
                    key = f"{group}_{len(samples_data)}"
                    samples_data[key] = vol.cpu().numpy()
                    # Remove from selected_paths to avoid duplicates
                    selected_paths[group].remove(path)

        # Check if we have all samples
        if all(len(paths) == 0 for paths in selected_paths.values()):
            break

    # Define anatomically interesting slices
    axial_slice_idx = 32      # Axial view - slice 32
    coronal_slice_idx = 50    # Coronal view - slice 50
    sagittal_slice1_idx = 55  # Sagittal view - slice 55
    sagittal_slice2_idx = 70  # Sagittal view - slice 70

    # Visualize the samples
    num_groups = len(groups)
    plt.figure(figsize=(20, 5 * num_groups))  # Wider figure to accommodate 4 slices

    for i, (key, vol) in enumerate(samples_data.items()):
        # Extract label
        label = key.split('_')[0]

        # Get anatomically interesting slices
        vol = vol.squeeze()  # Remove channel dimension
        axial_slice = vol[axial_slice_idx, :, :]
        coronal_slice = vol[:, coronal_slice_idx, :]
        sagittal_slice1 = vol[:, :, sagittal_slice1_idx]
        sagittal_slice2 = vol[:, :, sagittal_slice2_idx]

        # Plot slices (now 4 slices per row)
        plt.subplot(len(samples_data), 4, i*4 + 1)
        plt.imshow(axial_slice, cmap='gray')
        plt.title(f'{label} - Axial (z={axial_slice_idx})')
        plt.axis('off')

        plt.subplot(len(samples_data), 4, i*4 + 2)
        plt.imshow(coronal_slice, cmap='gray')
        plt.title(f'{label} - Coronal (y={coronal_slice_idx})')
        plt.axis('off')

        plt.subplot(len(samples_data), 4, i*4 + 3)
        plt.imshow(sagittal_slice1, cmap='gray')
        plt.title(f'{label} - Sagittal1 (x={sagittal_slice1_idx})')
        plt.axis('off')

        plt.subplot(len(samples_data), 4, i*4 + 4)
        plt.imshow(sagittal_slice2, cmap='gray')
        plt.title(f'{label} - Sagittal2 (x={sagittal_slice2_idx})')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Run optimized EDA
if __name__ == "__main__":
    start_time = time.time()
    print("Starting Memory-Efficient EDA with Stratified Sampling...")

    # Create dataloaders with small batch size
    print("\nCreating memory-efficient dataloaders...")
    train_loader, val_loader = create_memory_efficient_dataloaders(df, batch_size=2)

    # Analyze with stratified sampling and more samples
    print("\nAnalyzing training dataset (with stratification)...")
    train_stats = analyze_dataset_statistics_efficiently(
        train_loader,
        max_samples=100,  # Increased from 50 to 100
        min_samples_per_group=15  # Ensure at least 15 samples per group
    )

    # Plot distributions and statistics
    print("\nPlotting intensity distributions...")
    plot_intensity_distributions(train_stats)

    print("\nPlotting group statistics...")
    plot_group_statistics(train_stats)

    # Visualize a few examples
    print("\nVisualizing example slices...")
    visualize_sample_slices(train_stats, train_loader, samples_per_group=1)

    # Print summary statistics by group
    print("\nSummary Statistics by Group:")
    summary_stats = train_stats.groupby('label').agg({
        'mean': ['mean', 'std'],
        'std': ['mean', 'std'],
        'min': ['mean', 'std'],
        'max': ['mean', 'std']
    }).round(3)
    print(summary_stats)

    # Memory cleanup
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    print(f"\nEDA completed in {time.time() - start_time:.2f} seconds!")
    print_memory_stats()

"""### Slice Intensity Variance Analysis"""

def analyze_slice_variance(dataloader, num_samples_per_group=5):
    """
    Analyzes slice-wise variance across different views for each patient group
    """
    print("Analyzing slice-wise variance patterns...")

    # Initialize storage for variances
    group_variances = {
        'PD': {'axial': [], 'coronal': [], 'sagittal': []},
        'Control': {'axial': [], 'coronal': [], 'sagittal': []},
        'SWEDD': {'axial': [], 'coronal': [], 'sagittal': []}
    }
    sample_counts = {'PD': 0, 'Control': 0, 'SWEDD': 0}

    try:
        for batch in tqdm(dataloader, desc="Computing slice variances"):
            volumes = batch['volume']
            labels = batch['label']

            for volume, label in zip(volumes, labels):
                label = label if isinstance(label, str) else label.item()

                if sample_counts[label] >= num_samples_per_group:
                    continue

                # Get volume data
                vol_data = volume.squeeze().numpy()
                d, h, w = vol_data.shape

                # Compute variance for each slice in each view
                axial_var = [np.var(vol_data[i, :, :]) for i in range(d)]
                coronal_var = [np.var(vol_data[:, i, :]) for i in range(h)]
                sagittal_var = [np.var(vol_data[:, :, i]) for i in range(w)]

                # Store variances
                group_variances[label]['axial'].append(axial_var)
                group_variances[label]['coronal'].append(coronal_var)
                group_variances[label]['sagittal'].append(sagittal_var)

                sample_counts[label] += 1

            # Check if we have enough samples from each group
            if all(count >= num_samples_per_group for count in sample_counts.values()):
                break

            # Memory cleanup
            del volumes, labels
            gc.collect()
            torch.cuda.empty_cache()

    except Exception as e:
        print(f"Error during variance analysis: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

    # Compute average variances across samples for each group
    avg_variances = {}
    for group in group_variances:
        avg_variances[group] = {
            view: np.mean(variances, axis=0)
            for view, variances in group_variances[group].items()
        }

    return avg_variances

# Plot the slice variance results
def plot_slice_variances(avg_variances):
    """
    Creates line plots for slice-wise variance analysis
    """
    views = ['axial', 'coronal', 'sagittal']
    fig, axes = plt.subplots(1, 3, figsize=(20, 6))

    for idx, view in enumerate(views):
        ax = axes[idx]

        for group in avg_variances:
            variances = avg_variances[group][view]
            ax.plot(range(len(variances)), variances, label=group)

        ax.set_title(f'{view.capitalize()} View - Slice-wise Variance')
        ax.set_xlabel('Slice Index')
        ax.set_ylabel('Average Variance')
        ax.legend()
        ax.grid(True)

    plt.tight_layout()
    plt.show()

# Analyze slice-wise variance
print("\nAnalyzing slice-wise variance patterns...")
avg_variances = analyze_slice_variance(train_loader, num_samples_per_group=5)

if avg_variances is not None:
    print("\nPlotting slice-wise variance analysis...")
    plot_slice_variances(avg_variances)

"""# Model Phase

## 1. Autoencoder

### Model Setup
"""

# Cell 11: Optimized Autoencoder with Memory Management
import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict

class ConvBlock(nn.Module):
    """Memory-efficient convolutional block with batch normalization and ReLU activation."""
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.block = nn.Sequential(OrderedDict([
            ('conv', nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)),
            ('bn', nn.BatchNorm3d(out_channels)),
            ('relu', nn.ReLU(inplace=True))  # inplace ReLU for memory efficiency
        ]))

    def forward(self, x):
        return self.block(x)

class Encoder(nn.Module):
    """3D Encoder network optimized for 64×128×128 input volumes."""
    def __init__(self, latent_dim=256):
        super().__init__()

        # Initial feature extraction
        self.init_conv = ConvBlock(1, 16)  # (1, 64, 128, 128) -> (16, 64, 128, 128)

        # Downsampling path with progressive channel increase
        self.down1 = nn.Sequential(
            ConvBlock(16, 32, stride=2),    # -> (32, 32, 64, 64)
            ConvBlock(32, 32)               # -> (32, 32, 64, 64)
        )

        self.down2 = nn.Sequential(
            ConvBlock(32, 64, stride=2),    # -> (64, 16, 32, 32)
            ConvBlock(64, 64)               # -> (64, 16, 32, 32)
        )

        self.down3 = nn.Sequential(
            ConvBlock(64, 128, stride=2),   # -> (128, 8, 16, 16)
            ConvBlock(128, 128)             # -> (128, 8, 16, 16)
        )

        self.down4 = nn.Sequential(
            ConvBlock(128, 256, stride=2),  # -> (256, 4, 8, 8)
            ConvBlock(256, 256)             # -> (256, 4, 8, 8)
        )

        # Project to latent space
        self.flatten_size = 256 * 4 * 8 * 8
        self.fc = nn.Linear(self.flatten_size, latent_dim)

    def forward(self, x):
        x = self.init_conv(x)
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)

        # Flatten and project to latent space
        flat = torch.flatten(d4, start_dim=1)
        z = self.fc(flat)

        return z

class Decoder(nn.Module):
    """3D Decoder network optimized for 64×128×128 output volumes."""
    def __init__(self, latent_dim=256):
        super().__init__()

        self.flatten_size = 256 * 4 * 8 * 8
        self.fc = nn.Linear(latent_dim, self.flatten_size)

        # Upsampling path
        self.up1 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(256, 128),
            ConvBlock(128, 128)
        )

        self.up2 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(128, 64),
            ConvBlock(64, 64)
        )

        self.up3 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(64, 32),
            ConvBlock(32, 32)
        )

        self.up4 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(32, 16),
            ConvBlock(16, 16)
        )

        # Final convolution
        self.final_conv = nn.Conv3d(16, 1, kernel_size=1)

    def forward(self, z):
        # Reshape from latent space
        x = self.fc(z)
        x = x.view(-1, 256, 4, 8, 8)

        # Upsampling
        x = self.up1(x)
        x = self.up2(x)
        x = self.up3(x)
        x = self.up4(x)

        # Final convolution
        x = self.final_conv(x)

        return x

class BaseAutoencoder(nn.Module):
    """Memory-optimized 3D Autoencoder for 64×128×128 medical volumes."""
    def __init__(self, latent_dim=256):
        super().__init__()
        self.encoder = Encoder(latent_dim)
        self.decoder = Decoder(latent_dim)

    def forward(self, x):
        z = self.encoder(x)
        reconstruction = self.decoder(z)
        return reconstruction

    def encode(self, x):
        """Encode input to latent space"""
        z = self.encoder(x)
        return z

    def decode(self, z):
        """Decode from latent space (for generation)"""
        return self.decoder(z)

# Memory and GPU test function
def test_autoencoder(batch_size=2):
    """Test the autoencoder with dummy data and verify memory usage."""
    print("\nTesting Autoencoder Architecture...")

    try:
        # Create model and move to GPU
        model = BaseAutoencoder(latent_dim=256)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        # Print model summary
        num_params = sum(p.numel() for p in model.parameters())
        print(f"\nModel Parameters: {num_params:,}")

        # Create dummy input (64x128x128 volume)
        dummy_input = torch.randn(batch_size, 1, 64, 128, 128, device=device)

        # Print initial memory usage
        print("\nInitial GPU Memory Usage:")
        print_memory_stats()

        # Test encoding
        print("\nTesting encoder...")
        with torch.no_grad():
            latent = model.encode(dummy_input)
        print(f"Input shape: {dummy_input.shape}")
        print(f"Latent shape: {latent.shape}")

        # Test full forward pass
        print("\nTesting forward pass...")
        with torch.no_grad():
            output = model(dummy_input)

        # Print output shape and final memory usage
        print(f"Output shape: {output.shape}")
        print("\nFinal GPU Memory Usage:")
        print_memory_stats()

        # Verify shapes
        assert output.shape == dummy_input.shape, f"Shape mismatch: {output.shape} vs {dummy_input.shape}"

        # Clean up
        del model, dummy_input, output, latent
        torch.cuda.empty_cache()

        print("\nAutoencoder test completed successfully!")
        return True

    except Exception as e:
        print(f"Error testing autoencoder: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

# Run test if this cell is executed
if __name__ == "__main__":
    test_autoencoder(batch_size=2)

# Cell 12: Training Configuration and Utilities
import os
import json
import time
from pathlib import Path
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torch.cuda.amp as amp
import math

class TrainingConfig:
    """Training configuration optimized for NVIDIA 4070Ti"""
    def __init__(self, **kwargs):
        # Model parameters
        self.latent_dim = kwargs.get('latent_dim', 256)

        # Training parameters
        self.learning_rate = kwargs.get('learning_rate', 1e-4)
        self.batch_size = kwargs.get('batch_size', 4)
        self.accumulation_steps = kwargs.get('accumulation_steps', 4)
        self.epochs = kwargs.get('epochs', 100)
        self.early_stopping_patience = kwargs.get('early_stopping_patience', 10)

        # Optimization
        self.use_mixed_precision = kwargs.get('use_mixed_precision', True)
        self.weight_decay = kwargs.get('weight_decay', 1e-5)
        self.gradient_clip = kwargs.get('gradient_clip', 1.0)

        # Dataloader parameters
        self.num_workers = kwargs.get('num_workers', 2)
        self.pin_memory = kwargs.get('pin_memory', True)

        # Checkpoint parameters
        self.checkpoint_dir = kwargs.get('checkpoint_dir', 'checkpoints')
        self.model_name = kwargs.get('model_name', 'autoencoder')
        self.save_interval = kwargs.get('save_interval', 5)

        # Create checkpoint directory
        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)

        # Print configuration summary
        print(f"\n{'='*50}")
        print(f"TRAINING CONFIGURATION")
        print(f"{'='*50}")
        print(f"Model: {self.model_name} with latent dim {self.latent_dim}")
        print(f"Batch size: {self.batch_size} × {self.accumulation_steps} steps = {self.batch_size * self.accumulation_steps} effective")
        print(f"Learning rate: {self.learning_rate}")
        print(f"Mixed precision: {'Enabled' if self.use_mixed_precision else 'Disabled'}")
        print(f"Epochs: {self.epochs} with patience {self.early_stopping_patience}")
        print(f"Dataloader workers: {self.num_workers}")
        print(f"Checkpoints saved to: {self.checkpoint_dir}")
        print(f"{'='*50}\n")

class EarlyStopping:
    """Early stopping handler with patience"""
    def __init__(self, patience=10, min_delta=0, verbose=True):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')
        self.early_stop = False
        self.verbose = verbose
        self.best_epoch = 0

    def __call__(self, val_loss, epoch):
        if val_loss < self.best_loss - self.min_delta:
            if self.verbose:
                improvement = self.best_loss - val_loss
                print(f"Validation loss improved by {improvement:.6f}")
            self.best_loss = val_loss
            self.counter = 0
            self.best_epoch = epoch
            return True  # Model improved
        else:
            self.counter += 1
            if self.verbose:
                print(f"Early stopping counter: {self.counter}/{self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print(f"Early stopping triggered. Best epoch was {self.best_epoch}.")
            return False  # Model didn't improve

class CheckpointHandler:
    """Handles saving and loading of model checkpoints"""
    def __init__(self, checkpoint_dir, model_name):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.model_name = model_name
        self.checkpoint_path = self.checkpoint_dir / f"{model_name}_checkpoint.pth"
        self.best_model_path = self.checkpoint_dir / f"{model_name}_best.pth"
        self.metadata_path = self.checkpoint_dir / f"{model_name}_metadata.json"

        # Ensure directory exists
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

    def save(self, model, optimizer, scheduler, epoch, train_losses, val_losses, is_best=False):
        """Save model checkpoint and training metadata"""
        # Save model checkpoint
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'train_losses': train_losses,
            'val_losses': val_losses
        }

        # Always save latest checkpoint
        torch.save(checkpoint, self.checkpoint_path)

        # Save best model separately if this is the best model
        if is_best:
            torch.save(model.state_dict(), self.best_model_path)
            print(f"Saved best model to {self.best_model_path}")

        # Save metadata
        metadata = {
            'last_epoch': epoch,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(self.metadata_path, 'w') as f:
            json.dump(metadata, f, indent=4)

    def load(self, model, optimizer=None, scheduler=None, device=None):
        """Load model checkpoint and return training metadata"""
        if not self.checkpoint_path.exists():
            print(f"No checkpoint found at {self.checkpoint_path}")
            return None

        if device is None:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Load checkpoint
        checkpoint = torch.load(self.checkpoint_path, map_location=device)

        # Load model state
        model.load_state_dict(checkpoint['model_state_dict'])

        # Optionally load optimizer and scheduler states
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        if scheduler is not None and checkpoint['scheduler_state_dict'] is not None:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        print(f"Loaded checkpoint from epoch {checkpoint['epoch']}")

        return {
            'epoch': checkpoint['epoch'],
            'train_losses': checkpoint['train_losses'],
            'val_losses': checkpoint['val_losses']
        }

def create_optimizer(model, config):
    """Create optimizer with weight decay and parameter grouping"""
    # Separate parameters that should have weight decay from those that shouldn't
    decay_params = []
    no_decay_params = []

    for name, param in model.named_parameters():
        if 'bias' in name or 'bn' in name:
            no_decay_params.append(param)
        else:
            decay_params.append(param)

    # Create parameter groups
    param_groups = [
        {'params': decay_params, 'weight_decay': config.weight_decay},
        {'params': no_decay_params, 'weight_decay': 0.0}
    ]

    # Create optimizer
    optimizer = optim.AdamW(param_groups, lr=config.learning_rate)

    return optimizer

def create_scheduler(optimizer, config):
    """Create learning rate scheduler"""
    return ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=5,
        verbose=True,
        min_lr=1e-6
    )

def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, min_lr=0.0, last_epoch=-1):
    """Create a cosine learning rate schedule with warmup"""
    def lr_lambda(current_step):
        # Warmup
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))

        # Cosine decay
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        factor = 0.5 * (1.0 + math.cos(math.pi * progress))
        return max(min_lr, factor)

    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch)

# Test configuration if this cell is executed
if __name__ == "__main__":
    config = TrainingConfig(
        latent_dim=256,
        batch_size=2,
        accumulation_steps=8,
        learning_rate=1e-4,
        epochs=100,
        model_name="autoencoder_test"
    )

    model = BaseAutoencoder(config.latent_dim)
    optimizer = create_optimizer(model, config)
    scheduler = create_scheduler(optimizer, config)

    print("Configuration and utilities loaded successfully!")

# Cell 13: Training Loop Implementation
import torch
import torch.nn as nn
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import gc
import time

def train_autoencoder(model, train_loader, val_loader, config=None):
    """Optimized training loop with GPU memory management and progress tracking"""
    if config is None:
        config = TrainingConfig()

    # Set up device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Initialize components
    criterion = nn.MSELoss()
    optimizer = create_optimizer(model, config)
    scheduler = create_scheduler(optimizer, config)
    early_stopping = EarlyStopping(patience=config.early_stopping_patience)
    checkpoint_handler = CheckpointHandler(config.checkpoint_dir, config.model_name)

    # Mixed precision setup
    scaler = amp.GradScaler(enabled=config.use_mixed_precision)

    # Training tracking variables
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    start_time = time.time()

    # Load checkpoint if available
    start_epoch = 0
    checkpoint_data = checkpoint_handler.load(model, optimizer, scheduler, device)
    if checkpoint_data:
        start_epoch = checkpoint_data['epoch'] + 1
        train_losses = checkpoint_data['train_losses']
        val_losses = checkpoint_data['val_losses']
        print(f"Resuming training from epoch {start_epoch}")

    # Calculate total steps for progress tracking
    total_steps = len(train_loader) * config.epochs

    # Training loop
    try:
        # Create progress bar for total training
        total_pbar = tqdm(total=total_steps, desc="Total Progress", position=0)
        total_pbar.update(start_epoch * len(train_loader))

        for epoch in range(start_epoch, config.epochs):
            # Training phase
            model.train()
            epoch_loss = 0
            optimizer.zero_grad()  # Zero gradients at epoch start

            train_pbar = tqdm(train_loader,
                            desc=f'Epoch {epoch+1}/{config.epochs} [Train]',
                            leave=False,
                            position=1)

            for batch_idx, batch in enumerate(train_pbar):
                try:
                    # Move data to device
                    volumes = batch['volume'].to(device, non_blocking=True)

                    # Mixed precision forward pass
                    with amp.autocast(enabled=config.use_mixed_precision):
                        reconstructed = model(volumes)
                        loss = criterion(reconstructed, volumes)
                        # Scale loss by accumulation steps
                        loss = loss / config.accumulation_steps

                    # Mixed precision backward pass
                    scaler.scale(loss).backward()

                    # Gradient accumulation
                    if (batch_idx + 1) % config.accumulation_steps == 0 or (batch_idx + 1 == len(train_loader)):
                        # Clip gradients to prevent exploding gradients
                        if config.gradient_clip > 0:
                            scaler.unscale_(optimizer)
                            torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)

                        # Update weights
                        scaler.step(optimizer)
                        scaler.update()
                        optimizer.zero_grad()

                    # Track loss (using the non-scaled loss for reporting)
                    batch_loss = loss.item() * config.accumulation_steps
                    epoch_loss += batch_loss

                    # Update progress bars
                    train_pbar.set_postfix({'loss': f"{batch_loss:.6f}"})
                    total_pbar.update(1)

                    # Memory cleanup
                    del volumes, reconstructed, loss
                    torch.cuda.empty_cache()

                except RuntimeError as e:
                    if "out of memory" in str(e):
                        print(f"\nOOM in batch {batch_idx}. Cleaning up...")
                        torch.cuda.empty_cache()
                        gc.collect()
                        # Skip this batch and continue
                        continue
                    raise e

            # Calculate average training loss
            avg_train_loss = epoch_loss / len(train_loader)
            train_losses.append(avg_train_loss)

            # Validation phase
            model.eval()
            val_loss = 0

            val_pbar = tqdm(val_loader,
                          desc=f'Epoch {epoch+1}/{config.epochs} [Val]',
                          leave=False,
                          position=1)

            with torch.no_grad():
                for batch in val_pbar:
                    try:
                        volumes = batch['volume'].to(device)
                        reconstructed = model(volumes)
                        loss = criterion(reconstructed, volumes)
                        val_loss += loss.item()

                        val_pbar.set_postfix({'loss': f"{loss.item():.6f}"})

                        # Memory cleanup
                        del volumes, reconstructed, loss
                        torch.cuda.empty_cache()

                    except RuntimeError as e:
                        if "out of memory" in str(e):
                            print("\nOOM during validation. Cleaning up...")
                            torch.cuda.empty_cache()
                            gc.collect()
                            continue
                        raise e

            # Calculate average validation loss
            avg_val_loss = val_loss / len(val_loader)
            val_losses.append(avg_val_loss)

            # Update learning rate
            scheduler.step(avg_val_loss)

            # Check if this is the best model
            is_best = avg_val_loss < best_val_loss
            if is_best:
                best_val_loss = avg_val_loss

            # Save checkpoint
            if (epoch + 1) % config.save_interval == 0 or is_best or (epoch + 1 == config.epochs):
                checkpoint_handler.save(
                    model, optimizer, scheduler,
                    epoch, train_losses, val_losses,
                    is_best=is_best
                )

            # Print epoch summary
            elapsed_time = time.time() - start_time
            time_per_epoch = elapsed_time / (epoch - start_epoch + 1) if epoch >= start_epoch else 0
            est_time_left = time_per_epoch * (config.epochs - epoch - 1)

            print(f"\nEpoch {epoch+1}/{config.epochs} completed in {time_per_epoch:.2f}s")
            print(f"Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}")
            print(f"Learning rate: {optimizer.param_groups[0]['lr']:.8f}")
            print(f"Est. time remaining: {est_time_left/60:.2f} minutes")
            print_memory_stats()

            # Early stopping check
            if early_stopping(avg_val_loss, epoch):
                if early_stopping.early_stop:
                    print("\nEarly stopping triggered!")
                    break

    except KeyboardInterrupt:
        print("\nTraining interrupted by user!")
        # Still save the model
        checkpoint_handler.save(
            model, optimizer, scheduler,
            epoch, train_losses, val_losses,
            is_best=False
        )

    finally:
        # Close progress bars
        if 'total_pbar' in locals():
            total_pbar.close()

        # Plot training history
        plt.figure(figsize=(12, 5))

        # Plot full history
        plt.subplot(1, 2, 1)
        plt.plot(train_losses, label='Train Loss')
        plt.plot(val_losses, label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Full Training History')
        plt.legend()
        plt.grid(True)

        # Plot recent history (last 30 epochs or full history if < 30 epochs)
        plt.subplot(1, 2, 2)
        recent = min(30, len(train_losses))
        if recent > 5:  # Only plot recent if we have enough epochs
            plt.plot(train_losses[-recent:], label='Train Loss')
            plt.plot(val_losses[-recent:], label='Validation Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Last {recent} Epochs')
            plt.legend()
            plt.grid(True)

        plt.tight_layout()
        plt.savefig(os.path.join(config.checkpoint_dir, f"{config.model_name}_training_history.png"))
        plt.show()

        # Print final training summary
        total_time = time.time() - start_time
        print(f"\nTraining completed in {total_time/60:.2f} minutes")
        print(f"Best validation loss: {best_val_loss:.6f}")

        return train_losses, val_losses, model

"""### Training"""

# Run training if this cell is executed
if __name__ == "__main__":

    # Initialize model
    model = BaseAutoencoder(latent_dim=256)

    # Create configuration
    config = TrainingConfig(
    latent_dim=256,
    batch_size=8,              # Increased from 2 to 8
    accumulation_steps=8,      # Increased from 4 to 8 (effective batch size = 64)
    learning_rate=1e-4,
    epochs=200,
    early_stopping_patience=10,
    use_mixed_precision=True,
    num_workers=4,             # Increased from 2 to 4
    model_name="autoencoder_v1"
)

    # Train model
    print("\nStarting training...")
    train_losses, val_losses, trained_model = train_autoencoder(
        model, train_loader, val_loader, config
    )

"""### Evaluation and Result Visualization"""

# Cell 14: Updated Autoencoder Evaluation with Anatomical Slices
import torch
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import json
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import seaborn as sns
from tqdm import tqdm

def load_trained_model(checkpoint_dir, model_name, latent_dim=256):
    """Load best trained model for evaluation"""
    model_path = Path(checkpoint_dir) / f"{model_name}_best.pth"
    metadata_path = Path(checkpoint_dir) / f"{model_name}_metadata.json"

    if not model_path.exists():
        # Try loading checkpoint if best model doesn't exist
        model_path = Path(checkpoint_dir) / f"{model_name}_checkpoint.pth"
        if not model_path.exists():
            raise FileNotFoundError(f"No model found at {model_path}")

        # Load from checkpoint
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = BaseAutoencoder(latent_dim=latent_dim)
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        # Load best model
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = BaseAutoencoder(latent_dim=latent_dim)
        model.load_state_dict(torch.load(model_path, map_location=device))

    # Load training history
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
    else:
        metadata = {"train_losses": [], "val_losses": []}

    model.eval()
    model.to(device)

    return model, metadata

def plot_training_history(metadata):
    """Plot training and validation loss history"""
    plt.figure(figsize=(12, 5))

    train_losses = metadata["train_losses"]
    val_losses = metadata["val_losses"]

    # Plot full history
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Full Training History')
    plt.legend()
    plt.grid(True)

    # Plot recent history (last 30 epochs or all if < 30)
    plt.subplot(1, 2, 2)
    recent = min(30, len(train_losses))
    if recent > 5:  # Only plot recent history if we have enough epochs
        plt.plot(train_losses[-recent:], label='Train Loss')
        plt.plot(val_losses[-recent:], label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title(f'Last {recent} Epochs')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.show()

def visualize_reconstruction_samples(model, dataloader, num_samples=3):
    """Visualize original vs reconstructed volumes for samples from the dataset using anatomically relevant slices"""
    device = next(model.parameters()).device

    # Get samples from dataloader
    samples = []
    labels = []

    for batch in dataloader:
        volumes = batch['volume']
        batch_labels = batch['label']

        for i in range(min(len(volumes), num_samples - len(samples))):
            samples.append(volumes[i:i+1])
            labels.append(batch_labels[i])

        if len(samples) >= num_samples:
            break

    # Visualize each sample
    with torch.no_grad():
        for idx, (sample, label) in enumerate(zip(samples, labels)):
            # Get original volume
            orig_vol = sample.to(device)

            # Generate reconstruction
            reconstructed = model(orig_vol)

            # Move to CPU for visualization
            orig_vol = orig_vol.cpu().squeeze().numpy()
            recon_vol = reconstructed.cpu().squeeze().numpy()

            # Create figure for this sample
            fig = plt.figure(figsize=(16, 12))
            plt.suptitle(f"Sample {idx+1} - Group: {label}", fontsize=16)

            # Define anatomically relevant slices
            axial_slice = 32      # Axial view - slice 32
            coronal_slice = 50    # Coronal view - slice 50
            sagittal_slice1 = 55  # Sagittal view - slice 55
            sagittal_slice2 = 70  # Sagittal view - slice 70

            # Plot original slices - top row
            plt.subplot(2, 4, 1)
            plt.imshow(orig_vol[axial_slice], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Axial (z={axial_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 2)
            plt.imshow(orig_vol[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Coronal (y={coronal_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 3)
            plt.imshow(orig_vol[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Sagittal (x={sagittal_slice1})")
            plt.axis('off')

            plt.subplot(2, 4, 4)
            plt.imshow(orig_vol[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Sagittal (x={sagittal_slice2})")
            plt.axis('off')

            # Plot reconstructed slices - bottom row
            plt.subplot(2, 4, 5)
            plt.imshow(recon_vol[axial_slice], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Axial (z={axial_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 6)
            plt.imshow(recon_vol[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Coronal (y={coronal_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 7)
            plt.imshow(recon_vol[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Sagittal (x={sagittal_slice1})")
            plt.axis('off')

            plt.subplot(2, 4, 8)
            plt.imshow(recon_vol[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Sagittal (x={sagittal_slice2})")
            plt.axis('off')

            plt.tight_layout()
            plt.show()

def compute_reconstruction_error(model, dataloader):
    """Compute detailed reconstruction error metrics on validation set"""
    device = next(model.parameters()).device
    criterion = nn.MSELoss(reduction='none')

    total_mse = 0
    total_samples = 0
    error_by_label = {}

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Computing metrics"):
            volumes = batch['volume'].to(device)
            labels = batch['label']

            # Get reconstructions
            reconstructed = model(volumes)

            # Compute MSE loss per sample
            mse = criterion(reconstructed, volumes)

            # Average over dimensions
            mse = mse.mean(dim=(1, 2, 3, 4)).cpu().numpy()

            # Track overall error
            total_mse += mse.sum()
            total_samples += volumes.shape[0]

            # Track error by label
            for i, label in enumerate(labels):
                if label not in error_by_label:
                    error_by_label[label] = []
                error_by_label[label].append(mse[i])

            # Memory cleanup
            del volumes, reconstructed, mse
            torch.cuda.empty_cache()

    # Calculate overall metrics
    avg_mse = total_mse / total_samples
    rmse = np.sqrt(avg_mse)

    print("\nReconstruction Error Metrics:")
    print(f"Overall MSE: {avg_mse:.6f}")
    print(f"Overall RMSE: {rmse:.6f}")

    # Calculate metrics by group
    print("\nReconstruction Error by Group:")
    for label, errors in error_by_label.items():
        group_mse = np.mean(errors)
        group_rmse = np.sqrt(group_mse)
        group_std = np.std(errors)
        print(f"{label}:")
        print(f"  MSE: {group_mse:.6f} ± {group_std:.6f}")
        print(f"  RMSE: {group_rmse:.6f}")

    # Plot error distribution by group
    plt.figure(figsize=(10, 6))
    for label, errors in error_by_label.items():
        sns.histplot(errors, alpha=0.5, label=label, bins=20, kde=True)

    plt.title("Reconstruction Error Distribution by Group")
    plt.xlabel("Mean Squared Error")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    return avg_mse, error_by_label

def extract_latent_vectors(model, dataloader, max_samples=None):
    """Extract latent vectors from all samples in the dataloader"""
    device = next(model.parameters()).device

    latent_vectors = []
    labels = []
    paths = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Extract latent vectors
            z = model.encode(volumes)

            # Store results
            latent_vectors.append(z.cpu().numpy())
            labels.extend(batch_labels)
            paths.extend(batch_paths)

            # Memory cleanup
            del volumes, z
            torch.cuda.empty_cache()

            # Check if we have enough samples
            if max_samples and len(labels) >= max_samples:
                latent_vectors = np.vstack(latent_vectors)
                latent_vectors = latent_vectors[:max_samples]
                labels = labels[:max_samples]
                paths = paths[:max_samples]
                break

    # Stack all latent vectors if we didn't break early
    if isinstance(latent_vectors[0], np.ndarray):
        latent_vectors = np.vstack(latent_vectors)

    return latent_vectors, labels, paths

def visualize_latent_space(latent_vectors, labels, method='tsne'):
    """Visualize latent space using t-SNE or PCA"""
    plt.figure(figsize=(10, 8))

    # Create label-to-color mapping for consistent colors
    unique_labels = list(set(labels))
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    label_to_color = {label: colors[i] for i, label in enumerate(unique_labels)}

    # Apply dimensionality reduction
    if method.lower() == 'tsne':
        print("Computing t-SNE projection...")
        reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, len(latent_vectors) - 1))
        title = 't-SNE Visualization of Latent Space'
    else:
        print("Computing PCA projection...")
        reducer = PCA(n_components=2, random_state=42)
        title = 'PCA Visualization of Latent Space'

    # Apply reduction
    reduced_vecs = reducer.fit_transform(latent_vectors)

    # Create scatter plot
    for label in unique_labels:
        # Get indices where this label appears
        indices = [i for i, l in enumerate(labels) if l == label]

        # Plot these points
        plt.scatter(
            reduced_vecs[indices, 0],
            reduced_vecs[indices, 1],
            label=label,
            color=label_to_color[label],
            alpha=0.7,
            edgecolor='w',
            s=100
        )

    plt.title(title, fontsize=14)
    plt.xlabel("Dimension 1", fontsize=12)
    plt.ylabel("Dimension 2", fontsize=12)
    plt.legend(title="Group", fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    return reduced_vecs

def plot_latent_dimension_activation(latent_vectors, labels):
    """Analyze activation patterns of latent dimensions"""
    # Create a DataFrame with latent dimensions and labels
    import pandas as pd

    # First, convert labels to categorical for better plotting
    unique_labels = list(set(labels))
    label_map = {label: i for i, label in enumerate(unique_labels)}
    label_indices = [label_map[label] for label in labels]

    # Create DataFrames
    latent_df = pd.DataFrame(latent_vectors)
    latent_df['label'] = labels

    # Compute mean activation by group
    mean_activations = {}
    for label in unique_labels:
        group_vectors = latent_vectors[np.array(labels) == label]
        mean_activations[label] = np.mean(group_vectors, axis=0)

    # Identify top discriminative dimensions
    activation_matrix = np.vstack([mean_activations[label] for label in unique_labels])
    variance = np.var(activation_matrix, axis=0)
    top_dims = np.argsort(variance)[-10:]  # Top 10 dimensions

    # Plot mean activation for top dimensions
    plt.figure(figsize=(14, 6))

    # Plot heatmap
    plt.subplot(1, 2, 1)
    heatmap_data = pd.DataFrame({
        f"Dim {i}": [mean_activations[label][i] for label in unique_labels]
        for i in top_dims
    })
    heatmap_data.index = unique_labels

    sns.heatmap(heatmap_data, cmap='coolwarm', center=0,
               annot=True, fmt=".2f", cbar_kws={'label': 'Mean Activation'})
    plt.title("Mean Activation of Top Discriminative Dimensions")

    # Plot box plots for top 5 dimensions
    plt.subplot(1, 2, 2)

    # Create data for boxplot
    plot_data = []
    labels_for_plot = []
    positions = []

    for i, dim in enumerate(top_dims[:5]):  # Top 5 for clarity
        for j, label in enumerate(unique_labels):
            group_values = latent_vectors[np.array(labels) == label, dim]
            plot_data.append(group_values)
            labels_for_plot.append(f"{label}")
            positions.append(i + j * 0.25)

    # Create boxplot
    boxplot = plt.boxplot(plot_data, positions=positions, patch_artist=True, widths=0.15)

    # Customize boxplot colors
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    for i, label in enumerate(unique_labels):
        indices = [j for j, l in enumerate(labels_for_plot) if l == label]
        for idx in indices:
            boxplot['boxes'][idx].set_facecolor(colors[i])

    # Add labels and ticks
    plt.xticks([i + (len(unique_labels) - 1) * 0.125 for i in range(5)],
              [f"Dim {d}" for d in top_dims[:5]])
    plt.title("Distribution of Top 5 Discriminative Dimensions")
    plt.ylabel("Activation Value")

    # Add legend
    for i, label in enumerate(unique_labels):
        plt.plot([], [], 'o', color=colors[i], label=label)
    plt.legend(title="Group")

    plt.tight_layout()
    plt.show()

    return top_dims

def find_outliers(model, dataloader, threshold_std=2.5):
    """Identify outliers based on reconstruction error"""
    device = next(model.parameters()).device
    criterion = nn.MSELoss(reduction='none')

    all_errors = []
    all_paths = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Finding outliers"):
            volumes = batch['volume'].to(device)
            paths = batch['path']
            labels = batch['label']

            # Get reconstructions
            reconstructed = model(volumes)

            # Compute MSE loss per sample
            mse = criterion(reconstructed, volumes)

            # Average over dimensions
            mse = mse.mean(dim=(1, 2, 3, 4)).cpu().numpy()

            # Store results
            all_errors.extend(mse)
            all_paths.extend(paths)
            all_labels.extend(labels)

            # Memory cleanup
            del volumes, reconstructed, mse
            torch.cuda.empty_cache()

    # Convert to numpy arrays
    all_errors = np.array(all_errors)

    # Compute statistics
    mean_error = np.mean(all_errors)
    std_error = np.std(all_errors)

    # Find outliers (samples with error > mean + threshold_std * std)
    threshold = mean_error + threshold_std * std_error
    outlier_indices = np.where(all_errors > threshold)[0]

    print(f"\nOutlier Analysis:")
    print(f"Mean error: {mean_error:.6f}")
    print(f"Error standard deviation: {std_error:.6f}")
    print(f"Outlier threshold: {threshold:.6f}")
    print(f"Found {len(outlier_indices)} outliers out of {len(all_errors)} samples ({len(outlier_indices)/len(all_errors)*100:.2f}%)")

    # Create dictionary of outliers
    outliers = {
        all_paths[i]: {
            'error': all_errors[i],
            'label': all_labels[i],
            'z_score': (all_errors[i] - mean_error) / std_error
        }
        for i in outlier_indices
    }

    # Plot error distribution with outlier threshold
    plt.figure(figsize=(10, 6))
    plt.hist(all_errors, bins=30, alpha=0.7)
    plt.axvline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold_std} std)')
    plt.title("Reconstruction Error Distribution")
    plt.xlabel("Mean Squared Error")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    return outliers, all_errors, all_paths, all_labels

def visualize_outliers(model, outliers, threshold=0.01):
    """Visualize the top outliers with highest reconstruction error using anatomically relevant slices"""
    device = next(model.parameters()).device

    # Sort outliers by error (descending)
    sorted_outliers = sorted(outliers.items(), key=lambda x: x[1]['error'], reverse=True)

    # Visualize top outliers
    num_outliers = min(5, len(sorted_outliers))

    for i in range(num_outliers):
        path, info = sorted_outliers[i]
        error = info['error']
        label = info['label']
        z_score = info['z_score']

        try:
            # Load the original volume
            with torch.no_grad():
                # Load DICOM file
                original_volume, _ = load_dicom(path)
                original_volume = original_volume[9:73, :, :]

                # Process volume
                norm_vol, _, _ = process_volume(original_volume, target_shape=(64, 128, 128))

                # Convert to tensor and add batch dimension
                vol_tensor = torch.from_numpy(np.expand_dims(norm_vol, axis=(0, 1))).float().to(device)

                # Get reconstruction
                reconstructed = model(vol_tensor)

                # Move tensors to CPU and remove batch and channel dimensions
                vol_np = vol_tensor.cpu().squeeze().numpy()
                recon_np = reconstructed.cpu().squeeze().numpy()

                # Create figure
                fig = plt.figure(figsize=(16, 12))
                plt.suptitle(f"Outlier {i+1}: {path.split('/')[-1]}\nGroup: {label}, Error: {error:.6f}, Z-score: {z_score:.2f}", fontsize=14)

                # Define anatomically relevant slices
                axial_slice = 32      # Axial view - slice 32
                coronal_slice = 50    # Coronal view - slice 50
                sagittal_slice1 = 55  # Sagittal view - slice 55
                sagittal_slice2 = 70  # Sagittal view - slice 70

                # Plot original slices - top row
                plt.subplot(2, 4, 1)
                plt.imshow(vol_np[axial_slice], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Axial (z={axial_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 2)
                plt.imshow(vol_np[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Coronal (y={coronal_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 3)
                plt.imshow(vol_np[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Sagittal (x={sagittal_slice1})")
                plt.axis('off')

                plt.subplot(2, 4, 4)
                plt.imshow(vol_np[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Sagittal (x={sagittal_slice2})")
                plt.axis('off')

                # Plot reconstructed slices - bottom row
                plt.subplot(2, 4, 5)
                plt.imshow(recon_np[axial_slice], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Axial (z={axial_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 6)
                plt.imshow(recon_np[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Coronal (y={coronal_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 7)
                plt.imshow(recon_np[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Sagittal (x={sagittal_slice1})")
                plt.axis('off')

                plt.subplot(2, 4, 8)
                plt.imshow(recon_np[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Sagittal (x={sagittal_slice2})")
                plt.axis('off')

                plt.tight_layout()
                plt.show()

        except Exception as e:
            print(f"Error visualizing outlier {path}: {e}")

# Run evaluation if this cell is executed
if __name__ == "__main__":
    # Load model and metadata
    model, metadata = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)

    # Plot training history
    plot_training_history(metadata)

    # Visualize reconstructions
    visualize_reconstruction_samples(model, val_loader, num_samples=3)

    # Compute reconstruction error
    avg_mse, error_by_label = compute_reconstruction_error(model, val_loader)

    # Extract and visualize latent space
    latent_vectors, labels, paths = extract_latent_vectors(model, val_loader, max_samples=200)
    reduced_vecs = visualize_latent_space(latent_vectors, labels, method='tsne')
    reduced_vecs = visualize_latent_space(latent_vectors, labels, method='pca')

    # Analyze latent dimensions
    top_dims = plot_latent_dimension_activation(latent_vectors, labels)

    # Find and visualize outliers
    outliers, all_errors, all_paths, all_labels = find_outliers(model, val_loader, threshold_std=2.5)
    visualize_outliers(model, outliers)

# Cell 15: Autoencoder Latent Dimension Visualization with Consistent Scales

import torch
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import LinearSegmentedColormap
import torch.nn.functional as F

def visualize_latent_dimension(model, dataloader, dimension_idx, alpha=5.0, group=None):
    """
    Visualize what a specific latent dimension represents by modifying it
    and observing the effect on brain reconstruction using anatomically relevant slices.

    Ensures consistent scales across all views for better comparison.

    Parameters:
        model: Trained autoencoder model
        dataloader: DataLoader containing samples
        dimension_idx: The latent dimension to manipulate (e.g., 231)
        alpha: Strength of the dimension manipulation
        group: Optional filter for specific patient group (e.g., 'PD', 'Control')
    """
    device = next(model.parameters()).device
    model.eval()

    # Find a suitable sample (optionally from specific group)
    for batch in dataloader:
        volumes = batch['volume']
        labels = batch['label']
        paths = batch['path']

        if group is not None:
            # Find samples from the specified group
            group_indices = [i for i, label in enumerate(labels) if label == group]
            if not group_indices:
                continue
            # Use the first matching sample
            idx = group_indices[0]
            sample = volumes[idx:idx+1].to(device)
            sample_label = labels[idx]
            sample_path = paths[idx]
        else:
            # Just use the first sample
            sample = volumes[0:1].to(device)
            sample_label = labels[0]
            sample_path = paths[0]

        break  # Exit after finding a sample

    with torch.no_grad():
        # Encode the sample to get its latent representation
        z = model.encode(sample)

        # Create modified latent vectors
        z_plus = z.clone()
        z_minus = z.clone()

        # Modify the specific dimension
        z_plus[0, dimension_idx] += alpha
        z_minus[0, dimension_idx] -= alpha

        # Decode the original and modified latent vectors
        original_reconstruction = model.decode(z)
        plus_reconstruction = model.decode(z_plus)
        minus_reconstruction = model.decode(z_minus)

        # Move tensors to CPU and convert to numpy for visualization
        original_vol = original_reconstruction.cpu().squeeze().numpy()
        plus_vol = plus_reconstruction.cpu().squeeze().numpy()
        minus_vol = minus_reconstruction.cpu().squeeze().numpy()

        # Calculate the difference maps
        plus_diff = plus_vol - original_vol
        minus_diff = minus_vol - original_vol

        # Set up the figure
        fig = plt.figure(figsize=(16, 15))
        plt.suptitle(f"Visualization of Dimension {dimension_idx} in Brain Space\nPatient Group: {sample_label}", fontsize=16)

        # Define anatomically relevant slices
        slices = {
            'axial': 32,       # Axial z=32
            'coronal': 50,     # Coronal y=50
            'sagittal1': 55,   # Sagittal x=55
            'sagittal2': 70    # Sagittal x=70
        }

        # Create a custom colormap for difference maps
        diff_cmap = plt.cm.RdBu_r  # Red-Blue colormap with red for negative, blue for positive

        # Determine consistent scales for brain intensity and difference maps
        brain_vmin, brain_vmax = 0, 3  # Standard scale for brain images

        # Find global min/max for difference maps to use consistent scale
        diff_min = min(np.min(plus_diff), np.min(minus_diff))
        diff_max = max(np.max(plus_diff), np.max(minus_diff))
        # Make the range symmetric around zero for better visualization
        diff_abs_max = max(abs(diff_min), abs(diff_max))
        diff_vmin, diff_vmax = -diff_abs_max, diff_abs_max

        # Row 1: Original reconstruction - 4 views
        plt.subplot(5, 4, 1)
        plt.imshow(original_vol[slices['axial']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Original (Axial z={slices['axial']})")
        plt.axis('off')

        plt.subplot(5, 4, 2)
        plt.imshow(original_vol[:, slices['coronal'], :], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Original (Coronal y={slices['coronal']})")
        plt.axis('off')

        plt.subplot(5, 4, 3)
        plt.imshow(original_vol[:, :, slices['sagittal1']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Original (Sagittal x={slices['sagittal1']})")
        plt.axis('off')

        plt.subplot(5, 4, 4)
        plt.imshow(original_vol[:, :, slices['sagittal2']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Original (Sagittal x={slices['sagittal2']})")
        plt.axis('off')

        # Row 2: Increased dimension - 4 views
        plt.subplot(5, 4, 5)
        plt.imshow(plus_vol[slices['axial']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 6)
        plt.imshow(plus_vol[:, slices['coronal'], :], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 7)
        plt.imshow(plus_vol[:, :, slices['sagittal1']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 8)
        plt.imshow(plus_vol[:, :, slices['sagittal2']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        # Row 3: Decreased dimension - 4 views
        plt.subplot(5, 4, 9)
        plt.imshow(minus_vol[slices['axial']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 10)
        plt.imshow(minus_vol[:, slices['coronal'], :], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 11)
        plt.imshow(minus_vol[:, :, slices['sagittal1']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 12)
        plt.imshow(minus_vol[:, :, slices['sagittal2']], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        # Row 4: Difference map (increased - original) - 4 views
        plt.subplot(5, 4, 13)
        im1 = plt.imshow(plus_diff[slices['axial']], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (+)")
        plt.axis('off')

        plt.subplot(5, 4, 14)
        plt.imshow(plus_diff[:, slices['coronal'], :], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (+)")
        plt.axis('off')

        plt.subplot(5, 4, 15)
        plt.imshow(plus_diff[:, :, slices['sagittal1']], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (+)")
        plt.axis('off')

        plt.subplot(5, 4, 16)
        plt.imshow(plus_diff[:, :, slices['sagittal2']], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (+)")
        plt.axis('off')

        # Row 5: Difference map (decreased - original) - 4 views
        plt.subplot(5, 4, 17)
        im2 = plt.imshow(minus_diff[slices['axial']], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (-)")
        plt.axis('off')

        plt.subplot(5, 4, 18)
        plt.imshow(minus_diff[:, slices['coronal'], :], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (-)")
        plt.axis('off')

        plt.subplot(5, 4, 19)
        plt.imshow(minus_diff[:, :, slices['sagittal1']], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (-)")
        plt.axis('off')

        plt.subplot(5, 4, 20)
        plt.imshow(minus_diff[:, :, slices['sagittal2']], cmap=diff_cmap, vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference (-)")
        plt.axis('off')

        # Add colorbar for difference maps - now showing the global range
        cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.3])
        cbar = plt.colorbar(im1, cax=cbar_ax)
        cbar.set_label(f'Difference Intensity (Range: {diff_vmin:.3f} to {diff_vmax:.3f})')

        plt.tight_layout()
        plt.subplots_adjust(top=0.92, right=0.9)
        plt.show()

        # Print information about scales used
        print(f"Brain Intensity Scale: {brain_vmin} to {brain_vmax}")
        print(f"Difference Map Scale: {diff_vmin:.3f} to {diff_vmax:.3f}")

        # Return both the sample info and reconstructions for further analysis
        return {
            'label': sample_label,
            'path': sample_path,
            'original': original_vol,
            'plus': plus_vol,
            'minus': minus_vol,
            'plus_diff': plus_diff,
            'minus_diff': minus_diff,
            'diff_min': diff_vmin,
            'diff_max': diff_vmax
        }

def explore_top_dimensions(model, dataloader, dimensions, groups=None):
    """
    Explore the top discriminative dimensions across different patient groups using anatomically relevant slices.
    Ensures consistent scales across all visualizations for a given dimension.

    Parameters:
        model: Trained autoencoder model
        dataloader: DataLoader containing samples
        dimensions: List of dimension indices to explore
        groups: List of groups to include (default is all groups)
    """
    if groups is None:
        # Get all unique groups from the first batch
        for batch in dataloader:
            groups = list(set(batch['label']))
            break

    for dimension in dimensions:
        print(f"\n{'='*80}")
        print(f"Exploring Dimension {dimension}")
        print(f"{'='*80}")

        # First pass to determine global min/max difference values
        diff_min_global = float('inf')
        diff_max_global = float('-inf')

        # Store results from first pass
        dimension_results = {}

        # Scan all groups to find global min/max
        for group in groups:
            print(f"\nAnalyzing dimension {dimension} for group: {group} (first pass)")
            results = visualize_latent_dimension(model, dataloader, dimension, alpha=8.0, group=group)

            # Update global min/max
            plus_diff = results['plus_diff']
            minus_diff = results['minus_diff']

            curr_min = min(np.min(plus_diff), np.min(minus_diff))
            curr_max = max(np.max(plus_diff), np.max(minus_diff))

            diff_min_global = min(diff_min_global, curr_min)
            diff_max_global = max(diff_max_global, curr_max)

            # Store results for second pass
            dimension_results[group] = results

        # Make the scale symmetric
        diff_abs_max = max(abs(diff_min_global), abs(diff_max_global))
        diff_global_vmin, diff_global_vmax = -diff_abs_max, diff_abs_max

        print(f"\nGlobal difference range for dimension {dimension} across all groups: {diff_global_vmin:.3f} to {diff_global_vmax:.3f}")

        # Optional: Add a small delay for better visualization
        import time
        time.sleep(1)

def generate_feature_importance_map(model, dataloader, dimension_idx, group=None, num_samples=5):
    """
    Generate a more robust feature importance map for a specific dimension
    by aggregating effects across multiple samples using anatomically relevant slices.
    Uses consistent scales across all views for better comparison.

    Parameters:
        model: Trained autoencoder model
        dataloader: DataLoader containing samples
        dimension_idx: The latent dimension to analyze
        group: Optional filter for specific patient group
        num_samples: Number of samples to aggregate
    """
    device = next(model.parameters()).device
    model.eval()

    # Storage for aggregated results
    aggregated_plus_diff = None
    aggregated_minus_diff = None
    sample_count = 0

    # Find samples (optionally from specific group)
    for batch in dataloader:
        volumes = batch['volume']
        labels = batch['label']

        if group is not None:
            # Find samples from the specified group
            group_indices = [i for i, label in enumerate(labels) if label == group]
            indices = group_indices
        else:
            # Use all samples in batch
            indices = range(len(volumes))

        for idx in indices:
            if sample_count >= num_samples:
                break

            sample = volumes[idx:idx+1].to(device)

            with torch.no_grad():
                # Encode the sample
                z = model.encode(sample)

                # Create modified latent vectors
                z_plus = z.clone()
                z_minus = z.clone()

                # Modify the specific dimension
                z_plus[0, dimension_idx] += 5.0
                z_minus[0, dimension_idx] -= 5.0

                # Decode the vectors
                original_reconstruction = model.decode(z)
                plus_reconstruction = model.decode(z_plus)
                minus_reconstruction = model.decode(z_minus)

                # Calculate the difference maps
                plus_diff = (plus_reconstruction - original_reconstruction).cpu().squeeze().numpy()
                minus_diff = (minus_reconstruction - original_reconstruction).cpu().squeeze().numpy()

                # Aggregate the difference maps
                if aggregated_plus_diff is None:
                    aggregated_plus_diff = plus_diff
                    aggregated_minus_diff = minus_diff
                else:
                    aggregated_plus_diff += plus_diff
                    aggregated_minus_diff += minus_diff

                sample_count += 1

        if sample_count >= num_samples:
            break

    # Average the difference maps
    aggregated_plus_diff /= sample_count
    aggregated_minus_diff /= sample_count

    # Compute absolute importance map (average of plus and minus effects)
    importance_map = (np.abs(aggregated_plus_diff) + np.abs(aggregated_minus_diff)) / 2

    # Define anatomically relevant slices
    axial_slice = 32      # Axial view - slice 32
    coronal_slice = 50    # Coronal view - slice 50
    sagittal_slice1 = 55  # Sagittal view - slice 55
    sagittal_slice2 = 70  # Sagittal view - slice 70

    # Determine global max value for importance map for consistent scale
    importance_max = np.max(importance_map)

    # Determine global min/max for activation maps for consistent scale
    activation_min = min(np.min(aggregated_plus_diff), np.min(aggregated_minus_diff))
    activation_max = max(np.max(aggregated_plus_diff), np.max(aggregated_minus_diff))
    # Make the activation scale symmetric around zero
    activation_abs_max = max(abs(activation_min), abs(activation_max))
    activation_vmin, activation_vmax = -activation_abs_max, activation_abs_max

    # Visualize the importance map
    fig = plt.figure(figsize=(16, 8))
    plt.suptitle(f"Feature Importance Map for Dimension {dimension_idx}" +
                (f" (Group: {group})" if group else ""), fontsize=16)

    # Plot axial, coronal, and sagittal views for importance map
    plt.subplot(2, 4, 1)
    im1 = plt.imshow(importance_map[axial_slice], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Axial (z={axial_slice})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 2)
    plt.imshow(importance_map[:, coronal_slice, :], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Coronal (y={coronal_slice})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 3)
    plt.imshow(importance_map[:, :, sagittal_slice1], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Sagittal (x={sagittal_slice1})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 4)
    plt.imshow(importance_map[:, :, sagittal_slice2], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Sagittal (x={sagittal_slice2})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    # Plot activating direction (positive difference) with consistent scale
    plt.subplot(2, 4, 5)
    im2 = plt.imshow(aggregated_plus_diff[axial_slice], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Axial")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 6)
    plt.imshow(aggregated_plus_diff[:, coronal_slice, :], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Coronal")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 7)
    plt.imshow(aggregated_plus_diff[:, :, sagittal_slice1], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Sagittal 1")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 8)
    plt.imshow(aggregated_plus_diff[:, :, sagittal_slice2], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Sagittal 2")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # Print information about scales used
    print(f"Importance Map Scale: 0 to {importance_max:.3f}")
    print(f"Activation Map Scale: {activation_vmin:.3f} to {activation_vmax:.3f}")

    return importance_map, aggregated_plus_diff, aggregated_minus_diff

# Example usage
if __name__ == "__main__":
    # Load your trained model first
    model, metadata = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)

    # Example 1: Visualize one specific important dimension for a specific group
    # This shows what happens when you increase or decrease this dimension
    visualize_latent_dimension(model, val_loader, dimension_idx=231, alpha=8.0, group='PD')

    # Example 2: Compare the same dimension across different patient groups
    # Uncomment to see how the same dimension affects different groups
    explore_top_dimensions(model, val_loader, dimensions=[231, 94, 154], groups=['PD', 'Control', 'SWEDD'])

    # Example 3: Generate a feature importance map by aggregating across multiple samples
    # This shows which brain regions are most affected by this dimension
    generate_feature_importance_map(model, val_loader, dimension_idx=94, group='PD', num_samples=10)
    generate_feature_importance_map(model, val_loader, dimension_idx=94, group='Control', num_samples=10)
    generate_feature_importance_map(model, val_loader, dimension_idx=231, group='PD', num_samples=10)
    generate_feature_importance_map(model, val_loader, dimension_idx=231, group='Control', num_samples=10)

"""## 2. Variational Autoencoder (VAE)

### Model Setup
"""

# Cell 16: Corrected VAE Implementation
import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict

class VAE(nn.Module):
    """
    3D Variational Autoencoder optimized for 64×128×128 medical volumes with
    memory-efficient implementation for NVIDIA 4070Ti.
    """
    def __init__(self, latent_dim=256):
        super().__init__()
        self.encoder = VAEEncoder(latent_dim)
        self.decoder = VAEDecoder(latent_dim)
        # Enable CUDNN benchmarking for optimal performance
        torch.backends.cudnn.benchmark = True
        self.latent_dim = latent_dim

    def reparameterize(self, mu, log_var):
        """
        Reparameterization trick to enable backpropagation through sampling.
        """
        if self.training:
            std = torch.exp(0.5 * log_var)
            eps = torch.randn_like(std)
            return mu + eps * std
        return mu

    def forward(self, x):
        # Encode input to get mean and variance of latent distribution
        mu, log_var = self.encoder(x)

        # Sample from latent distribution
        z = self.reparameterize(mu, log_var)

        # Decode sampled latent vector
        reconstruction = self.decoder(z)

        return reconstruction, mu, log_var

    def encode(self, x):
        """Encode input to latent parameters without sampling"""
        mu, log_var = self.encoder(x)
        return mu, log_var

    def generate(self, z=None, num_samples=1):
        """Generate samples from latent space or random samples"""
        device = next(self.parameters()).device

        if z is None:
            # Generate random latent vectors
            z = torch.randn(num_samples, self.latent_dim, device=device)

        # Decode latent vectors to generate samples
        with torch.no_grad():
            samples = self.decoder(z)

        return samples

class ConvBlock(nn.Module):
    """Memory-efficient convolutional block with batch normalization and ReLU."""
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.block = nn.Sequential(OrderedDict([
            ('conv', nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)),
            ('bn', nn.BatchNorm3d(out_channels)),
            ('relu', nn.ReLU(inplace=True))  # inplace ReLU for memory efficiency
        ]))

    def forward(self, x):
        return self.block(x)

class VAEEncoder(nn.Module):
    """3D Encoder network with probabilistic latent space."""
    def __init__(self, latent_dim=256):
        super().__init__()

        # Initial feature extraction
        self.init_conv = ConvBlock(1, 16)  # 64×128×128 -> same size

        # Downsampling path with progressive channel increase
        self.down1 = nn.Sequential(
            ConvBlock(16, 32, stride=2),    # -> 32×64×64
            ConvBlock(32, 32)
        )

        self.down2 = nn.Sequential(
            ConvBlock(32, 64, stride=2),    # -> 16×32×32
            ConvBlock(64, 64)
        )

        self.down3 = nn.Sequential(
            ConvBlock(64, 128, stride=2),   # -> 8×16×16
            ConvBlock(128, 128)
        )

        self.down4 = nn.Sequential(
            ConvBlock(128, 256, stride=2),  # -> 4×8×8
            ConvBlock(256, 256)
        )

        # Project to latent parameters
        self.flatten_size = 256 * 4 * 8 * 8
        self.fc_mu = nn.Linear(self.flatten_size, latent_dim)
        self.fc_var = nn.Linear(self.flatten_size, latent_dim)

    def forward(self, x):
        # Initial convolution
        x = self.init_conv(x)

        # Downsampling
        x = self.down1(x)
        x = self.down2(x)
        x = self.down3(x)
        x = self.down4(x)

        # Flatten and project to latent parameters
        flat = torch.flatten(x, start_dim=1)
        mu = self.fc_mu(flat)
        log_var = self.fc_var(flat)

        return mu, log_var

class VAEDecoder(nn.Module):
    """3D Decoder network without enhanced capacity - matching the saved model."""
    def __init__(self, latent_dim=256):
        super().__init__()

        self.flatten_size = 256 * 4 * 8 * 8
        self.fc = nn.Linear(latent_dim, self.flatten_size)

        # Upsampling path without enhanced capacity (matches the saved model)
        self.up1 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(256, 128),  # Original channel size from saved model
            ConvBlock(128, 128)
        )

        self.up2 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(128, 64),   # Original channel size from saved model
            ConvBlock(64, 64)
        )

        self.up3 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(64, 32),    # Original channel size from saved model
            ConvBlock(32, 32)
        )

        self.up4 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False),
            ConvBlock(32, 16),    # Original channel size from saved model
            ConvBlock(16, 16)
        )

        # No refinement layer in the original model

        # Final convolution
        self.final_conv = nn.Conv3d(16, 1, kernel_size=1)

    def forward(self, z):
        # Reshape from latent space
        x = self.fc(z)
        x = x.view(-1, 256, 4, 8, 8)

        # Upsampling
        x = self.up1(x)
        x = self.up2(x)
        x = self.up3(x)
        x = self.up4(x)

        # Final convolution (no activation to allow for negative values if needed)
        x = self.final_conv(x)

        return x

# Custom loss function for VAE
class VAELoss(nn.Module):
    """
    VAE loss combining reconstruction loss and KL divergence
    with beta parameter to control the trade-off and free bits approach.
    """
    def __init__(self, beta=0.0005, beta_warmup_steps=5000, free_bits=3.0):
        super().__init__()
        self.beta_base = beta
        self.beta_warmup_steps = beta_warmup_steps
        self.current_step = 0
        self.free_bits = free_bits  # Free bits parameter to prevent posterior collapse

    def forward(self, recon_x, x, mu, log_var):
        """
        Calculate VAE loss with enhanced beta annealing and free bits.
        """
        # Reconstruction loss (mean squared error)
        recon_loss = F.mse_loss(recon_x, x, reduction='mean')

        # KL divergence with free bits
        # Instead of penalizing all KL divergence, allow some "free bits"
        kl_raw = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1)

        # Apply free bits: only penalize when KL is above threshold
        kl_free = torch.maximum(kl_raw - self.free_bits, torch.zeros_like(kl_raw))
        kl_loss = torch.mean(kl_free)

        # Calculate beta with cyclical warmup
        # Cyclical annealing gives the model periods to focus on reconstruction
        if self.beta_warmup_steps > 0:
            # Implement cyclical annealing
            cycle_length = self.beta_warmup_steps // 2
            cycle_position = (self.current_step % cycle_length) / cycle_length
            if self.current_step // cycle_length % 2 == 0:  # Even cycles: warmup
                beta = self.beta_base * cycle_position
            else:  # Odd cycles: constant
                beta = self.beta_base
        else:
            beta = self.beta_base

        # Increment step counter
        self.current_step += 1

        # Total loss
        total_loss = recon_loss + beta * kl_loss

        return total_loss, recon_loss, kl_loss, beta

# Test VAE with dummy data
def test_vae(batch_size=2, latent_dim=256):
    """Test the VAE architecture and memory usage with dummy data."""
    print("\nTesting VAE Architecture...")

    try:
        # Create model and move to GPU
        model = VAE(latent_dim=latent_dim)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        # Create loss function
        vae_loss = VAELoss(beta=0.005)

        # Print model summary
        num_params = sum(p.numel() for p in model.parameters())
        print(f"\nVAE Model Parameters: {num_params:,}")

        # Create dummy input
        dummy_input = torch.randn(batch_size, 1, 64, 128, 128, device=device)

        # Test forward pass
        print("\nTesting forward pass...")
        print_memory_stats()
        with torch.no_grad():
            recon, mu, log_var = model(dummy_input)

        # Test loss calculation
        loss, recon_loss, kl_loss, beta = vae_loss(recon, dummy_input, mu, log_var)

        print(f"\nInput shape: {dummy_input.shape}")
        print(f"Latent mu shape: {mu.shape}")
        print(f"Output shape: {recon.shape}")
        print(f"\nLoss values:")
        print(f"Total loss: {loss.item():.6f}")
        print(f"Reconstruction loss: {recon_loss.item():.6f}")
        print(f"KL loss: {kl_loss.item():.6f}")
        print(f"Beta value: {beta:.6f}")

        # Check memory usage
        print("\nGPU Memory After Forward Pass:")
        print_memory_stats()

        # Clean up
        del model, dummy_input, recon, mu, log_var
        torch.cuda.empty_cache()

        print("\nVAE test completed successfully!")
        return True

    except Exception as e:
        print(f"Error testing VAE: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

# Run test if this cell is executed
if __name__ == "__main__":
    test_vae(batch_size=2, latent_dim=256)

# Cell 17: VAE Training Configuration and Training Loop
import os
import json
import time
from pathlib import Path
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torch.cuda.amp as amp
import gc
import torch

class VAEConfig:
    """Configuration for VAE training optimized for NVIDIA 4070Ti"""
    def __init__(self, **kwargs):
        # Model parameters
        self.latent_dim = kwargs.get('latent_dim', 256)

        # Training parameters
        self.learning_rate = kwargs.get('learning_rate', 5e-5)
        self.batch_size = kwargs.get('batch_size', 8)
        self.accumulation_steps = kwargs.get('accumulation_steps', 8)  # Effective batch size of 64
        self.epochs = kwargs.get('epochs', 100)
        self.early_stopping_patience = kwargs.get('early_stopping_patience', 15)

        # Loss parameters
        self.beta = kwargs.get('beta', 0.005)  # KL divergence weight
        self.beta_warmup_steps = kwargs.get('beta_warmup_steps', 2000)

        # Optimization
        self.use_mixed_precision = kwargs.get('use_mixed_precision', True)
        self.weight_decay = kwargs.get('weight_decay', 1e-6)
        self.gradient_clip = kwargs.get('gradient_clip', 1.0)

        # Dataloader parameters
        self.num_workers = kwargs.get('num_workers', 4)
        self.pin_memory = kwargs.get('pin_memory', True)

        # Checkpoint parameters
        self.checkpoint_dir = kwargs.get('checkpoint_dir', 'checkpoints')
        self.model_name = kwargs.get('model_name', 'vae_model')
        self.save_interval = kwargs.get('save_interval', 5)

        # Create checkpoint directory
        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)

        # Print configuration summary
        print(f"\n{'='*50}")
        print(f"VAE TRAINING CONFIGURATION")
        print(f"{'='*50}")
        print(f"Model: {self.model_name} with latent dim {self.latent_dim}")
        print(f"Batch size: {self.batch_size} × {self.accumulation_steps} steps = {self.batch_size * self.accumulation_steps} effective")
        print(f"Learning rate: {self.learning_rate}")
        print(f"Beta (KL weight): {self.beta} with {self.beta_warmup_steps} warmup steps")
        print(f"Mixed precision: {'Enabled' if self.use_mixed_precision else 'Disabled'}")
        print(f"Epochs: {self.epochs} with patience {self.early_stopping_patience}")
        print(f"Dataloader workers: {self.num_workers}")
        print(f"Checkpoints saved to: {self.checkpoint_dir}")
        print(f"{'='*50}\n")

class VAECheckpointHandler:
    """Handles saving and loading of VAE model checkpoints"""
    def __init__(self, checkpoint_dir, model_name):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.model_name = model_name
        self.checkpoint_path = self.checkpoint_dir / f"{model_name}_checkpoint.pth"
        self.best_model_path = self.checkpoint_dir / f"{model_name}_best.pth"
        self.metadata_path = self.checkpoint_dir / f"{model_name}_metadata.json"

        # Ensure directory exists
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

    def save(self, model, optimizer, scheduler, epoch, train_losses, val_losses,
           train_recon_losses, train_kl_losses, val_recon_losses, val_kl_losses,
           is_best=False):
        """Save VAE checkpoint with additional VAE-specific metrics"""
        # Save model checkpoint
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_recon_losses': train_recon_losses,
            'train_kl_losses': train_kl_losses,
            'val_recon_losses': val_recon_losses,
            'val_kl_losses': val_kl_losses
        }

        # Save checkpoint
        torch.save(checkpoint, self.checkpoint_path)

        # Save best model separately if this is the best model
        if is_best:
            torch.save(model.state_dict(), self.best_model_path)
            print(f"Saved best model to {self.best_model_path}")

        # Save metadata
        metadata = {
            'last_epoch': epoch,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_recon_losses': train_recon_losses,
            'train_kl_losses': train_kl_losses,
            'val_recon_losses': val_recon_losses,
            'val_kl_losses': val_kl_losses,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(self.metadata_path, 'w') as f:
            json.dump(metadata, f, indent=4)

    def load(self, model, optimizer=None, scheduler=None, device=None):
        """Load model checkpoint and return training metadata"""
        if not self.checkpoint_path.exists():
            print(f"No checkpoint found at {self.checkpoint_path}")
            return None

        if device is None:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Load checkpoint
        checkpoint = torch.load(self.checkpoint_path, map_location=device)

        # Load model state
        model.load_state_dict(checkpoint['model_state_dict'])

        # Optionally load optimizer and scheduler states
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        if scheduler is not None and checkpoint.get('scheduler_state_dict') is not None:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        print(f"Loaded checkpoint from epoch {checkpoint['epoch']}")

        return {
            'epoch': checkpoint['epoch'],
            'train_losses': checkpoint.get('train_losses', []),
            'val_losses': checkpoint.get('val_losses', []),
            'train_recon_losses': checkpoint.get('train_recon_losses', []),
            'train_kl_losses': checkpoint.get('train_kl_losses', []),
            'val_recon_losses': checkpoint.get('val_recon_losses', []),
            'val_kl_losses': checkpoint.get('val_kl_losses', [])
        }

def create_vae_optimizer(model, config):
    """Create optimizer with parameter groups for VAE"""
    # Separate parameters that should have weight decay from those that shouldn't
    decay_params = []
    no_decay_params = []

    for name, param in model.named_parameters():
        if 'bias' in name or 'bn' in name:
            no_decay_params.append(param)
        else:
            decay_params.append(param)

    # Create parameter groups
    param_groups = [
        {'params': decay_params, 'weight_decay': config.weight_decay},
        {'params': no_decay_params, 'weight_decay': 0.0}
    ]

    # Create optimizer
    optimizer = optim.AdamW(param_groups, lr=config.learning_rate)

    return optimizer

def create_vae_scheduler(optimizer, config):
    """Create learning rate scheduler"""
    return ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=5,
        verbose=True,
        min_lr=1e-6
    )

class VAEEarlyStopping:
    """Early stopping handler with patience for VAE"""
    def __init__(self, patience=10, min_delta=0, verbose=True):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')
        self.early_stop = False
        self.verbose = verbose
        self.best_epoch = 0

    def __call__(self, val_loss, epoch):
        if val_loss < self.best_loss - self.min_delta:
            if self.verbose:
                improvement = self.best_loss - val_loss
                print(f"Validation loss improved by {improvement:.6f}")
            self.best_loss = val_loss
            self.counter = 0
            self.best_epoch = epoch
            return True  # Model improved
        else:
            self.counter += 1
            if self.verbose:
                print(f"Early stopping counter: {self.counter}/{self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print(f"Early stopping triggered. Best epoch was {self.best_epoch}.")
            return False  # Model didn't improve

def train_vae(model, train_loader, val_loader, config=None):
    """Memory-optimized VAE training loop with mixed precision and gradient accumulation"""
    if config is None:
        config = VAEConfig()

    # Set up device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Initialize components
    criterion = VAELoss(beta=config.beta, beta_warmup_steps=config.beta_warmup_steps)
    optimizer = create_vae_optimizer(model, config)
    scheduler = create_vae_scheduler(optimizer, config)
    early_stopping = VAEEarlyStopping(patience=config.early_stopping_patience)
    checkpoint_handler = VAECheckpointHandler(config.checkpoint_dir, config.model_name)

    # Mixed precision setup
    scaler = amp.GradScaler(enabled=config.use_mixed_precision)

    # Training tracking variables
    train_losses = []
    val_losses = []
    train_recon_losses = []
    train_kl_losses = []
    val_recon_losses = []
    val_kl_losses = []
    best_val_loss = float('inf')
    start_time = time.time()

    # Load checkpoint if available
    start_epoch = 0
    checkpoint_data = checkpoint_handler.load(model, optimizer, scheduler, device)
    if checkpoint_data:
        start_epoch = checkpoint_data['epoch'] + 1
        train_losses = checkpoint_data.get('train_losses', [])
        val_losses = checkpoint_data.get('val_losses', [])
        train_recon_losses = checkpoint_data.get('train_recon_losses', [])
        train_kl_losses = checkpoint_data.get('train_kl_losses', [])
        val_recon_losses = checkpoint_data.get('val_recon_losses', [])
        val_kl_losses = checkpoint_data.get('val_kl_losses', [])
        print(f"Resuming training from epoch {start_epoch}")

    # Calculate total steps for progress tracking
    total_steps = len(train_loader) * config.epochs

    # Training loop
    try:
        # Create progress bar for total training
        total_pbar = tqdm(total=total_steps, desc="Total Progress", position=0)
        total_pbar.update(start_epoch * len(train_loader))

        for epoch in range(start_epoch, config.epochs):
            # Training phase
            model.train()
            epoch_loss = 0
            epoch_recon_loss = 0
            epoch_kl_loss = 0
            current_beta = 0
            optimizer.zero_grad()  # Zero gradients at epoch start

            train_pbar = tqdm(train_loader,
                            desc=f'Epoch {epoch+1}/{config.epochs} [Train]',
                            leave=False,
                            position=1)

            for batch_idx, batch in enumerate(train_pbar):
                try:
                    # Move data to device
                    volumes = batch['volume'].to(device, non_blocking=True)

                    # Mixed precision forward pass
                    with amp.autocast(enabled=config.use_mixed_precision):
                        reconstructed, mu, log_var = model(volumes)
                        loss, recon_loss, kl_loss, beta = criterion(reconstructed, volumes, mu, log_var)
                        current_beta = beta
                        # Scale loss by accumulation steps
                        loss = loss / config.accumulation_steps

                    # Mixed precision backward pass
                    scaler.scale(loss).backward()

                    # Gradient accumulation
                    if (batch_idx + 1) % config.accumulation_steps == 0 or (batch_idx + 1 == len(train_loader)):
                        # Clip gradients to prevent exploding gradients
                        if config.gradient_clip > 0:
                            scaler.unscale_(optimizer)
                            torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)

                        # Update weights
                        scaler.step(optimizer)
                        scaler.update()
                        optimizer.zero_grad()

                    # Track loss (using the non-scaled loss for reporting)
                    batch_loss = loss.item() * config.accumulation_steps
                    epoch_loss += batch_loss
                    epoch_recon_loss += recon_loss.item()
                    epoch_kl_loss += kl_loss.item()

                    # Update progress bars
                    train_pbar.set_postfix({
                        'loss': f"{batch_loss:.6f}",
                        'recon': f"{recon_loss.item():.6f}",
                        'kl': f"{kl_loss.item():.6f}",
                        'beta': f"{beta:.6f}"
                    })
                    total_pbar.update(1)

                    # Memory cleanup
                    del volumes, reconstructed, mu, log_var, loss, recon_loss, kl_loss
                    torch.cuda.empty_cache()

                except RuntimeError as e:
                    if "out of memory" in str(e):
                        print(f"\nOOM in batch {batch_idx}. Cleaning up...")
                        torch.cuda.empty_cache()
                        gc.collect()
                        # Skip this batch and continue
                        continue
                    else:
                        print(f"RuntimeError: {str(e)}")
                        raise e
                except Exception as e:
                    print(f"Unexpected error: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    raise e

            # Calculate average training losses
            avg_train_loss = epoch_loss / len(train_loader)
            avg_train_recon_loss = epoch_recon_loss / len(train_loader)
            avg_train_kl_loss = epoch_kl_loss / len(train_loader)

            train_losses.append(avg_train_loss)
            train_recon_losses.append(avg_train_recon_loss)
            train_kl_losses.append(avg_train_kl_loss)

            # Validation phase
            model.eval()
            val_loss = 0
            val_recon_loss_sum = 0
            val_kl_loss_sum = 0

            val_pbar = tqdm(val_loader,
                          desc=f'Epoch {epoch+1}/{config.epochs} [Val]',
                          leave=False,
                          position=1)

            with torch.no_grad():
                for batch in val_pbar:
                    try:
                        volumes = batch['volume'].to(device)
                        reconstructed, mu, log_var = model(volumes)
                        loss, recon_loss, kl_loss, _ = criterion(reconstructed, volumes, mu, log_var)

                        val_loss += loss.item()
                        val_recon_loss_sum += recon_loss.item()
                        val_kl_loss_sum += kl_loss.item()

                        val_pbar.set_postfix({
                            'loss': f"{loss.item():.6f}",
                            'recon': f"{recon_loss.item():.6f}",
                            'kl': f"{kl_loss.item():.6f}"
                        })

                        # Memory cleanup
                        del volumes, reconstructed, mu, log_var, loss, recon_loss, kl_loss
                        torch.cuda.empty_cache()

                    except RuntimeError as e:
                        if "out of memory" in str(e):
                            print("\nOOM during validation. Cleaning up...")
                            torch.cuda.empty_cache()
                            gc.collect()
                            continue
                        else:
                            print(f"RuntimeError during validation: {str(e)}")
                            raise e
                    except Exception as e:
                        print(f"Unexpected error during validation: {str(e)}")
                        import traceback
                        traceback.print_exc()
                        raise e

            # Calculate average validation losses
            avg_val_loss = val_loss / len(val_loader)
            avg_val_recon_loss = val_recon_loss_sum / len(val_loader)
            avg_val_kl_loss = val_kl_loss_sum / len(val_loader)

            val_losses.append(avg_val_loss)
            val_recon_losses.append(avg_val_recon_loss)
            val_kl_losses.append(avg_val_kl_loss)

            # Update learning rate
            scheduler.step(avg_val_loss)

            # Check if this is the best model
            is_best = avg_val_loss < best_val_loss
            if is_best:
                best_val_loss = avg_val_loss

            # Save checkpoint
            if (epoch + 1) % config.save_interval == 0 or is_best or (epoch + 1 == config.epochs):
                # Save additional loss components
                checkpoint_handler.save(
                    model, optimizer, scheduler,
                    epoch, train_losses, val_losses,
                    train_recon_losses, train_kl_losses,
                    val_recon_losses, val_kl_losses,
                    is_best=is_best
                )

            # Print epoch summary
            elapsed_time = time.time() - start_time
            time_per_epoch = elapsed_time / (epoch - start_epoch + 1) if epoch >= start_epoch else 0
            est_time_left = time_per_epoch * (config.epochs - epoch - 1)

            print(f"\nEpoch {epoch+1}/{config.epochs} completed in {time_per_epoch:.2f}s")
            print(f"Train Loss: {avg_train_loss:.6f} (Recon: {avg_train_recon_loss:.6f}, KL: {avg_train_kl_loss:.6f})")
            print(f"Val Loss: {avg_val_loss:.6f} (Recon: {avg_val_recon_loss:.6f}, KL: {avg_val_kl_loss:.6f})")
            print(f"Learning rate: {optimizer.param_groups[0]['lr']:.8f}")
            print(f"Beta value: {current_beta:.6f}")
            print(f"Est. time remaining: {est_time_left/60:.2f} minutes")
            print_memory_stats()

            # Early stopping check
            if early_stopping(avg_val_loss, epoch):
                if early_stopping.early_stop:
                    print("\nEarly stopping triggered!")
                    break

    except KeyboardInterrupt:
        print("\nTraining interrupted by user!")
        # Still save the model
        checkpoint_handler.save(
            model, optimizer, scheduler,
            epoch, train_losses, val_losses,
            train_recon_losses, train_kl_losses,
            val_recon_losses, val_kl_losses,
            is_best=False
        )

    finally:
        # Close progress bars
        if 'total_pbar' in locals():
            total_pbar.close()

        # Plot training history
        plt.figure(figsize=(15, 10))

        # Plot total loss
        plt.subplot(2, 2, 1)
        plt.plot(train_losses, label='Train Loss')
        plt.plot(val_losses, label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Total Loss')
        plt.title('Total Loss History')
        plt.legend()
        plt.grid(True)

        # Plot reconstruction loss
        plt.subplot(2, 2, 2)
        plt.plot(train_recon_losses, label='Train Recon Loss')
        plt.plot(val_recon_losses, label='Val Recon Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Reconstruction Loss')
        plt.title('Reconstruction Loss History')
        plt.legend()
        plt.grid(True)

        # Plot KL loss
        plt.subplot(2, 2, 3)
        plt.plot(train_kl_losses, label='Train KL Loss')
        plt.plot(val_kl_losses, label='Val KL Loss')
        plt.xlabel('Epoch')
        plt.ylabel('KL Divergence Loss')
        plt.title('KL Divergence Loss History')
        plt.legend()
        plt.grid(True)

        # Plot recent total loss (last 30 epochs or all if < 30)
        plt.subplot(2, 2, 4)
        recent = min(30, len(train_losses))
        if recent > 5:  # Only plot recent history if we have enough epochs
            plt.plot(train_losses[-recent:], label='Train Loss')
            plt.plot(val_losses[-recent:], label='Validation Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Total Loss')
            plt.title(f'Last {recent} Epochs')
            plt.legend()
            plt.grid(True)

        plt.tight_layout()
        plt.savefig(os.path.join(config.checkpoint_dir, f"{config.model_name}_training_history.png"))
        plt.show()

        # Print final training summary
        total_time = time.time() - start_time
        print(f"\nTraining completed in {total_time/60:.2f} minutes")
        print(f"Best validation loss: {best_val_loss:.6f}")

        return {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_recon_losses': train_recon_losses,
            'train_kl_losses': train_kl_losses,
            'val_recon_losses': val_recon_losses,
            'val_kl_losses': val_kl_losses,
            'best_val_loss': best_val_loss,
            'model': model
        }

"""### Training"""

# Example usage to train the VAE
if __name__ == "__main__":
    # Create the VAE model
    model = VAE(latent_dim=256)

    # Create VAE configuration
    config = VAEConfig(
        latent_dim=256,
        batch_size=8,
        accumulation_steps=8,        # Effective batch size = 64
        learning_rate=2e-5,
        epochs=300,
        beta=0.0005,                 # Reduced from 0.005 to 0.0005 (10x smaller)
        beta_warmup_steps=10000,      # Increased from 2000 to 10000
        early_stopping_patience=20,
        use_mixed_precision=True,
        num_workers=4,
        model_name="vae_model_v2"    # New model name to avoid overwriting
    )

    # Train the VAE
    results = train_vae(model, train_loader, val_loader, config)

# Extra test - Vae v6
if __name__ == "__main__":
    # Create the VAE model
    model = VAE(latent_dim=256)

    # Create VAE configuration
    config = VAEConfig(
        latent_dim=256,
        batch_size=8,
        accumulation_steps=8,        # Effective batch size = 64
        learning_rate=2e-5,
        epochs=300,
        beta=0.001,                 # Reduced from 0.005 to 0.0005 (10x smaller)
        beta_warmup_steps=2000,      # Increased from 2000 to 10000
        early_stopping_patience=20,
        use_mixed_precision=True,
        num_workers=4,
        model_name="vae_model_v6"    # New model name to avoid overwriting
    )

    # Train the VAE
    results = train_vae(model, train_loader, val_loader, config)

"""### Evaluation and Result Visualization"""

# Cell 18: VAE Evaluation and Visualization
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import json
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import seaborn as sns
from tqdm import tqdm
import gc

def load_trained_vae(checkpoint_dir, model_name='vae_model_v2', latent_dim=256):
    """Load trained VAE model for evaluation with robust error handling"""
    model_path = Path(checkpoint_dir) / f"{model_name}_best.pth"
    checkpoint_path = Path(checkpoint_dir) / f"{model_name}_checkpoint.pth"
    metadata_path = Path(checkpoint_dir) / f"{model_name}_metadata.json"

    # Set device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Create VAE model
    model = VAE(latent_dim=latent_dim)

    # Load model weights with error handling
    try:
        if model_path.exists():
            print(f"Loading best VAE model from {model_path}")
            model.load_state_dict(torch.load(model_path, map_location=device))
        elif checkpoint_path.exists():
            print(f"Best model not found. Loading from checkpoint at {checkpoint_path}")
            checkpoint = torch.load(checkpoint_path, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"Loaded VAE checkpoint from epoch {checkpoint.get('epoch', 'unknown')}")
        else:
            raise FileNotFoundError(f"No VAE model found at {model_path} or {checkpoint_path}")
    except Exception as e:
        print(f"Error loading VAE model: {str(e)}")
        print("Available files in directory:")
        for file in Path(checkpoint_dir).glob("*"):
            print(f" - {file.name}")
        raise

    # Load training history
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        print(f"Loaded training history with {len(metadata.get('train_losses', []))} epochs")
    else:
        metadata = {"train_losses": [], "val_losses": [],
                   "train_recon_losses": [], "train_kl_losses": [],
                   "val_recon_losses": [], "val_kl_losses": []}
        print("No metadata found, using empty history")

    # Move model to device and set to evaluation mode
    model.eval()
    model.to(device)

    return model, metadata

def plot_vae_training_history(metadata):
    """Plot full VAE training history including component losses"""
    plt.figure(figsize=(15, 10))

    # Extract loss data from metadata
    train_losses = metadata.get("train_losses", [])
    val_losses = metadata.get("val_losses", [])
    train_recon_losses = metadata.get("train_recon_losses", [])
    train_kl_losses = metadata.get("train_kl_losses", [])
    val_recon_losses = metadata.get("val_recon_losses", [])
    val_kl_losses = metadata.get("val_kl_losses", [])

    # 1. Plot total loss (train & validation)
    plt.subplot(2, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Total Loss')
    plt.title('Total Loss History')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 2. Plot reconstruction loss (train & validation)
    plt.subplot(2, 2, 2)
    plt.plot(train_recon_losses, label='Train Recon Loss')
    plt.plot(val_recon_losses, label='Val Recon Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Reconstruction Loss')
    plt.title('Reconstruction Loss History')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 3. Plot KL loss (train & validation)
    plt.subplot(2, 2, 3)
    plt.plot(train_kl_losses, label='Train KL Loss')
    plt.plot(val_kl_losses, label='Val KL Loss')
    plt.xlabel('Epoch')
    plt.ylabel('KL Divergence Loss')
    plt.title('KL Divergence Loss History')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 4. Plot recent total loss (last 30 epochs or all if < 30)
    plt.subplot(2, 2, 4)
    recent = min(30, len(train_losses))
    if recent > 5:  # Only plot recent history if we have enough epochs
        plt.plot(train_losses[-recent:], label='Train Loss')
        plt.plot(val_losses[-recent:], label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Total Loss')
        plt.title(f'Last {recent} Epochs')
        plt.legend()
        plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

def visualize_vae_reconstructions(model, dataloader, num_samples=3):
    """Visualize original vs reconstructed volumes from VAE with anatomically relevant slices"""
    device = next(model.parameters()).device

    # Get samples from dataloader
    samples = []
    labels = []

    for batch in dataloader:
        volumes = batch['volume']
        batch_labels = batch['label']

        for i in range(min(len(volumes), num_samples - len(samples))):
            samples.append(volumes[i:i+1])
            labels.append(batch_labels[i])

        if len(samples) >= num_samples:
            break

    # Visualize each sample
    with torch.no_grad():
        for idx, (sample, label) in enumerate(zip(samples, labels)):
            # Get original volume
            orig_vol = sample.to(device)

            # Generate reconstruction
            reconstructed, mu, log_var = model(orig_vol)

            # Move to CPU for visualization
            orig_vol_np = orig_vol.cpu().squeeze().numpy()
            recon_vol_np = reconstructed.cpu().squeeze().numpy()

            # Create figure for this sample
            fig = plt.figure(figsize=(16, 12))
            plt.suptitle(f"VAE Sample {idx+1} - Group: {label}", fontsize=16)

            # Define anatomically relevant slices
            axial_slice = 32      # Axial view - slice 32
            coronal_slice = 50    # Coronal view - slice 50
            sagittal_slice1 = 55  # Sagittal view - slice 55
            sagittal_slice2 = 70  # Sagittal view - slice 70

            # Plot original slices - top row
            plt.subplot(2, 4, 1)
            plt.imshow(orig_vol_np[axial_slice], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Axial (z={axial_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 2)
            plt.imshow(orig_vol_np[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Coronal (y={coronal_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 3)
            plt.imshow(orig_vol_np[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Sagittal (x={sagittal_slice1})")
            plt.axis('off')

            plt.subplot(2, 4, 4)
            plt.imshow(orig_vol_np[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Original - Sagittal (x={sagittal_slice2})")
            plt.axis('off')

            # Plot reconstructed slices - bottom row
            plt.subplot(2, 4, 5)
            plt.imshow(recon_vol_np[axial_slice], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Axial (z={axial_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 6)
            plt.imshow(recon_vol_np[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Coronal (y={coronal_slice})")
            plt.axis('off')

            plt.subplot(2, 4, 7)
            plt.imshow(recon_vol_np[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Sagittal (x={sagittal_slice1})")
            plt.axis('off')

            plt.subplot(2, 4, 8)
            plt.imshow(recon_vol_np[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
            plt.title(f"Reconstructed - Sagittal (x={sagittal_slice2})")
            plt.axis('off')

            plt.tight_layout()
            plt.show()

def extract_vae_latent_vectors(model, dataloader, max_samples=200):
    """Extract latent vectors from VAE encoder"""
    device = next(model.parameters()).device

    latent_means = []
    latent_logvars = []
    labels = []
    paths = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting VAE latent vectors"):
            try:
                volumes = batch['volume'].to(device)
                batch_labels = batch['label']
                batch_paths = batch['path']

                # Extract latent vectors (both mean and log_var)
                mu, log_var = model.encode(volumes)

                # Store results
                latent_means.append(mu.cpu().numpy())
                latent_logvars.append(log_var.cpu().numpy())
                labels.extend(batch_labels)
                paths.extend(batch_paths)

                # Memory cleanup
                del volumes, mu, log_var
                torch.cuda.empty_cache()

                # Check if we have enough samples
                if max_samples and len(labels) >= max_samples:
                    latent_means = np.vstack(latent_means)
                    latent_logvars = np.vstack(latent_logvars)
                    latent_means = latent_means[:max_samples]
                    latent_logvars = latent_logvars[:max_samples]
                    labels = labels[:max_samples]
                    paths = paths[:max_samples]
                    break

            except Exception as e:
                print(f"Error processing batch: {str(e)}")
                continue

    # Stack all latent vectors if we didn't break early
    if isinstance(latent_means[0], np.ndarray):
        latent_means = np.vstack(latent_means)
        latent_logvars = np.vstack(latent_logvars)

    return latent_means, latent_logvars, labels, paths

def visualize_latent_space(latent_vectors, labels, method='tsne'):
    """Visualize latent space using t-SNE or PCA"""
    plt.figure(figsize=(10, 8))

    # Create label-to-color mapping for consistent colors
    unique_labels = list(set(labels))
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    label_to_color = {label: colors[i] for i, label in enumerate(unique_labels)}

    # Apply dimensionality reduction
    if method.lower() == 'tsne':
        print("Computing t-SNE projection...")
        reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, len(latent_vectors) - 1))
        title = 't-SNE Visualization of VAE Latent Space'
    else:
        print("Computing PCA projection...")
        reducer = PCA(n_components=2, random_state=42)
        title = 'PCA Visualization of VAE Latent Space'

    # Apply reduction
    reduced_vecs = reducer.fit_transform(latent_vectors)

    # Create scatter plot
    for label in unique_labels:
        # Get indices where this label appears
        indices = [i for i, l in enumerate(labels) if l == label]

        # Plot these points
        plt.scatter(
            reduced_vecs[indices, 0],
            reduced_vecs[indices, 1],
            label=label,
            color=label_to_color[label],
            alpha=0.7,
            edgecolor='w',
            s=100
        )

    plt.title(title, fontsize=14)
    plt.xlabel("Dimension 1", fontsize=12)
    plt.ylabel("Dimension 2", fontsize=12)
    plt.legend(title="Group", fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    return reduced_vecs

def plot_latent_dimension_activation(latent_vectors, labels):
    """Analyze activation patterns of latent dimensions"""
    # Create a DataFrame with latent dimensions and labels
    import pandas as pd

    # First, convert labels to categorical for better plotting
    unique_labels = list(set(labels))
    label_map = {label: i for i, label in enumerate(unique_labels)}
    label_indices = [label_map[label] for label in labels]

    # Create DataFrames
    latent_df = pd.DataFrame(latent_vectors)
    latent_df['label'] = labels

    # Compute mean activation by group
    mean_activations = {}
    for label in unique_labels:
        group_vectors = latent_vectors[np.array(labels) == label]
        mean_activations[label] = np.mean(group_vectors, axis=0)

    # Identify top discriminative dimensions
    activation_matrix = np.vstack([mean_activations[label] for label in unique_labels])
    variance = np.var(activation_matrix, axis=0)
    top_dims = np.argsort(variance)[-10:]  # Top 10 dimensions

    # Plot mean activation for top dimensions
    plt.figure(figsize=(14, 6))

    # Plot heatmap
    plt.subplot(1, 2, 1)
    heatmap_data = pd.DataFrame({
        f"Dim {i}": [mean_activations[label][i] for label in unique_labels]
        for i in top_dims
    })
    heatmap_data.index = unique_labels

    sns.heatmap(heatmap_data, cmap='coolwarm', center=0,
               annot=True, fmt=".2f", cbar_kws={'label': 'Mean Activation'})
    plt.title("Mean Activation of Top Discriminative Dimensions")

    # Plot box plots for top 5 dimensions
    plt.subplot(1, 2, 2)

    # Create data for boxplot
    plot_data = []
    labels_for_plot = []
    positions = []

    for i, dim in enumerate(top_dims[:5]):  # Top 5 for clarity
        for j, label in enumerate(unique_labels):
            group_values = latent_vectors[np.array(labels) == label, dim]
            plot_data.append(group_values)
            labels_for_plot.append(f"{label}")
            positions.append(i + j * 0.25)

    # Create boxplot
    boxplot = plt.boxplot(plot_data, positions=positions, patch_artist=True, widths=0.15)

    # Customize boxplot colors
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    for i, label in enumerate(unique_labels):
        indices = [j for j, l in enumerate(labels_for_plot) if l == label]
        for idx in indices:
            boxplot['boxes'][idx].set_facecolor(colors[i])

    # Add labels and ticks
    plt.xticks([i + (len(unique_labels) - 1) * 0.125 for i in range(5)],
              [f"Dim {d}" for d in top_dims[:5]])
    plt.title("Distribution of Top 5 Discriminative Dimensions")
    plt.ylabel("Activation Value")

    # Add legend
    for i, label in enumerate(unique_labels):
        plt.plot([], [], 'o', color=colors[i], label=label)
    plt.legend(title="Group")

    plt.tight_layout()
    plt.show()

    return top_dims

def compute_reconstruction_error(model, dataloader):
    """Compute detailed reconstruction error metrics on validation set"""
    device = next(model.parameters()).device
    criterion = nn.MSELoss(reduction='none')

    total_mse = 0
    total_samples = 0
    error_by_label = {}
    kl_by_label = {}

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Computing metrics"):
            volumes = batch['volume'].to(device)
            labels = batch['label']

            # Get reconstructions and latent variables
            reconstructed, mu, log_var = model(volumes)

            # Compute MSE loss per sample
            mse = criterion(reconstructed, volumes)

            # Average over dimensions
            mse = mse.mean(dim=(1, 2, 3, 4)).cpu().numpy()

            # Compute KL divergence
            kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1).cpu().numpy()

            # Track overall error
            total_mse += mse.sum()
            total_samples += volumes.shape[0]

            # Track error by label
            for i, label in enumerate(labels):
                if label not in error_by_label:
                    error_by_label[label] = []
                    kl_by_label[label] = []
                error_by_label[label].append(mse[i])
                kl_by_label[label].append(kl_div[i])

    # Calculate overall metrics
    avg_mse = total_mse / total_samples
    rmse = np.sqrt(avg_mse)

    print("\nReconstruction Error Metrics:")
    print(f"Overall MSE: {avg_mse:.6f}")
    print(f"Overall RMSE: {rmse:.6f}")

    # Calculate metrics by group
    print("\nReconstruction Error by Group:")
    for label, errors in error_by_label.items():
        group_mse = np.mean(errors)
        group_rmse = np.sqrt(group_mse)
        group_std = np.std(errors)
        group_kl = np.mean(kl_by_label[label])
        print(f"{label}:")
        print(f"  MSE: {group_mse:.6f} ± {group_std:.6f}")
        print(f"  RMSE: {group_rmse:.6f}")
        print(f"  KL Divergence: {group_kl:.6f}")

    # Plot error distribution by group
    plt.figure(figsize=(15, 6))

    # MSE Distribution
    plt.subplot(1, 2, 1)
    for label, errors in error_by_label.items():
        sns.histplot(errors, alpha=0.5, label=label, bins=20, kde=True)
    plt.title("Reconstruction Error Distribution by Group")
    plt.xlabel("Mean Squared Error")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(True, alpha=0.3)

    # KL Divergence Distribution
    plt.subplot(1, 2, 2)
    for label, kl_values in kl_by_label.items():
        sns.histplot(kl_values, alpha=0.5, label=label, bins=20, kde=True)
    plt.title("KL Divergence Distribution by Group")
    plt.xlabel("KL Divergence")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    return avg_mse, error_by_label, kl_by_label

def find_vae_outliers(model, dataloader, threshold_std=2.5):
    """Identify outliers based on reconstruction error"""
    device = next(model.parameters()).device
    criterion = nn.MSELoss(reduction='none')

    all_errors = []
    all_paths = []
    all_labels = []
    all_kl_divs = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Finding outliers"):
            volumes = batch['volume'].to(device)
            paths = batch['path']
            labels = batch['label']

            # Get reconstructions and latent variables
            reconstructed, mu, log_var = model(volumes)

            # Compute MSE loss per sample
            mse = criterion(reconstructed, volumes)

            # Average over dimensions
            mse = mse.mean(dim=(1, 2, 3, 4)).cpu().numpy()

            # Compute KL divergence
            kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1).cpu().numpy()

            # Store results
            all_errors.extend(mse)
            all_paths.extend(paths)
            all_labels.extend(labels)
            all_kl_divs.extend(kl_div)

    # Convert to numpy arrays
    all_errors = np.array(all_errors)
    all_kl_divs = np.array(all_kl_divs)

    # Compute statistics
    mean_error = np.mean(all_errors)
    std_error = np.std(all_errors)

    # Find outliers (samples with error > mean + threshold_std * std)
    threshold = mean_error + threshold_std * std_error
    outlier_indices = np.where(all_errors > threshold)[0]

    print(f"\nOutlier Analysis:")
    print(f"Mean error: {mean_error:.6f}")
    print(f"Error standard deviation: {std_error:.6f}")
    print(f"Outlier threshold: {threshold:.6f}")
    print(f"Found {len(outlier_indices)} outliers out of {len(all_errors)} samples ({len(outlier_indices)/len(all_errors)*100:.2f}%)")

    # Create dictionary of outliers
    outliers = {
        all_paths[i]: {
            'error': all_errors[i],
            'label': all_labels[i],
            'kl_div': all_kl_divs[i],
            'z_score': (all_errors[i] - mean_error) / std_error
        }
        for i in outlier_indices
    }

    # Plot error distribution with outlier threshold
    plt.figure(figsize=(15, 6))

    # Plot MSE distribution
    plt.subplot(1, 2, 1)
    plt.hist(all_errors, bins=30, alpha=0.7)
    plt.axvline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold_std} std)')
    plt.title("Reconstruction Error Distribution")
    plt.xlabel("Mean Squared Error")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Plot error vs KL divergence, highlighting outliers
    plt.subplot(1, 2, 2)
    plt.scatter(all_errors, all_kl_divs, alpha=0.5, s=20, label="Normal samples")

    # Highlight outliers
    outlier_errors = [all_errors[i] for i in outlier_indices]
    outlier_kl_divs = [all_kl_divs[i] for i in outlier_indices]
    plt.scatter(outlier_errors, outlier_kl_divs, color='r', s=50, label="Outliers")

    plt.axvline(threshold, color='r', linestyle='--')
    plt.title("Error vs KL Divergence")
    plt.xlabel("Reconstruction Error (MSE)")
    plt.ylabel("KL Divergence")
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    return outliers, all_errors, all_paths, all_labels

def visualize_vae_outliers(model, outliers, top_n=5):
    """Visualize the top outliers with highest reconstruction error"""
    device = next(model.parameters()).device

    # Sort outliers by error (descending)
    sorted_outliers = sorted(outliers.items(), key=lambda x: x[1]['error'], reverse=True)

    # Visualize top outliers
    num_outliers = min(top_n, len(sorted_outliers))

    for i in range(num_outliers):
        path, info = sorted_outliers[i]
        error = info['error']
        label = info['label']
        z_score = info['z_score']
        kl_div = info['kl_div']

        try:
            # Load the original volume
            with torch.no_grad():
                # Load DICOM file
                original_volume, _ = load_dicom(path)
                original_volume = original_volume[9:73, :, :]

                # Process volume
                norm_vol, _, _ = process_volume(original_volume, target_shape=(64, 128, 128))

                # Convert to tensor and add batch dimension
                vol_tensor = torch.from_numpy(np.expand_dims(norm_vol, axis=(0, 1))).float().to(device)

                # Get reconstruction
                reconstructed, mu, log_var = model(vol_tensor)

                # Move tensors to CPU and remove batch and channel dimensions
                vol_np = vol_tensor.cpu().squeeze().numpy()
                recon_np = reconstructed.cpu().squeeze().numpy()

                # Create figure
                fig = plt.figure(figsize=(16, 12))
                plt.suptitle(f"Outlier {i+1}: {path.split('/')[-1]}\nGroup: {label}, Error: {error:.6f}, Z-score: {z_score:.2f}, KL Div: {kl_div:.2f}", fontsize=14)

                # Define anatomically relevant slices
                axial_slice = 32      # Axial view - slice 32
                coronal_slice = 50    # Coronal view - slice 50
                sagittal_slice1 = 55  # Sagittal view - slice 55
                sagittal_slice2 = 70  # Sagittal view - slice 70

                # Plot original slices - top row
                plt.subplot(2, 4, 1)
                plt.imshow(vol_np[axial_slice], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Axial (z={axial_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 2)
                plt.imshow(vol_np[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Coronal (y={coronal_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 3)
                plt.imshow(vol_np[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Sagittal (x={sagittal_slice1})")
                plt.axis('off')

                plt.subplot(2, 4, 4)
                plt.imshow(vol_np[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Original - Sagittal (x={sagittal_slice2})")
                plt.axis('off')

                # Plot reconstructed slices - bottom row
                plt.subplot(2, 4, 5)
                plt.imshow(recon_np[axial_slice], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Axial (z={axial_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 6)
                plt.imshow(recon_np[:, coronal_slice, :], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Coronal (y={coronal_slice})")
                plt.axis('off')

                plt.subplot(2, 4, 7)
                plt.imshow(recon_np[:, :, sagittal_slice1], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Sagittal (x={sagittal_slice1})")
                plt.axis('off')

                plt.subplot(2, 4, 8)
                plt.imshow(recon_np[:, :, sagittal_slice2], cmap='gray', vmin=0, vmax=3)
                plt.title(f"Reconstructed - Sagittal (x={sagittal_slice2})")
                plt.axis('off')

                plt.tight_layout()
                plt.show()

        except Exception as e:
            print(f"Error visualizing outlier {path}: {e}")

def visualize_vae_latent_dimension(model, dataloader, dimension_idx, alpha=5.0, group=None):
    """
    Visualize what a specific VAE latent dimension represents by modifying it
    and observing the effect on brain reconstruction.

    Parameters:
        model: Trained VAE model
        dataloader: DataLoader containing samples
        dimension_idx: The latent dimension to manipulate (e.g., 63)
        alpha: Strength of the dimension manipulation
        group: Optional filter for specific patient group (e.g., 'PD', 'Control')
    """
    device = next(model.parameters()).device
    model.eval()

    # Find a suitable sample (optionally from specific group)
    for batch in dataloader:
        volumes = batch['volume']
        labels = batch['label']
        paths = batch['path']

        if group is not None:
            # Find samples from the specified group
            group_indices = [i for i, label in enumerate(labels) if label == group]
            if not group_indices:
                continue
            # Use the first matching sample
            idx = group_indices[0]
            sample = volumes[idx:idx+1].to(device)
            sample_label = labels[idx]
            sample_path = paths[idx]
        else:
            # Just use the first sample
            sample = volumes[0:1].to(device)
            sample_label = labels[0]
            sample_path = paths[0]

        break  # Exit after finding a sample

    with torch.no_grad():
        # Encode the sample to get its latent representation
        mu, log_var = model.encode(sample)
        z = model.reparameterize(mu, log_var)

        # Create modified latent vectors
        z_plus = z.clone()
        z_minus = z.clone()

        # Modify the specific dimension
        z_plus[0, dimension_idx] += alpha
        z_minus[0, dimension_idx] -= alpha

        # Decode the original and modified latent vectors
        original_reconstruction = model.decoder(z)
        plus_reconstruction = model.decoder(z_plus)
        minus_reconstruction = model.decoder(z_minus)

        # Move tensors to CPU and convert to numpy for visualization
        original_vol = original_reconstruction.cpu().squeeze().numpy()
        plus_vol = plus_reconstruction.cpu().squeeze().numpy()
        minus_vol = minus_reconstruction.cpu().squeeze().numpy()

        # Calculate the difference maps
        plus_diff = plus_vol - original_vol
        minus_diff = minus_vol - original_vol

        # Set up the figure
        fig = plt.figure(figsize=(18, 15))
        plt.suptitle(f"Visualization of VAE Dimension {dimension_idx} in Brain Space\nPatient Group: {sample_label}", fontsize=16)

        # Define anatomically relevant slices
        slices = {
            'axial': 32,       # Axial z=32
            'coronal': 50,     # Coronal y=50
            'sagittal1': 55,   # Sagittal x=55
            'sagittal2': 70    # Sagittal x=70
        }

        # Create a custom colormap for difference maps
        diff_cmap = plt.cm.RdBu_r  # Red-Blue colormap with red for negative, blue for positive

        # Row 1: Original reconstruction
        plt.subplot(5, 4, 1)
        plt.imshow(original_vol[slices['axial']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Original (Axial z={slices['axial']})")
        plt.axis('off')

        plt.subplot(5, 4, 2)
        plt.imshow(original_vol[:, slices['coronal'], :], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Original (Coronal y={slices['coronal']})")
        plt.axis('off')

        plt.subplot(5, 4, 3)
        plt.imshow(original_vol[:, :, slices['sagittal1']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Original (Sagittal x={slices['sagittal1']})")
        plt.axis('off')

        plt.subplot(5, 4, 4)
        plt.imshow(original_vol[:, :, slices['sagittal2']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Original (Sagittal x={slices['sagittal2']})")
        plt.axis('off')

        # Row 2: Increased dimension
        plt.subplot(5, 4, 5)
        plt.imshow(plus_vol[slices['axial']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 6)
        plt.imshow(plus_vol[:, slices['coronal'], :], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 7)
        plt.imshow(plus_vol[:, :, slices['sagittal1']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 8)
        plt.imshow(plus_vol[:, :, slices['sagittal2']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} + {alpha}")
        plt.axis('off')

        # Row 3: Decreased dimension
        plt.subplot(5, 4, 9)
        plt.imshow(minus_vol[slices['axial']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 10)
        plt.imshow(minus_vol[:, slices['coronal'], :], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 11)
        plt.imshow(minus_vol[:, :, slices['sagittal1']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        plt.subplot(5, 4, 12)
        plt.imshow(minus_vol[:, :, slices['sagittal2']], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Dim {dimension_idx} - {alpha}")
        plt.axis('off')

        # Row 4: Difference map (increased - original)
        plt.subplot(5, 4, 13)
        im1 = plt.imshow(plus_diff[slices['axial']], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (+)")
        plt.axis('off')

        plt.subplot(5, 4, 14)
        plt.imshow(plus_diff[:, slices['coronal'], :], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (+)")
        plt.axis('off')

        plt.subplot(5, 4, 15)
        plt.imshow(plus_diff[:, :, slices['sagittal1']], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (+)")
        plt.axis('off')

        plt.subplot(5, 4, 16)
        plt.imshow(plus_diff[:, :, slices['sagittal2']], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (+)")
        plt.axis('off')

        # Row 5: Difference map (decreased - original)
        plt.subplot(5, 4, 17)
        im2 = plt.imshow(minus_diff[slices['axial']], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (-)")
        plt.axis('off')

        plt.subplot(5, 4, 18)
        plt.imshow(minus_diff[:, slices['coronal'], :], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (-)")
        plt.axis('off')

        plt.subplot(5, 4, 19)
        plt.imshow(minus_diff[:, :, slices['sagittal1']], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (-)")
        plt.axis('off')

        plt.subplot(5, 4, 20)
        plt.imshow(minus_diff[:, :, slices['sagittal2']], cmap=diff_cmap, vmin=-0.5, vmax=0.5)
        plt.title(f"Difference (-)")
        plt.axis('off')

        # Add colorbar for difference maps
        cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.3])
        cbar = plt.colorbar(im1, cax=cbar_ax)
        cbar.set_label('Difference Intensity')

        plt.tight_layout()
        plt.subplots_adjust(top=0.92, right=0.9)
        plt.show()

        # Return both the sample info and reconstructions for further analysis
        return {
            'label': sample_label,
            'path': sample_path,
            'original': original_vol,
            'plus': plus_vol,
            'minus': minus_vol,
            'plus_diff': plus_diff,
            'minus_diff': minus_diff
        }

# Run VAE evaluation
if __name__ == "__main__":
    try:
        print("=== Starting VAE Evaluation ===")

        # Load trained VAE model
        print("\nLoading trained VAE model...")
        vae_model, vae_metadata = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

        # 1. Plot training history
        print("\nPlotting VAE training history...")
        plot_vae_training_history(vae_metadata)

        # 2. Visualize reconstructions
        print("\nVisualizing VAE reconstructions...")
        visualize_vae_reconstructions(vae_model, val_loader, num_samples=3)

        # 3. Extract latent vectors from VAE
        print("\nExtracting latent vectors from VAE...")
        latent_means, latent_logvars, labels, paths = extract_vae_latent_vectors(vae_model, val_loader, max_samples=200)

        # 4. Visualize latent space with t-SNE and PCA
        print("\nVisualizing latent space with t-SNE...")
        tsne_result = visualize_latent_space(latent_means, labels, method='tsne')

        print("\nVisualizing latent space with PCA...")
        pca_result = visualize_latent_space(latent_means, labels, method='pca')

        # 5. Analyze discriminative dimensions
        print("\nAnalyzing discriminative dimensions in latent space...")
        top_dims = plot_latent_dimension_activation(latent_means, labels)

        # 6. Compute and visualize reconstruction error
        print("\nComputing reconstruction error metrics...")
        avg_mse, error_by_label, kl_by_label = compute_reconstruction_error(vae_model, val_loader)

        # 7. Find and visualize outliers
        print("\nFinding and visualizing outliers...")
        outliers, all_errors, all_paths, all_labels = find_vae_outliers(vae_model, val_loader, threshold_std=2.5)
        visualize_vae_outliers(vae_model, outliers)

        # 8. Visualize latent dimensions in brain space
        print("\nVisualizing discriminative dimensions in brain space...")
        for dim in [63, 34, 123]:  # Specified dimensions
            visualize_vae_latent_dimension(vae_model, val_loader, dimension_idx=dim, alpha=5.0)

        print("\nVAE Evaluation completed successfully!")

    except Exception as e:
        print(f"Error during VAE evaluation: {str(e)}")
        import traceback
        traceback.print_exc()

# Cell 19: VAE Feature Importance Maps and Uncertainty Visualization with Consistent Scales
import torch
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import gc
from matplotlib.colors import LinearSegmentedColormap

def generate_vae_feature_importance_map(model, dataloader, dimension_idx, group=None, num_samples=5):
    """
    Generate feature importance map for a specific VAE latent dimension
    by aggregating effects across multiple samples using anatomically relevant slices.
    Uses consistent scales across all views for better comparison.

    Parameters:
        model: Trained VAE model
        dataloader: DataLoader containing samples
        dimension_idx: The latent dimension to analyze
        group: Optional filter for specific patient group
        num_samples: Number of samples to aggregate
    """
    device = next(model.parameters()).device
    model.eval()

    # Storage for aggregated results
    aggregated_plus_diff = None
    aggregated_minus_diff = None
    sample_count = 0

    # Storage for encoding statistics
    mu_values = []
    logvar_values = []

    # Find samples (optionally from specific group)
    for batch in dataloader:
        volumes = batch['volume']
        labels = batch['label']

        if group is not None:
            # Find samples from the specified group
            group_indices = [i for i, label in enumerate(labels) if label == group]
            indices = group_indices
        else:
            # Use all samples in batch
            indices = range(len(volumes))

        for idx in indices:
            if sample_count >= num_samples:
                break

            sample = volumes[idx:idx+1].to(device)

            with torch.no_grad():
                # Encode the sample to get mean and log_var
                mu, log_var = model.encode(sample)

                # Store these for uncertainty analysis
                mu_values.append(mu[0, dimension_idx].cpu().item())
                logvar_values.append(log_var[0, dimension_idx].cpu().item())

                # Use mean as the latent vector (no sampling in evaluation)
                z = mu.clone()

                # Create modified latent vectors
                z_plus = z.clone()
                z_minus = z.clone()

                # Modify the specific dimension
                z_plus[0, dimension_idx] += 5.0
                z_minus[0, dimension_idx] -= 5.0

                # Decode the vectors
                original_reconstruction = model.decoder(z)
                plus_reconstruction = model.decoder(z_plus)
                minus_reconstruction = model.decoder(z_minus)

                # Calculate the difference maps
                plus_diff = (plus_reconstruction - original_reconstruction).cpu().squeeze().numpy()
                minus_diff = (minus_reconstruction - original_reconstruction).cpu().squeeze().numpy()

                # Aggregate the difference maps
                if aggregated_plus_diff is None:
                    aggregated_plus_diff = plus_diff
                    aggregated_minus_diff = minus_diff
                else:
                    aggregated_plus_diff += plus_diff
                    aggregated_minus_diff += minus_diff

                sample_count += 1

        if sample_count >= num_samples:
            break

    # Average the difference maps
    aggregated_plus_diff /= sample_count
    aggregated_minus_diff /= sample_count

    # Compute absolute importance map (average of plus and minus effects)
    importance_map = (np.abs(aggregated_plus_diff) + np.abs(aggregated_minus_diff)) / 2

    # Define anatomically relevant slices
    axial_slice = 32      # Axial view - slice 32
    coronal_slice = 50    # Coronal view - slice 50
    sagittal_slice1 = 55  # Sagittal view - slice 55
    sagittal_slice2 = 70  # Sagittal view - slice 70

    # Determine global max value for importance maps for consistent scale
    importance_max = np.max(importance_map)

    # Determine global min/max for activation maps for consistent scale
    activation_min = min(np.min(aggregated_plus_diff), np.min(aggregated_minus_diff))
    activation_max = max(np.max(aggregated_plus_diff), np.max(aggregated_minus_diff))
    # Make the activation scale symmetric around zero
    activation_abs_max = max(abs(activation_min), abs(activation_max))
    activation_vmin, activation_vmax = -activation_abs_max, activation_abs_max

    # Visualize the importance map
    fig = plt.figure(figsize=(16, 8))
    plt.suptitle(f"VAE Feature Importance Map for Dimension {dimension_idx}" +
                (f" (Group: {group})" if group else ""), fontsize=16)

    # Plot axial, coronal, and sagittal views for importance map - all with same scale
    plt.subplot(2, 4, 1)
    im1 = plt.imshow(importance_map[axial_slice], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Axial (z={axial_slice})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 2)
    plt.imshow(importance_map[:, coronal_slice, :], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Coronal (y={coronal_slice})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 3)
    plt.imshow(importance_map[:, :, sagittal_slice1], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Sagittal (x={sagittal_slice1})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 4)
    plt.imshow(importance_map[:, :, sagittal_slice2], cmap='hot', vmin=0, vmax=importance_max)
    plt.title(f"Sagittal (x={sagittal_slice2})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    # Plot activating direction (positive difference) with consistent scale
    plt.subplot(2, 4, 5)
    im2 = plt.imshow(aggregated_plus_diff[axial_slice], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Axial")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 6)
    plt.imshow(aggregated_plus_diff[:, coronal_slice, :], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Coronal")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 7)
    plt.imshow(aggregated_plus_diff[:, :, sagittal_slice1], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Sagittal 1")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 8)
    plt.imshow(aggregated_plus_diff[:, :, sagittal_slice2], cmap='bwr', vmin=activation_vmin, vmax=activation_vmax)
    plt.title(f"Activating Direction - Sagittal 2")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # Print information about scales used
    print(f"Importance Map Scale: 0 to {importance_max:.3f}")
    print(f"Activation Map Scale: {activation_vmin:.3f} to {activation_vmax:.3f}")

    # Return values for further analysis
    mean_mu = np.mean(mu_values)
    std_mu = np.std(mu_values)
    mean_var = np.exp(np.mean(logvar_values))

    print(f"Dimension {dimension_idx} statistics:")
    print(f"  Mean activation: {mean_mu:.4f} ± {std_mu:.4f}")
    print(f"  Average variance: {mean_var:.4f}")

    return importance_map, aggregated_plus_diff, aggregated_minus_diff

def visualize_vae_uncertainty(model, dataloader, group=None, num_samples=20):
    """
    Visualize uncertainty in VAE's reconstructions by sampling
    multiple times from the latent distribution.
    Uses consistent scales across all views for better comparison.

    Parameters:
        model: Trained VAE model
        dataloader: DataLoader containing samples
        group: Optional filter for specific patient group
        num_samples: Number of samples to encode
    """
    device = next(model.parameters()).device
    model.eval()

    # Find a suitable sample from the specified group
    sample_vol = None
    sample_label = None

    for batch in dataloader:
        volumes = batch['volume']
        labels = batch['label']

        if group is not None:
            # Find first sample from specified group
            group_indices = [i for i, label in enumerate(labels) if label == group]
            if group_indices:
                idx = group_indices[0]
                sample_vol = volumes[idx:idx+1].to(device)
                sample_label = labels[idx]
                break
        else:
            # Use the first sample
            sample_vol = volumes[0:1].to(device)
            sample_label = labels[0]
            break

    if sample_vol is None:
        print(f"No samples found for group {group}")
        return

    # Generate multiple reconstructions to visualize uncertainty
    reconstructions = []

    with torch.no_grad():
        # Encode the sample to get mean and log_var
        mu, log_var = model.encode(sample_vol)

        # Generate multiple reconstructions by sampling from latent space
        for _ in range(20):  # Generate 20 different reconstructions
            # Sample from latent distribution
            std = torch.exp(0.5 * log_var)
            eps = torch.randn_like(std)
            z = mu + eps * std

            # Decode sample
            recon = model.decoder(z)
            reconstructions.append(recon.cpu().squeeze().numpy())

    # Define anatomically relevant slices
    axial_slice = 32      # Axial view - slice 32
    coronal_slice = 50    # Coronal view - slice 50
    sagittal_slice1 = 55  # Sagittal view - slice 55
    sagittal_slice2 = 70  # Sagittal view - slice 70

    # Convert sample to numpy for visualization
    sample_np = sample_vol.cpu().squeeze().numpy()

    # Calculate statistics over reconstructions
    recon_mean = np.mean(reconstructions, axis=0)
    recon_std = np.std(reconstructions, axis=0)

    # Determine global scale for original and mean reconstruction
    brain_vmin, brain_vmax = 0, 3  # Standard scale for brain images

    # Determine global max for uncertainty maps
    uncertainty_max = np.max(recon_std)

    # Visualize uncertainty
    fig = plt.figure(figsize=(16, 12))
    plt.suptitle(f"VAE Reconstruction Uncertainty - Group: {sample_label}", fontsize=16)

    # Row 1: Original sample with consistent scale
    plt.subplot(3, 4, 1)
    plt.imshow(sample_np[axial_slice], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Original - Axial (z={axial_slice})")
    plt.axis('off')

    plt.subplot(3, 4, 2)
    plt.imshow(sample_np[:, coronal_slice, :], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Original - Coronal (y={coronal_slice})")
    plt.axis('off')

    plt.subplot(3, 4, 3)
    plt.imshow(sample_np[:, :, sagittal_slice1], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Original - Sagittal (x={sagittal_slice1})")
    plt.axis('off')

    plt.subplot(3, 4, 4)
    plt.imshow(sample_np[:, :, sagittal_slice2], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Original - Sagittal (x={sagittal_slice2})")
    plt.axis('off')

    # Row 2: Mean reconstruction with consistent scale
    plt.subplot(3, 4, 5)
    plt.imshow(recon_mean[axial_slice], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Mean Recon - Axial")
    plt.axis('off')

    plt.subplot(3, 4, 6)
    plt.imshow(recon_mean[:, coronal_slice, :], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Mean Recon - Coronal")
    plt.axis('off')

    plt.subplot(3, 4, 7)
    plt.imshow(recon_mean[:, :, sagittal_slice1], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Mean Recon - Sagittal 1")
    plt.axis('off')

    plt.subplot(3, 4, 8)
    plt.imshow(recon_mean[:, :, sagittal_slice2], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
    plt.title(f"Mean Recon - Sagittal 2")
    plt.axis('off')

    # Row 3: Standard deviation (uncertainty) with consistent scale
    plt.subplot(3, 4, 9)
    plt.imshow(recon_std[axial_slice], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Axial")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(3, 4, 10)
    plt.imshow(recon_std[:, coronal_slice, :], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Coronal")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(3, 4, 11)
    plt.imshow(recon_std[:, :, sagittal_slice1], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Sagittal 1")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(3, 4, 12)
    plt.imshow(recon_std[:, :, sagittal_slice2], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Sagittal 2")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # Print information about scales used
    print(f"Brain Intensity Scale: {brain_vmin} to {brain_vmax}")
    print(f"Uncertainty Scale: 0 to {uncertainty_max:.3f}")

    return recon_mean, recon_std

def generate_full_brain_uncertainty_map(model, dataloader, group=None, num_samples=10):
    """
    Generate uncertainty maps across the entire brain by analyzing the
    variability in reconstructions from multiple samples.
    Uses consistent scales across all views for better comparison.

    Parameters:
        model: Trained VAE model
        dataloader: DataLoader containing samples
        group: Optional filter for specific patient group
        num_samples: Number of samples to analyze
    """
    device = next(model.parameters()).device
    model.eval()

    # Store reconstructions and their uncertainties
    all_uncertainty_maps = []
    sample_count = 0

    # Process samples
    for batch in tqdm(dataloader, desc="Generating uncertainty maps"):
        volumes = batch['volume']
        labels = batch['label']

        if group is not None:
            # Filter samples for the specified group
            group_indices = [i for i, label in enumerate(labels) if label == group]
            batch_indices = group_indices
        else:
            # Use all samples in batch
            batch_indices = range(len(volumes))

        for idx in batch_indices:
            if sample_count >= num_samples:
                break

            sample = volumes[idx:idx+1].to(device)

            # Generate multiple reconstructions for this sample
            with torch.no_grad():
                # Encode the sample
                mu, log_var = model.encode(sample)

                # Generate reconstructions by sampling 10 times
                sample_recons = []
                for _ in range(10):
                    # Sample from latent distribution
                    std = torch.exp(0.5 * log_var)
                    eps = torch.randn_like(std)
                    z = mu + eps * std

                    # Decode sample
                    recon = model.decoder(z)
                    sample_recons.append(recon.cpu().squeeze().numpy())

                # Calculate standard deviation across reconstructions
                uncertainty_map = np.std(sample_recons, axis=0)
                all_uncertainty_maps.append(uncertainty_map)

                sample_count += 1

        # Memory cleanup
        gc.collect()
        torch.cuda.empty_cache()

        if sample_count >= num_samples:
            break

    # Average uncertainty across samples
    avg_uncertainty = np.mean(all_uncertainty_maps, axis=0)

    # Define anatomically relevant slices
    axial_slice = 32      # Axial view - slice 32
    coronal_slice = 50    # Coronal view - slice 50
    sagittal_slice1 = 55  # Sagittal view - slice 55
    sagittal_slice2 = 70  # Sagittal view - slice 70

    # Global max for uncertainty visualization
    uncertainty_max = np.max(avg_uncertainty)

    # Visualize average uncertainty across all samples
    fig = plt.figure(figsize=(16, 8))
    plt.suptitle(f"VAE Full Brain Uncertainty Map" +
                (f" - Group: {group}" if group else ""), fontsize=16)

    # Top row: Uncertainty views with viridis colormap and consistent scale
    plt.subplot(2, 4, 1)
    plt.imshow(avg_uncertainty[axial_slice], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Axial (z={axial_slice})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 2)
    plt.imshow(avg_uncertainty[:, coronal_slice, :], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Coronal (y={coronal_slice})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 3)
    plt.imshow(avg_uncertainty[:, :, sagittal_slice1], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Sagittal (x={sagittal_slice1})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    plt.subplot(2, 4, 4)
    plt.imshow(avg_uncertainty[:, :, sagittal_slice2], cmap='viridis', vmin=0, vmax=uncertainty_max)
    plt.title(f"Uncertainty - Sagittal (x={sagittal_slice2})")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

    # Calculate high uncertainty regions (top 10%)
    threshold = np.percentile(avg_uncertainty, 90)
    high_uncertainty_mask = avg_uncertainty > threshold

    # Bottom row: Thresholded uncertainty highlighting highest uncertainty regions
    plt.subplot(2, 4, 5)
    plt.imshow(avg_uncertainty[axial_slice], cmap='gray')
    plt.imshow(high_uncertainty_mask[axial_slice], cmap='hot', alpha=0.7)
    plt.title(f"High Uncertainty - Axial")
    plt.axis('off')

    plt.subplot(2, 4, 6)
    plt.imshow(avg_uncertainty[:, coronal_slice, :], cmap='gray')
    plt.imshow(high_uncertainty_mask[:, coronal_slice, :], cmap='hot', alpha=0.7)
    plt.title(f"High Uncertainty - Coronal")
    plt.axis('off')

    plt.subplot(2, 4, 7)
    plt.imshow(avg_uncertainty[:, :, sagittal_slice1], cmap='gray')
    plt.imshow(high_uncertainty_mask[:, :, sagittal_slice1], cmap='hot', alpha=0.7)
    plt.title(f"High Uncertainty - Sagittal 1")
    plt.axis('off')

    plt.subplot(2, 4, 8)
    plt.imshow(avg_uncertainty[:, :, sagittal_slice2], cmap='gray')
    plt.imshow(high_uncertainty_mask[:, :, sagittal_slice2], cmap='hot', alpha=0.7)
    plt.title(f"High Uncertainty - Sagittal 2")
    plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # Print information about scales used
    print(f"Uncertainty Scale: 0 to {uncertainty_max:.3f}")
    print(f"High Uncertainty Threshold: {threshold:.3f}")

    return avg_uncertainty, high_uncertainty_mask

def compare_group_uncertainty(model, dataloader, groups=['PD', 'Control', 'SWEDD'], num_samples=5):
    """
    Compare uncertainty patterns between different patient groups.
    Uses consistent scales across all visualizations for better comparison.

    Parameters:
        model: Trained VAE model
        dataloader: DataLoader containing samples
        groups: List of groups to compare
        num_samples: Number of samples per group
    """
    uncertainty_maps = {}

    # Generate uncertainty maps for each group
    for group in groups:
        print(f"Generating uncertainty maps for group: {group}")
        avg_uncertainty, _ = generate_full_brain_uncertainty_map(
            model, dataloader, group=group, num_samples=num_samples)
        uncertainty_maps[group] = avg_uncertainty

    # Find global max across all groups for consistent scale
    global_max = max(np.max(uncertainty_maps[group]) for group in groups)

    # Define anatomically relevant slices
    axial_slice = 32      # Axial view - slice 32
    coronal_slice = 50    # Coronal view - slice 50
    sagittal_slice1 = 55  # Sagittal view - slice 55
    sagittal_slice2 = 70  # Sagittal view - slice 70

    # Visualize uncertainty differences between groups
    fig = plt.figure(figsize=(16, 12))
    plt.suptitle(f"VAE Uncertainty Comparison Between Groups", fontsize=16)

    # Row for each group - all with the same color scale
    for i, group in enumerate(groups):
        plt.subplot(len(groups) + 1, 4, i*4 + 1)
        plt.imshow(uncertainty_maps[group][axial_slice], cmap='viridis', vmin=0, vmax=global_max)
        plt.title(f"{group} - Axial")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        plt.subplot(len(groups) + 1, 4, i*4 + 2)
        plt.imshow(uncertainty_maps[group][:, coronal_slice, :], cmap='viridis', vmin=0, vmax=global_max)
        plt.title(f"{group} - Coronal")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        plt.subplot(len(groups) + 1, 4, i*4 + 3)
        plt.imshow(uncertainty_maps[group][:, :, sagittal_slice1], cmap='viridis', vmin=0, vmax=global_max)
        plt.title(f"{group} - Sagittal 1")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        plt.subplot(len(groups) + 1, 4, i*4 + 4)
        plt.imshow(uncertainty_maps[group][:, :, sagittal_slice2], cmap='viridis', vmin=0, vmax=global_max)
        plt.title(f"{group} - Sagittal 2")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

    # Bottom row: Calculate difference between first two groups (if applicable)
    if len(groups) >= 2:
        diff_map = uncertainty_maps[groups[0]] - uncertainty_maps[groups[1]]

        # Find min/max for difference map and make symmetric
        diff_min, diff_max = np.min(diff_map), np.max(diff_map)
        diff_abs_max = max(abs(diff_min), abs(diff_max))
        diff_vmin, diff_vmax = -diff_abs_max, diff_abs_max

        plt.subplot(len(groups) + 1, 4, len(groups)*4 + 1)
        plt.imshow(diff_map[axial_slice], cmap='bwr', vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference ({groups[0]} - {groups[1]}) - Axial")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        plt.subplot(len(groups) + 1, 4, len(groups)*4 + 2)
        plt.imshow(diff_map[:, coronal_slice, :], cmap='bwr', vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference ({groups[0]} - {groups[1]}) - Coronal")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        plt.subplot(len(groups) + 1, 4, len(groups)*4 + 3)
        plt.imshow(diff_map[:, :, sagittal_slice1], cmap='bwr', vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference ({groups[0]} - {groups[1]}) - Sagittal 1")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        plt.subplot(len(groups) + 1, 4, len(groups)*4 + 4)
        plt.imshow(diff_map[:, :, sagittal_slice2], cmap='bwr', vmin=diff_vmin, vmax=diff_vmax)
        plt.title(f"Difference ({groups[0]} - {groups[1]}) - Sagittal 2")
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.axis('off')

        # Print information about scales used
        print(f"Uncertainty Scale: 0 to {global_max:.3f}")
        print(f"Difference Map Scale: {diff_vmin:.3f} to {diff_vmax:.3f}")

    plt.tight_layout()
    plt.subplots_adjust(top=0.95)
    plt.show()

    return uncertainty_maps

# Run the VAE feature importance and uncertainty visualization
if __name__ == "__main__":
    try:
        print("=== Starting VAE Feature Importance and Uncertainty Analysis ===")

        # Load trained VAE model (using the load_trained_vae function from Cell 18)
        print("\nLoading trained VAE model...")
        vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

        # 1. Generate feature importance maps for specified dimensions
        print("\nGenerating feature importance maps...")
        important_dims = [63, 34, 123]  # The dimensions specified by the user

        for dim in important_dims:
            print(f"\nAnalyzing dimension {dim}...")

            # For PD group
            print(f"Feature map for dimension {dim} - PD group")
            importance_map_pd, _, _ = generate_vae_feature_importance_map(
                vae_model, val_loader, dimension_idx=dim, group='PD', num_samples=8)

            # For Control group
            print(f"Feature map for dimension {dim} - Control group")
            importance_map_control, _, _ = generate_vae_feature_importance_map(
                vae_model, val_loader, dimension_idx=dim, group='Control', num_samples=8)

        # 2. Visualize uncertainty in VAE reconstructions
        print("\nVisualizing VAE reconstruction uncertainty...")

        # For a single sample (PD)
        print("Single sample uncertainty visualization - PD")
        recon_mean_pd, recon_std_pd = visualize_vae_uncertainty(
            vae_model, val_loader, group='PD')

        # For a single sample (Control)
        print("Single sample uncertainty visualization - Control")
        recon_mean_control, recon_std_control = visualize_vae_uncertainty(
            vae_model, val_loader, group='Control')

        # 3. Generate full brain uncertainty maps
        print("\nGenerating full brain uncertainty maps...")

        # For all samples
        print("Full brain uncertainty map - All groups")
        avg_uncertainty, high_uncertainty_mask = generate_full_brain_uncertainty_map(
            vae_model, val_loader, num_samples=15)

        # 4. Compare uncertainty between groups
        print("\nComparing uncertainty between groups...")
        uncertainty_maps = compare_group_uncertainty(
            vae_model, val_loader, groups=['PD', 'Control', 'SWEDD'], num_samples=5)

        print("\nVAE Feature Importance and Uncertainty Analysis completed successfully!")

    except Exception as e:
        print(f"Error during analysis: {str(e)}")
        import traceback
        traceback.print_exc()

"""# Performance Metrics & Visualizations

## KL Divergence
"""

# Cell 20: VAE Latent Space Analysis through KL Divergence

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import scipy.stats as stats
from tqdm import tqdm
import gc

def analyze_vae_kl_dimensions(model, dataloader, max_samples=150):
    """
    Analyze the KL divergence contribution of each dimension in the VAE latent space.

    KL divergence in VAEs measures how much the encoded distribution differs from
    the prior (standard normal) distribution. Dimensions with higher KL divergence
    are more "active" and potentially encode more meaningful features.
    """
    device = next(model.parameters()).device
    model.eval()

    # Storage for per-dimension KL and sample metadata
    kl_per_dim = []
    labels = []
    paths = []

    sample_count = 0
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Analyzing KL divergence per dimension"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Encode samples to get mu and log_var
            mu, log_var = model.encode(volumes)

            # Calculate KL divergence per dimension: 0.5 * (mu^2 + exp(log_var) - log_var - 1)
            kl_dims = 0.5 * (mu.pow(2) + log_var.exp() - log_var - 1)

            # Store results
            kl_per_dim.append(kl_dims.cpu().numpy())
            labels.extend(batch_labels)
            paths.extend(batch_paths)

            sample_count += volumes.shape[0]

            # Memory cleanup
            del volumes, mu, log_var, kl_dims
            torch.cuda.empty_cache()

            if sample_count >= max_samples:
                break

    # Stack arrays and trim to max_samples if needed
    kl_per_dim = np.vstack(kl_per_dim)
    if max_samples and len(labels) > max_samples:
        kl_per_dim = kl_per_dim[:max_samples]
        labels = labels[:max_samples]
        paths = paths[:max_samples]

    # Analyze overall KL divergence per dimension
    mean_kl_per_dim = np.mean(kl_per_dim, axis=0)

    # Find most active dimensions (highest KL)
    top_dims_idx = np.argsort(mean_kl_per_dim)[-20:][::-1]
    top_dims_kl = mean_kl_per_dim[top_dims_idx]

    # Plot overall KL per dimension (sorted)
    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    plt.bar(range(len(mean_kl_per_dim)), sorted(mean_kl_per_dim, reverse=True))
    plt.axhline(y=np.mean(mean_kl_per_dim), color='r', linestyle='--', label=f'Mean KL: {np.mean(mean_kl_per_dim):.4f}')
    plt.title('KL Divergence per Dimension (Sorted)')
    plt.xlabel('Dimension Index (Sorted)')
    plt.ylabel('Mean KL Divergence')
    plt.grid(alpha=0.3)
    plt.legend()

    # Plot top 20 dimensions with actual indices
    plt.subplot(1, 2, 2)
    plt.bar(top_dims_idx, top_dims_kl)
    plt.title('Top 20 Most Active Dimensions')
    plt.xlabel('Dimension Index')
    plt.ylabel('Mean KL Divergence')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # Analyze distribution of top dimensions across patient groups
    print(f"\nAnalyzing top 5 most active dimensions across patient groups:")

    # Get unique labels
    unique_labels = list(set(labels))

    # Prepare data for violin plots
    top5_dims = top_dims_idx[:5]

    plt.figure(figsize=(15, 8))
    for i, dim in enumerate(top5_dims):
        plt.subplot(1, 5, i+1)

        # Create a dataframe for this dimension
        dim_df = pd.DataFrame({
            'KL': kl_per_dim[:, dim],
            'Group': labels
        })

        # Create violin plot
        sns.violinplot(x='Group', y='KL', data=dim_df, palette='viridis')
        plt.title(f'Dimension {dim}')
        plt.ylabel('KL Divergence' if i == 0 else '')
        plt.grid(alpha=0.3)

        # Add ANOVA p-value to see if groups are significantly different
        groups_data = [dim_df[dim_df['Group'] == group]['KL'].values for group in unique_labels]
        f_val, p_val = stats.f_oneway(*groups_data)
        plt.annotate(f'p={p_val:.4f}', xy=(0.5, 0.9), xycoords='axes fraction', ha='center')

    plt.tight_layout()
    plt.show()

    # Test predictive power of top dimensions using a simple classifier
    print("\nTesting predictive power of top KL dimensions:")

    # Prepare train/test split (70/30)
    np.random.seed(42)
    indices = np.random.permutation(len(labels))
    train_idx, test_idx = indices[:int(0.7*len(indices))], indices[int(0.7*len(indices)):]

    # Convert labels to numeric for the classifier
    label_map = {label: i for i, label in enumerate(unique_labels)}
    y = np.array([label_map[label] for label in labels])

    # Train a random forest on different sets of dimensions
    for n_dims in [5, 10, 20, 50, 100]:
        if n_dims <= len(top_dims_idx):
            # Get top n dimensions
            selected_dims = top_dims_idx[:n_dims]
            X_selected = kl_per_dim[:, selected_dims]

            # Train model
            clf = RandomForestClassifier(n_estimators=100, random_state=42)
            clf.fit(X_selected[train_idx], y[train_idx])

            # Test model
            y_pred = clf.predict(X_selected[test_idx])
            accuracy = accuracy_score(y[test_idx], y_pred)

            print(f"Accuracy using top {n_dims} KL dimensions: {accuracy:.4f}")

            # Feature importance
            if n_dims <= 20:  # Only show for smaller sets
                importances = clf.feature_importances_
                indices = np.argsort(importances)[::-1]

                print("  Top 5 most important dimensions:")
                for i in range(min(5, n_dims)):
                    print(f"    Dim {selected_dims[indices[i]]}: {importances[indices[i]]:.4f}")

    return kl_per_dim, top_dims_idx, labels, paths

# Load the trained VAE model from previous cells
print("Loading trained VAE model...")
# Using the load_trained_vae function from Cell 18
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Analyze VAE KL divergence per dimension
print("\nAnalyzing VAE latent dimensions through KL divergence...")
kl_per_dim, top_dims, labels, paths = analyze_vae_kl_dimensions(
    vae_model, val_loader, max_samples=150)

print("KL Divergence Analysis completed!")

# Cell 21: Visualization of Top KL Dimensions in Brain Space

# Now let's visualize what the top dimensions represent in the brain space
print("Visualizing top KL dimensions in brain space...")

# Select the top 3 dimensions with highest KL divergence
top_3_dims = top_dims[:3]
print(f"Analyzing dimensions: {top_3_dims}")

# For each dimension, visualize its effect on reconstruction
for dim_idx in top_3_dims:
    print(f"\nVisualizing dimension {dim_idx}...")

    # Use the existing function from Cell 15
    visualize_vae_latent_dimension(vae_model, val_loader, dimension_idx=dim_idx, alpha=5.0)

    # Generate feature importance map
    print(f"Generating feature importance map for dimension {dim_idx}")
    for group in ['PD', 'Control']:
        generate_vae_feature_importance_map(
            vae_model, val_loader, dimension_idx=dim_idx, group=group, num_samples=8)

print("Top dimensions visualization completed!")

# Cell 22: Analysis of Latent Space Distributions and Alpha Values

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# Function to analyze autoencoder
def analyze_ae_alpha(ae_model, dataloader, alpha_value=8.0, max_samples=200):
    """Calculate how many standard deviations alpha represents for AE dimensions"""
    device = next(ae_model.parameters()).device
    ae_model.eval()

    print(f"Analyzing Autoencoder latent space (alpha = {alpha_value})...")

    # Storage for latent vectors
    latent_vectors = []

    # Extract latent vectors
    with torch.no_grad():
        sample_count = 0
        for batch in tqdm(dataloader, desc="Extracting AE latent vectors"):
            volumes = batch['volume'].to(device)

            # Get AE latent vectors
            z = ae_model.encode(volumes)

            # Store results
            latent_vectors.append(z.cpu().numpy())

            # Update counter and check limit
            sample_count += len(volumes)
            if sample_count >= max_samples:
                break

            # Memory cleanup
            del volumes, z
            torch.cuda.empty_cache()

    # Stack arrays
    latent_vectors = np.vstack(latent_vectors)
    print(f"Collected {latent_vectors.shape[0]} samples with {latent_vectors.shape[1]} dimensions")

    # Calculate statistics
    dim_stds = np.std(latent_vectors, axis=0)
    alpha_in_std_devs = alpha_value / dim_stds

    # Print statistics
    print(f"\nAutoencoder Latent Space Statistics:")
    print(f"  Alpha value: {alpha_value}")
    print(f"  Mean standard deviation: {np.mean(dim_stds):.4f}")
    print(f"  Alpha in std devs: mean = {np.mean(alpha_in_std_devs):.2f}, min = {np.min(alpha_in_std_devs):.2f}, max = {np.max(alpha_in_std_devs):.2f}")

    # Create histogram
    plt.figure(figsize=(10, 6))
    plt.hist(alpha_in_std_devs, bins=30, color='#A1CAF1')
    plt.axvline(x=1, color='r', linestyle='--', label='1 std dev')
    plt.axvline(x=2, color='r', linestyle=':', label='2 std devs')
    plt.axvline(x=3, color='r', linestyle='-.', label='3 std devs')
    plt.xlabel(f'Alpha ({alpha_value}) in Standard Deviations', fontsize=12)
    plt.ylabel('Count of Dimensions', fontsize=12)
    plt.title('Autoencoder: How Many Standard Deviations Does Alpha Represent?', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    return latent_vectors, dim_stds, alpha_in_std_devs

# Function to analyze VAE
def analyze_vae_alpha(vae_model, dataloader, alpha_value=5.0, max_samples=200):
    """Calculate how many standard deviations alpha represents for VAE dimensions"""
    device = next(vae_model.parameters()).device
    vae_model.eval()

    print(f"Analyzing VAE latent space (alpha = {alpha_value})...")

    # Storage for latent vectors
    latent_means = []

    # Extract latent vectors
    with torch.no_grad():
        sample_count = 0
        for batch in tqdm(dataloader, desc="Extracting VAE latent vectors"):
            volumes = batch['volume'].to(device)

            # Get VAE latent vectors - return is (mu, log_var)
            mu, _ = vae_model.encode(volumes)

            # Store results
            latent_means.append(mu.cpu().numpy())

            # Update counter and check limit
            sample_count += len(volumes)
            if sample_count >= max_samples:
                break

            # Memory cleanup
            del volumes, mu
            torch.cuda.empty_cache()

    # Stack arrays
    latent_means = np.vstack(latent_means)
    print(f"Collected {latent_means.shape[0]} samples with {latent_means.shape[1]} dimensions")

    # Calculate statistics
    dim_stds = np.std(latent_means, axis=0)
    alpha_in_std_devs = alpha_value / dim_stds

    # Print statistics
    print(f"\nVAE Latent Space Statistics:")
    print(f"  Alpha value: {alpha_value}")
    print(f"  Mean standard deviation: {np.mean(dim_stds):.4f}")
    print(f"  Alpha in std devs: mean = {np.mean(alpha_in_std_devs):.2f}, min = {np.min(alpha_in_std_devs):.2f}, max = {np.max(alpha_in_std_devs):.2f}")

    # Create histogram
    plt.figure(figsize=(10, 6))
    plt.hist(alpha_in_std_devs, bins=30, color='#F08080')
    plt.axvline(x=1, color='r', linestyle='--', label='1 std dev')
    plt.axvline(x=2, color='r', linestyle=':', label='2 std devs')
    plt.axvline(x=3, color='r', linestyle='-.', label='3 std devs')
    plt.xlabel(f'Alpha ({alpha_value}) in Standard Deviations', fontsize=12)
    plt.ylabel('Count of Dimensions', fontsize=12)
    plt.title('VAE: How Many Standard Deviations Does Alpha Represent?', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    return latent_means, dim_stds, alpha_in_std_devs

# Function to analyze specific dimensions
def analyze_specific_dimension(model, dataloader, dimension, is_vae=False, alpha_value=8.0, max_samples=200):
    """Analyze a specific latent dimension in detail"""
    device = next(model.parameters()).device
    model.eval()
    model_name = "VAE" if is_vae else "Autoencoder"

    print(f"Analyzing {model_name} dimension {dimension} (alpha = {alpha_value})...")

    # Storage for dimension values
    dim_values = []

    # Extract latent vectors
    with torch.no_grad():
        sample_count = 0
        for batch in tqdm(dataloader, desc=f"Extracting {model_name} dimension {dimension}"):
            volumes = batch['volume'].to(device)

            # Get latent vectors
            if is_vae:
                z, _ = model.encode(volumes)  # For VAE, get mean vectors
            else:
                z = model.encode(volumes)  # For AE, get latent vectors

            # Extract the specific dimension
            dim_values.extend(z[:, dimension].cpu().numpy())

            # Update counter and check limit
            sample_count += len(volumes)
            if sample_count >= max_samples:
                break

            # Memory cleanup
            del volumes, z
            torch.cuda.empty_cache()

    # Convert to numpy array
    dim_values = np.array(dim_values)

    # Calculate statistics
    dim_mean = np.mean(dim_values)
    dim_std = np.std(dim_values)

    # Print statistics
    print(f"\n{model_name} Dimension {dimension} Statistics:")
    print(f"  Mean: {dim_mean:.4f}")
    print(f"  Standard deviation: {dim_std:.4f}")
    print(f"  Alpha ({alpha_value}) in std devs: {alpha_value / dim_std:.2f}")

    # Create visualization
    plt.figure(figsize=(10, 6))

    # Plot histogram with KDE
    sns.histplot(dim_values, kde=True)

    # Add lines for mean and perturbations
    plt.axvline(x=dim_mean, color='r', linestyle='-', label='Mean')
    plt.axvline(x=dim_mean + alpha_value, color='g', linestyle='--', label=f'Mean + α ({alpha_value})')
    plt.axvline(x=dim_mean - alpha_value, color='b', linestyle='--', label=f'Mean - α ({alpha_value})')

    # Add lines for standard deviations
    for i in range(1, 4):
        plt.axvline(x=dim_mean + i*dim_std, color='k', linestyle=':', alpha=0.5, label=f'+{i} std' if i == 1 else None)
        plt.axvline(x=dim_mean - i*dim_std, color='k', linestyle=':', alpha=0.5, label=f'-{i} std' if i == 1 else None)

    plt.xlabel('Dimension Value', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.title(f'{model_name} Dimension {dimension} Distribution\nAlpha={alpha_value} = {alpha_value/dim_std:.2f} std devs', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    return dim_values, dim_mean, dim_std

# Load the trained models (if not already loaded)
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Analyze both models
print("\nAnalyzing alpha values in terms of standard deviations...")
ae_vectors, ae_stds, ae_alpha_in_stds = analyze_ae_alpha(ae_model, val_loader, alpha_value=8.0, max_samples=200)
vae_means, vae_stds, vae_alpha_in_stds = analyze_vae_alpha(vae_model, val_loader, alpha_value=5.0, max_samples=200)

# Analyze specific dimensions mentioned in the original code
print("\nAnalyzing specific dimensions of interest:")
for dim in [231, 94, 154]:  # Top dimensions analyzed in previous cells
    print(f"\nDimension {dim}:")
    analyze_specific_dimension(ae_model, val_loader, dim, is_vae=False, alpha_value=8.0, max_samples=200)
    analyze_specific_dimension(vae_model, val_loader, dim, is_vae=True, alpha_value=5.0, max_samples=200)

"""## Metadata Analysis with Latent Dimensions"""

# Cell 23: Metadata Dimension Analysis with Improved Visualization

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import torch
import re
import scipy.stats as stats

def analyze_metadata_dimensions(ae_model, vae_model, dataloader, metadata_path="dicom_metadata.csv", max_samples=150):
    """
    Analyze how specific dimensions in the latent spaces correlate with metadata.
    """
    print("\nAnalyzing correlation between latent dimensions and metadata...")

    # Load metadata CSV
    if not os.path.exists(metadata_path):
        print(f"Error: Metadata file {metadata_path} not found!")
        return None

    # Load with proper type handling
    metadata_df = pd.read_csv(metadata_path)
    print(f"Loaded metadata with {len(metadata_df)} entries and columns: {metadata_df.columns.tolist()}")

    # Check data types and missing values
    print("\nData types in metadata:")
    print(metadata_df.dtypes)

    print("\nMissing values in metadata:")
    print(metadata_df.isnull().sum())

    # Extract latent vectors from models
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    sample_paths = []
    sample_labels = []
    ae_latent_vecs = []
    vae_latent_means = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Get latent vectors
            ae_z = ae_model.encode(volumes)
            vae_mu, _ = vae_model.encode(volumes)

            # Store results
            ae_latent_vecs.append(ae_z.cpu().numpy())
            vae_latent_means.append(vae_mu.cpu().numpy())
            sample_paths.extend(batch_paths)
            sample_labels.extend(batch_labels)

            # Memory cleanup
            del volumes, ae_z, vae_mu
            torch.cuda.empty_cache()

            if len(sample_paths) >= max_samples:
                break

    # Stack arrays
    ae_latent_vecs = np.vstack(ae_latent_vecs)
    vae_latent_means = np.vstack(vae_latent_means)

    # Create dataframe with sample info
    sample_df = pd.DataFrame({
        'file_path': sample_paths,
        'group': sample_labels
    })

    # Normalize paths for matching
    sample_df['file_path_norm'] = sample_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )
    metadata_df['file_path_norm'] = metadata_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )

    # Extract patient IDs as a fallback matching strategy
    def extract_patient_id(path):
        path = path.replace('\\', '/')
        match = re.search(r'PPMI_(\d+)_', path)
        if match:
            return match.group(1)
        match = re.search(r'PPMI_Images_\w+/(\d+)/', path)
        if match:
            return match.group(1)
        return None

    sample_df['patient_id'] = sample_df['file_path'].apply(extract_patient_id)
    metadata_df['patient_id'] = metadata_df['file_path'].apply(extract_patient_id)

    # Try to match by filename first
    merged_df = pd.merge(sample_df, metadata_df, on='file_path_norm', how='inner', suffixes=('_sample', '_meta'))

    # If that doesn't work well, try matching by patient ID
    if len(merged_df) < 10:
        print("Filename matching failed, trying patient ID matching...")
        merged_df = pd.merge(sample_df, metadata_df, on='patient_id', how='inner', suffixes=('_sample', '_meta'))

    print(f"Successfully matched {len(merged_df)} samples with metadata")

    if len(merged_df) < 10:
        print("Error: Insufficient matches for analysis. Check file paths.")
        print("Sample patient IDs:", sample_df['patient_id'].dropna().unique()[:10])
        print("Metadata patient IDs:", metadata_df['patient_id'].dropna().unique()[:10])
        return None

    # Get indices of matched samples to extract latent vectors
    matched_indices = [sample_paths.index(path) for path in merged_df['file_path_sample']]
    ae_matched = ae_latent_vecs[matched_indices]
    vae_matched = vae_latent_means[matched_indices]

    # Analyze categorical metadata fields
    categorical_fields = ['PatientSex', 'StudyDescription', 'Manufacturer', 'ManufacturerModelName']

    # Results storage
    dimension_analysis = {
        'ae': {field: {} for field in categorical_fields},
        'vae': {field: {} for field in categorical_fields}
    }

    # Analyze each metadata field
    for field in categorical_fields:
        field_meta = field + '_meta' if field + '_meta' in merged_df.columns else field

        if field_meta not in merged_df.columns:
            print(f"Warning: Field '{field}' not found in metadata")
            continue

        print(f"\nAnalyzing field '{field}'...")

        # Check data type and handle properly
        print(f"Data type for {field_meta}: {merged_df[field_meta].dtype}")

        # Handle nulls and convert to string for consistent processing
        field_values = merged_df[field_meta].fillna('Unknown').astype(str).values

        # Now get unique values safely
        unique_values = np.unique(field_values)
        print(f"Unique values: {unique_values}")

        # Skip if less than 2 categories
        if len(unique_values) < 2:
            print(f"Skipping '{field}' - only one unique value found")
            continue

        # Count samples per category
        value_counts = pd.Series(field_values).value_counts()
        print(f"Counts per category: {dict(value_counts)}")

        # Skip categories with too few samples
        keep_values = value_counts[value_counts >= 5].index.tolist()
        if len(keep_values) < 2:
            print(f"Skipping '{field}' - insufficient samples per category")
            continue

        # Filter to keep only samples with sufficient category representation
        keep_mask = np.array([v in keep_values for v in field_values])
        if keep_mask.sum() < 10:
            print(f"Skipping '{field}' - insufficient samples after filtering")
            continue

        filtered_values = field_values[keep_mask]
        ae_filtered = ae_matched[keep_mask]
        vae_filtered = vae_matched[keep_mask]

        print(f"Analyzing with {len(filtered_values)} samples across {len(keep_values)} categories")

        # Calculate dimension scores
        ae_scores = np.zeros(ae_filtered.shape[1])
        vae_scores = np.zeros(vae_filtered.shape[1])
        ae_p_values = np.ones(ae_filtered.shape[1])
        vae_p_values = np.ones(vae_filtered.shape[1])

        # Convert categorical values to numeric for analysis
        value_map = {val: i for i, val in enumerate(keep_values)}
        y = np.array([value_map[val] for val in filtered_values])

        # DIMENSION SELECTION METHOD:
        # Using ANOVA F-statistic to measure how well each dimension separates different categories
        for dim in range(ae_filtered.shape[1]):
            try:
                # Group data by category for ANOVA
                groups = [ae_filtered[filtered_values == val, dim] for val in keep_values]
                # Some groups might be empty or have only one sample
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    ae_scores[dim] = f_val
                    ae_p_values[dim] = p_val
                else:
                    ae_scores[dim] = 0
                    ae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing AE dimension {dim}: {e}")
                ae_scores[dim] = 0
                ae_p_values[dim] = 1.0

        for dim in range(vae_filtered.shape[1]):
            try:
                groups = [vae_filtered[filtered_values == val, dim] for val in keep_values]
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    vae_scores[dim] = f_val
                    vae_p_values[dim] = p_val
                else:
                    vae_scores[dim] = 0
                    vae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing VAE dimension {dim}: {e}")
                vae_scores[dim] = 0
                vae_p_values[dim] = 1.0

        # Find top dimensions (highest F-statistic and p < 0.05)
        ae_signif_dims = np.where(ae_p_values < 0.05)[0]
        vae_signif_dims = np.where(vae_p_values < 0.05)[0]

        ae_top_dims = ae_signif_dims[np.argsort(ae_scores[ae_signif_dims])[::-1][:10]]
        vae_top_dims = vae_signif_dims[np.argsort(vae_scores[vae_signif_dims])[::-1][:10]]

        print(f"\nTop 10 AE dimensions for {field}:")
        for i, dim in enumerate(ae_top_dims):
            print(f"  Dimension {dim}: F-statistic={ae_scores[dim]:.2f}, p-value={ae_p_values[dim]:.4f}")

        print(f"\nTop 10 VAE dimensions for {field}:")
        for i, dim in enumerate(vae_top_dims):
            print(f"  Dimension {dim}: F-statistic={vae_scores[dim]:.2f}, p-value={vae_p_values[dim]:.4f}")

        # Visualize top dimensions with separate plots for AE and VAE
        if len(ae_top_dims) > 0 or len(vae_top_dims) > 0:
            # Abbreviate labels if needed
            labels = []
            for val in keep_values:
                if len(val) > 20:  # If label is too long
                    shortened = val[:17] + "..."
                else:
                    shortened = val
                labels.append(shortened)

            # AE DIMENSIONS PLOT (if we have significant dimensions)
            if len(ae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"AE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top AE dimensions
                for i, dim in enumerate(ae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(ae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'AE Dimension {dim}', fontsize=14)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)  # Add padding for better readability
                        plt.grid(axis='y', alpha=0.3)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

            # VAE DIMENSIONS PLOT (if we have significant dimensions)
            if len(vae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"VAE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top VAE dimensions
                for i, dim in enumerate(vae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(vae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'VAE Dimension {dim}', fontsize=14)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)  # Add padding for better readability
                        plt.grid(axis='y', alpha=0.3)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

        # Store results
        dimension_analysis['ae'][field] = {
            'scores': ae_scores,
            'p_values': ae_p_values,
            'top_dims': ae_top_dims.tolist()
        }

        dimension_analysis['vae'][field] = {
            'scores': vae_scores,
            'p_values': vae_p_values,
            'top_dims': vae_top_dims.tolist()
        }

    return dimension_analysis

# Load both models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the dimension analysis
print("\nAnalyzing which dimensions correlate with metadata...")
dimension_results = analyze_metadata_dimensions(
    ae_model, vae_model, val_loader,
    metadata_path="dicom_metadata.csv", max_samples=150)

print("\nDimension analysis completed!")

# Cell 24: Metadata Dimension Analysis with Debug Output

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import torch
import re
import scipy.stats as stats

def analyze_metadata_dimensions(ae_model, vae_model, dataloader, metadata_path="dicom_metadata.csv", max_samples=150, debug=True):
    """
    Analyze how specific dimensions in the latent spaces correlate with metadata.
    """
    print("\nAnalyzing correlation between latent dimensions and metadata...")

    # Load metadata CSV
    if not os.path.exists(metadata_path):
        print(f"Error: Metadata file {metadata_path} not found!")
        return None

    # Load with proper type handling
    metadata_df = pd.read_csv(metadata_path)
    print(f"Loaded metadata with {len(metadata_df)} entries and columns: {metadata_df.columns.tolist()}")

    # Check data types and missing values
    print("\nData types in metadata:")
    print(metadata_df.dtypes)

    print("\nMissing values in metadata:")
    print(metadata_df.isnull().sum())

    # Extract latent vectors from models
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    sample_paths = []
    sample_labels = []
    ae_latent_vecs = []
    vae_latent_means = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Get latent vectors
            ae_z = ae_model.encode(volumes)
            vae_mu, _ = vae_model.encode(volumes)

            # Store results
            ae_latent_vecs.append(ae_z.cpu().numpy())
            vae_latent_means.append(vae_mu.cpu().numpy())
            sample_paths.extend(batch_paths)
            sample_labels.extend(batch_labels)

            # Memory cleanup
            del volumes, ae_z, vae_mu
            torch.cuda.empty_cache()

            if len(sample_paths) >= max_samples:
                break

    # Stack arrays
    ae_latent_vecs = np.vstack(ae_latent_vecs)
    vae_latent_means = np.vstack(vae_latent_means)

    print(f"Extracted latent vectors: AE shape={ae_latent_vecs.shape}, VAE shape={vae_latent_means.shape}")

    # Create dataframe with sample info
    sample_df = pd.DataFrame({
        'file_path': sample_paths,
        'group': sample_labels
    })

    # Normalize paths for matching
    sample_df['file_path_norm'] = sample_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )
    metadata_df['file_path_norm'] = metadata_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )

    # Extract patient IDs as a fallback matching strategy
    def extract_patient_id(path):
        path = path.replace('\\', '/')
        match = re.search(r'PPMI_(\d+)_', path)
        if match:
            return match.group(1)
        match = re.search(r'PPMI_Images_\w+/(\d+)/', path)
        if match:
            return match.group(1)
        return None

    sample_df['patient_id'] = sample_df['file_path'].apply(extract_patient_id)
    metadata_df['patient_id'] = metadata_df['file_path'].apply(extract_patient_id)

    # Try to match by filename first
    merged_df = pd.merge(sample_df, metadata_df, on='file_path_norm', how='inner', suffixes=('_sample', '_meta'))

    # If that doesn't work well, try matching by patient ID
    if len(merged_df) < 10:
        print("Filename matching failed, trying patient ID matching...")
        merged_df = pd.merge(sample_df, metadata_df, on='patient_id', how='inner', suffixes=('_sample', '_meta'))

    print(f"Successfully matched {len(merged_df)} samples with metadata")

    if len(merged_df) < 10:
        print("Error: Insufficient matches for analysis. Check file paths.")
        print("Sample patient IDs:", sample_df['patient_id'].dropna().unique()[:10])
        print("Metadata patient IDs:", metadata_df['patient_id'].dropna().unique()[:10])
        return None

    # Get indices of matched samples to extract latent vectors
    matched_indices = [sample_paths.index(path) for path in merged_df['file_path_sample']]
    ae_matched = ae_latent_vecs[matched_indices]
    vae_matched = vae_latent_means[matched_indices]

    print(f"Matched latent vectors: AE shape={ae_matched.shape}, VAE shape={vae_matched.shape}")

    # Analyze categorical metadata fields
    categorical_fields = ['PatientSex', 'StudyDescription', 'Manufacturer', 'ManufacturerModelName']

    # Results storage
    dimension_analysis = {
        'ae': {field: {} for field in categorical_fields},
        'vae': {field: {} for field in categorical_fields}
    }

    # Analyze each metadata field
    for field in categorical_fields:
        field_meta = field + '_meta' if field + '_meta' in merged_df.columns else field

        if field_meta not in merged_df.columns:
            print(f"Warning: Field '{field}' not found in metadata")
            continue

        print(f"\nAnalyzing field '{field}'...")

        # Check data type and handle properly
        print(f"Data type for {field_meta}: {merged_df[field_meta].dtype}")

        # Handle nulls and convert to string for consistent processing
        field_values = merged_df[field_meta].fillna('Unknown').astype(str).values

        # Now get unique values safely
        unique_values = np.unique(field_values)
        print(f"Unique values: {unique_values}")

        # Skip if less than 2 categories
        if len(unique_values) < 2:
            print(f"Skipping '{field}' - only one unique value found")
            continue

        # Count samples per category
        value_counts = pd.Series(field_values).value_counts()
        print(f"Counts per category: {dict(value_counts)}")

        # Skip categories with too few samples
        keep_values = value_counts[value_counts >= 5].index.tolist()
        if len(keep_values) < 2:
            print(f"Skipping '{field}' - insufficient samples per category")
            continue

        # Filter to keep only samples with sufficient category representation
        keep_mask = np.array([v in keep_values for v in field_values])
        if keep_mask.sum() < 10:
            print(f"Skipping '{field}' - insufficient samples after filtering")
            continue

        filtered_values = field_values[keep_mask]
        ae_filtered = ae_matched[keep_mask]
        vae_filtered = vae_matched[keep_mask]

        print(f"Analyzing with {len(filtered_values)} samples across {len(keep_values)} categories")

        # Calculate dimension scores
        ae_scores = np.zeros(ae_filtered.shape[1])
        vae_scores = np.zeros(vae_filtered.shape[1])
        ae_p_values = np.ones(ae_filtered.shape[1])
        vae_p_values = np.ones(vae_filtered.shape[1])

        # Convert categorical values to numeric for analysis
        value_map = {val: i for i, val in enumerate(keep_values)}
        y = np.array([value_map[val] for val in filtered_values])

        print(f"Starting F-statistic calculation for {ae_filtered.shape[1]} AE dimensions...")
        start_time = time.time()

        # Debug: Log processed dimensions
        processed_dims = 0
        success_dims = 0

        # DIMENSION SELECTION METHOD:
        # Using ANOVA F-statistic to measure how well each dimension separates different categories
        for dim in range(ae_filtered.shape[1]):
            processed_dims += 1
            try:
                # Group data by category for ANOVA
                groups = [ae_filtered[filtered_values == val, dim] for val in keep_values]

                # Verify we have enough data in each group
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    ae_scores[dim] = f_val
                    ae_p_values[dim] = p_val
                    success_dims += 1

                    # Debug: print some values periodically
                    if debug and dim % 50 == 0:
                        print(f"  AE Dim {dim}: F={f_val:.2f}, p={p_val:.4f}, group sizes: {[len(g) for g in groups]}")
                else:
                    if debug and dim % 50 == 0:
                        print(f"  AE Dim {dim}: Skipped - insufficient samples in groups: {[len(g) for g in groups]}")
                    ae_scores[dim] = 0
                    ae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing AE dimension {dim}: {e}")
                ae_scores[dim] = 0
                ae_p_values[dim] = 1.0

        print(f"Completed AE dimension analysis in {time.time() - start_time:.2f} seconds")
        print(f"Processed {processed_dims}/{ae_filtered.shape[1]} dimensions, {success_dims} with valid calculations")

        print(f"Starting F-statistic calculation for {vae_filtered.shape[1]} VAE dimensions...")
        start_time = time.time()

        # Reset counters for VAE
        processed_dims = 0
        success_dims = 0

        for dim in range(vae_filtered.shape[1]):
            processed_dims += 1
            try:
                groups = [vae_filtered[filtered_values == val, dim] for val in keep_values]
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    vae_scores[dim] = f_val
                    vae_p_values[dim] = p_val
                    success_dims += 1

                    # Debug: print some values periodically
                    if debug and dim % 50 == 0:
                        print(f"  VAE Dim {dim}: F={f_val:.2f}, p={p_val:.4f}, group sizes: {[len(g) for g in groups]}")
                else:
                    if debug and dim % 50 == 0:
                        print(f"  VAE Dim {dim}: Skipped - insufficient samples in groups: {[len(g) for g in groups]}")
                    vae_scores[dim] = 0
                    vae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing VAE dimension {dim}: {e}")
                vae_scores[dim] = 0
                vae_p_values[dim] = 1.0

        print(f"Completed VAE dimension analysis in {time.time() - start_time:.2f} seconds")
        print(f"Processed {processed_dims}/{vae_filtered.shape[1]} dimensions, {success_dims} with valid calculations")

        # ADD DETAILED DEBUGGING OUTPUT
        print(f"\nF-statistic Calculation Results for {field}:")
        print(f"AE dimensions with p < 0.05: {np.sum(ae_p_values < 0.05)} out of {len(ae_p_values)}")
        print(f"VAE dimensions with p < 0.05: {np.sum(vae_p_values < 0.05)} out of {len(vae_p_values)}")
        print(f"Top 5 AE F-statistics: {sorted(ae_scores)[-5:]}")
        print(f"Top 5 VAE F-statistics: {sorted(vae_scores)[-5:]}")
        print(f"Mean AE F-statistic: {np.mean(ae_scores):.4f}")
        print(f"Mean VAE F-statistic: {np.mean(vae_scores):.4f}")

        # Plot histogram of F-statistics to see distribution
        plt.figure(figsize=(15, 6))
        plt.subplot(1, 2, 1)
        plt.hist(ae_scores, bins=30)
        plt.title(f'AE F-statistic Distribution for {field}')
        plt.xlabel('F-statistic')
        plt.ylabel('Count')
        plt.grid(alpha=0.3)

        plt.subplot(1, 2, 2)
        plt.hist(vae_scores, bins=30)
        plt.title(f'VAE F-statistic Distribution for {field}')
        plt.xlabel('F-statistic')
        plt.ylabel('Count')
        plt.grid(alpha=0.3)

        plt.tight_layout()
        plt.show()

        # Find top dimensions (highest F-statistic and p < 0.05)
        ae_signif_dims = np.where(ae_p_values < 0.05)[0]
        vae_signif_dims = np.where(vae_p_values < 0.05)[0]

        print(f"Found {len(ae_signif_dims)} significant AE dimensions")
        print(f"Found {len(vae_signif_dims)} significant VAE dimensions")

        if len(ae_signif_dims) > 0:
            ae_top_dims = ae_signif_dims[np.argsort(ae_scores[ae_signif_dims])[::-1][:10]]
        else:
            ae_top_dims = np.argsort(ae_scores)[::-1][:10]  # Just use highest F even if not significant

        if len(vae_signif_dims) > 0:
            vae_top_dims = vae_signif_dims[np.argsort(vae_scores[vae_signif_dims])[::-1][:10]]
        else:
            vae_top_dims = np.argsort(vae_scores)[::-1][:10]  # Just use highest F even if not significant

        print(f"\nTop 10 AE dimensions for {field}:")
        for i, dim in enumerate(ae_top_dims):
            print(f"  Dimension {dim}: F-statistic={ae_scores[dim]:.2f}, p-value={ae_p_values[dim]:.4f}")

        print(f"\nTop 10 VAE dimensions for {field}:")
        for i, dim in enumerate(vae_top_dims):
            print(f"  Dimension {dim}: F-statistic={vae_scores[dim]:.2f}, p-value={vae_p_values[dim]:.4f}")

        # Visualize top dimensions with separate plots for AE and VAE
        if len(ae_top_dims) > 0 or len(vae_top_dims) > 0:
            # Abbreviate labels if needed
            labels = []
            for val in keep_values:
                if len(val) > 20:  # If label is too long
                    shortened = val[:17] + "..."
                else:
                    shortened = val
                labels.append(shortened)

            # STANDARDIZED Y-AXIS RANGES
            # Calculate global min/max for all top AE dimensions to be plotted
            ae_data_for_plot = []
            for dim in ae_top_dims[:3]:
                for val in keep_values:
                    mask = filtered_values == val
                    ae_data_for_plot.extend(ae_filtered[mask, dim])

            # Calculate global min/max for all top VAE dimensions to be plotted
            vae_data_for_plot = []
            for dim in vae_top_dims[:3]:
                for val in keep_values:
                    mask = filtered_values == val
                    vae_data_for_plot.extend(vae_filtered[mask, dim])

            # Determine y-axis ranges with 10% padding
            if ae_data_for_plot:
                ae_min = np.min(ae_data_for_plot)
                ae_max = np.max(ae_data_for_plot)
                ae_range = ae_max - ae_min
                ae_y_min = ae_min - 0.1 * ae_range
                ae_y_max = ae_max + 0.1 * ae_range

            if vae_data_for_plot:
                vae_min = np.min(vae_data_for_plot)
                vae_max = np.max(vae_data_for_plot)
                vae_range = vae_max - vae_min
                vae_y_min = vae_min - 0.1 * vae_range
                vae_y_max = vae_max + 0.1 * vae_range

            # AE DIMENSIONS PLOT (if we have significant dimensions)
            if len(ae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"AE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top AE dimensions
                for i, dim in enumerate(ae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(ae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'AE Dimension {dim} (F={ae_scores[dim]:.2f}, p={ae_p_values[dim]:.4f})', fontsize=12)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)
                        plt.grid(axis='y', alpha=0.3)

                        # Set consistent y-axis limits
                        plt.ylim(ae_y_min, ae_y_max)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

            # VAE DIMENSIONS PLOT (if we have significant dimensions)
            if len(vae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"VAE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top VAE dimensions
                for i, dim in enumerate(vae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(vae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'VAE Dimension {dim} (F={vae_scores[dim]:.2f}, p={vae_p_values[dim]:.4f})', fontsize=12)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)
                        plt.grid(axis='y', alpha=0.3)

                        # Set consistent y-axis limits
                        plt.ylim(vae_y_min, vae_y_max)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

        # Store results
        dimension_analysis['ae'][field] = {
            'scores': ae_scores,
            'p_values': ae_p_values,
            'top_dims': ae_top_dims.tolist()
        }

        dimension_analysis['vae'][field] = {
            'scores': vae_scores,
            'p_values': vae_p_values,
            'top_dims': vae_top_dims.tolist()
        }

    return dimension_analysis

# Make sure to import time for the timing measurements
import time

# Load both models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the dimension analysis with debug information
print("\nAnalyzing which dimensions correlate with metadata...")
dimension_results = analyze_metadata_dimensions(
    ae_model, vae_model, val_loader,
    metadata_path="dicom_metadata.csv", max_samples=500,
    debug=True)  # Enable debug output

print("\nDimension analysis completed!")

"""## Group Separation"""

# Cell 25: VAE Latent Dimension Analysis for Patient Group Separation

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mutual_info_score
from scipy.stats import f_oneway
import scipy.stats as stats
from tqdm import tqdm
import gc

def analyze_vae_dimensions_for_group_separation(model, dataloader, max_samples=200):
    """
    Analyze how individual VAE latent dimensions separate between patient groups (PD, Control, SWEDD).

    This analysis focuses on:
    1. Which dimensions have highest KL divergence (most "active" dimensions)
    2. Which dimensions best separate between patient groups
    3. Visualizing the distribution of top dimensions across groups
    """
    device = next(model.parameters()).device
    model.eval()

    # Storage for latent vectors and metadata
    latent_means = []
    latent_logvars = []
    kl_per_dim = []
    labels = []
    paths = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting VAE latent vectors"):
            try:
                volumes = batch['volume'].to(device)
                batch_labels = batch['label']
                batch_paths = batch['path']

                # Extract latent vectors
                mu, log_var = model.encode(volumes)

                # Calculate KL divergence per dimension: 0.5 * (mu^2 + exp(log_var) - log_var - 1)
                kl_dims = 0.5 * (mu.pow(2) + log_var.exp() - log_var - 1)

                # Store results
                latent_means.append(mu.cpu().numpy())
                latent_logvars.append(log_var.cpu().numpy())
                kl_per_dim.append(kl_dims.cpu().numpy())
                labels.extend(batch_labels)
                paths.extend(batch_paths)

                # Memory cleanup
                del volumes, mu, log_var, kl_dims
                torch.cuda.empty_cache()

                if len(labels) >= max_samples:
                    break

            except Exception as e:
                print(f"Error processing batch: {str(e)}")
                continue

    # Stack arrays
    latent_means = np.vstack(latent_means)
    latent_logvars = np.vstack(latent_logvars)
    kl_per_dim = np.vstack(kl_per_dim)

    # Limit to max_samples if needed
    if max_samples and len(labels) > max_samples:
        latent_means = latent_means[:max_samples]
        latent_logvars = latent_logvars[:max_samples]
        kl_per_dim = kl_per_dim[:max_samples]
        labels = labels[:max_samples]
        paths = paths[:max_samples]

    # Get unique patient groups
    unique_groups = sorted(list(set(labels)))

    # Print overview
    print(f"Analyzing {len(labels)} samples across {len(unique_groups)} patient groups: {unique_groups}")
    group_counts = {group: labels.count(group) for group in unique_groups}
    print("Samples per group:", group_counts)

    # Calculate overall KL divergence per dimension
    mean_kl_per_dim = np.mean(kl_per_dim, axis=0)

    # Calculate separation metrics for each dimension
    # We'll use ANOVA F-statistic to measure how well each dimension separates groups
    f_stats = np.zeros(latent_means.shape[1])
    p_values = np.ones(latent_means.shape[1])
    mi_scores = np.zeros(latent_means.shape[1])  # Mutual information scores

    # Create a numeric encoding of labels for mutual information
    label_map = {label: i for i, label in enumerate(unique_groups)}
    numeric_labels = np.array([label_map[label] for label in labels])

    # Calculate separation metrics for each dimension
    for dim in range(latent_means.shape[1]):
        # Get dimension values for each group
        groups_data = [latent_means[np.array(labels) == group, dim] for group in unique_groups]

        # Calculate ANOVA F-statistic and p-value
        if all(len(g) > 1 for g in groups_data):
            f_val, p_val = f_oneway(*groups_data)
            f_stats[dim] = f_val
            p_values[dim] = p_val

        # Calculate mutual information
        try:
            # Discretize dimension values for MI calculation
            dim_values = latent_means[:, dim]
            bins = min(20, len(dim_values) // 10)  # Use fewer bins for smaller datasets
            discretized = np.digitize(dim_values, np.linspace(min(dim_values), max(dim_values), bins))
            mi_scores[dim] = mutual_info_score(discretized, numeric_labels)
        except Exception as e:
            print(f"Error calculating MI for dimension {dim}: {e}")
            mi_scores[dim] = 0

    # Find top dimensions by different metrics
    # 1. Top active dimensions (highest KL)
    top_kl_dims = np.argsort(mean_kl_per_dim)[::-1][:20]

    # 2. Top separating dimensions (highest F-statistic with p < 0.05)
    significant_dims = np.where(p_values < 0.05)[0]
    top_f_dims = significant_dims[np.argsort(f_stats[significant_dims])[::-1][:20]] if len(significant_dims) > 0 else np.argsort(f_stats)[::-1][:20]

    # 3. Top dimensions by mutual information
    top_mi_dims = np.argsort(mi_scores)[::-1][:20]

    # Create a composite score that combines these metrics
    # Normalize each metric to [0, 1] range and then average
    if np.max(mean_kl_per_dim) > np.min(mean_kl_per_dim):
        norm_kl = (mean_kl_per_dim - np.min(mean_kl_per_dim)) / (np.max(mean_kl_per_dim) - np.min(mean_kl_per_dim) + 1e-10)
    else:
        norm_kl = np.zeros_like(mean_kl_per_dim)

    if np.max(f_stats) > np.min(f_stats):
        norm_f = (f_stats - np.min(f_stats)) / (np.max(f_stats) - np.min(f_stats) + 1e-10)
    else:
        norm_f = np.zeros_like(f_stats)

    if np.max(mi_scores) > np.min(mi_scores):
        norm_mi = (mi_scores - np.min(mi_scores)) / (np.max(mi_scores) - np.min(mi_scores) + 1e-10)
    else:
        norm_mi = np.zeros_like(mi_scores)

    # Weight the score components based on significance (F-stat p-value)
    significance_weight = np.where(p_values < 0.05, 1.0, 0.1)
    composite_scores = (norm_kl + norm_f * significance_weight + norm_mi) / 3

    # Top dimensions by composite score
    top_composite_dims = np.argsort(composite_scores)[::-1][:20]

    # Print top dimensions by each metric
    print("\nTop 10 dimensions by average KL divergence (most active):")
    for i, dim in enumerate(top_kl_dims[:10]):
        print(f"  Dimension {dim}: KL={mean_kl_per_dim[dim]:.4f}")

    print("\nTop 10 dimensions by F-statistic (best group separation):")
    for i, dim in enumerate(top_f_dims[:10]):
        print(f"  Dimension {dim}: F={f_stats[dim]:.2f}, p={p_values[dim]:.6f}")

    print("\nTop 10 dimensions by mutual information:")
    for i, dim in enumerate(top_mi_dims[:10]):
        print(f"  Dimension {dim}: MI={mi_scores[dim]:.4f}")

    print("\nTop 10 dimensions by composite score:")
    for i, dim in enumerate(top_composite_dims[:10]):
        print(f"  Dimension {dim}: Score={composite_scores[dim]:.4f}, KL={mean_kl_per_dim[dim]:.4f}, F={f_stats[dim]:.2f}, p={p_values[dim]:.6f}")

    # Visualize top dimensions by different metrics
    print("\nVisualizing top dimensions by group separation...")

    # Create a custom palette for consistent colors
    palette = {'PD': 'red', 'Control': 'blue', 'SWEDD': 'green'}

    # Visualize top dimensions by F-statistic
    top_dims_to_plot = top_f_dims[:5]
    visualize_dimensions_by_group(latent_means, labels, top_dims_to_plot,
                                 group_counts, f_stats, p_values, palette,
                                 "Top Dimensions by F-statistic")

    # Visualize top dimensions by KL divergence
    visualize_dimensions_by_group(latent_means, labels, top_kl_dims[:5],
                                 group_counts, f_stats, p_values, palette,
                                 "Top Dimensions by KL Divergence")

    # Visualize top dimensions by composite score
    visualize_dimensions_by_group(latent_means, labels, top_composite_dims[:5],
                                 group_counts, f_stats, p_values, palette,
                                 "Top Dimensions by Composite Score")

    # Create a dimension score dataframe for further reference
    dimension_scores = pd.DataFrame({
        'dimension': np.arange(latent_means.shape[1]),
        'kl_divergence': mean_kl_per_dim,
        'f_statistic': f_stats,
        'p_value': p_values,
        'mutual_info': mi_scores,
        'composite_score': composite_scores,
        'significant': p_values < 0.05
    })

    # Sort by composite score
    dimension_scores = dimension_scores.sort_values('composite_score', ascending=False)

    # Create group separation visualization in 2D space using top 2 dimensions
    create_2d_separation_plot(latent_means, labels, top_f_dims[:2], palette,
                             "Group Separation Using Top 2 Dimensions (F-statistic)")

    # Create group separation visualization in 2D space using top 2 composite dimensions
    create_2d_separation_plot(latent_means, labels, top_composite_dims[:2], palette,
                             "Group Separation Using Top 2 Dimensions (Composite Score)")

    return {
        'latent_means': latent_means,
        'latent_logvars': latent_logvars,
        'kl_per_dim': kl_per_dim,
        'labels': labels,
        'paths': paths,
        'top_kl_dims': top_kl_dims,
        'top_f_dims': top_f_dims,
        'top_mi_dims': top_mi_dims,
        'top_composite_dims': top_composite_dims,
        'dimension_scores': dimension_scores,
        'f_stats': f_stats,
        'p_values': p_values,
        'mean_kl_per_dim': mean_kl_per_dim,
        'mi_scores': mi_scores
    }

def visualize_dimensions_by_group(latent_means, labels, dimensions,
                                 group_counts, f_stats, p_values,
                                 palette, title):
    """
    Visualize how specific dimensions distribute across patient groups.

    Parameters:
        latent_means: Numpy array of latent vectors (n_samples, n_dims)
        labels: List of group labels for each sample
        dimensions: List of dimensions to visualize
        group_counts: Dictionary with count of samples per group
        f_stats: F-statistics for each dimension
        p_values: p-values for each dimension
        palette: Color palette for groups
        title: Title for the plot
    """
    unique_groups = sorted(list(set(labels)))
    n_dims = len(dimensions)

    # Set up the figure
    fig, axes = plt.subplots(1, n_dims, figsize=(n_dims*5, 6))
    if n_dims == 1:
        axes = [axes]

    fig.suptitle(f"{title}", fontsize=16)

    # Create visualization for each dimension
    for i, dim in enumerate(dimensions):
        ax = axes[i]

        # Create a dataframe for this dimension
        dim_df = pd.DataFrame({
            'Value': latent_means[:, dim],
            'Group': labels
        })

        # Create violin plot with swarm plot overlay
        sns.violinplot(x='Group', y='Value', data=dim_df, palette=palette, ax=ax)

        # Add swarm plot if there aren't too many samples (to avoid clutter)
        if sum(group_counts.values()) < 100:
            sns.swarmplot(x='Group', y='Value', data=dim_df, color='black', alpha=0.5, ax=ax)

        # Add box plot for clearer visualization of the median and quartiles
        sns.boxplot(x='Group', y='Value', data=dim_df, width=0.2, palette=palette,
                   boxprops={'alpha': 0.5}, ax=ax)

        # Add stats in the title
        ax.set_title(f"Dimension {dim}\nF={f_stats[dim]:.2f}, p={p_values[dim]:.6f}", fontsize=12)
        ax.set_xlabel('')

        if i == 0:
            ax.set_ylabel('Dimension Value', fontsize=12)
        else:
            ax.set_ylabel('')

        # Add group counts to x-axis labels
        x_labels = [f"{group}\n(n={group_counts[group]})" for group in unique_groups]
        ax.set_xticklabels(x_labels)

        # Add grid for better readability
        ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.subplots_adjust(top=0.85)
    plt.show()

def create_2d_separation_plot(latent_means, labels, top_2_dims, palette, title):
    """
    Create a 2D scatter plot showing how the top 2 dimensions separate patient groups.

    Parameters:
        latent_means: Numpy array of latent vectors
        labels: List of group labels
        top_2_dims: List of the top 2 dimensions to plot
        palette: Color palette for groups
        title: Title for the plot
    """
    if len(top_2_dims) < 2:
        print("Need at least 2 dimensions for 2D plot")
        return

    # Create figure
    plt.figure(figsize=(10, 8))

    # Extract the two dimensions
    dim1, dim2 = top_2_dims[0], top_2_dims[1]

    # Create dataframe for plotting
    plot_df = pd.DataFrame({
        'Dimension 1': latent_means[:, dim1],
        'Dimension 2': latent_means[:, dim2],
        'Group': labels
    })

    # Create scatter plot
    sns.scatterplot(x='Dimension 1', y='Dimension 2', hue='Group',
                   data=plot_df, palette=palette, s=100, alpha=0.7)

    # Add group centroids
    for group in set(labels):
        group_data = plot_df[plot_df['Group'] == group]
        centroid_x = group_data['Dimension 1'].mean()
        centroid_y = group_data['Dimension 2'].mean()
        plt.scatter(centroid_x, centroid_y, s=200, color=palette[group],
                   marker='X', edgecolor='black', linewidth=2,
                   label=f"{group} centroid")

    # Add dimension indices to axis labels
    plt.xlabel(f"Dimension {dim1}", fontsize=12)
    plt.ylabel(f"Dimension {dim2}", fontsize=12)

    # Add title with dimension indices
    plt.title(f"{title}\nDimensions {dim1} and {dim2}", fontsize=14)

    # Add grid for better readability
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Calculate and display group separation metrics for these dimensions
    calculate_2d_separation_metrics(latent_means[:, [dim1, dim2]], labels,
                                   f"Dimensions {dim1} and {dim2}")

def calculate_2d_separation_metrics(points_2d, labels, title):
    """
    Calculate metrics that quantify how well the selected dimensions separate groups.

    Parameters:
        points_2d: Numpy array of 2D points
        labels: List of group labels
        title: Title for printed metrics
    """
    unique_groups = sorted(list(set(labels)))

    # Convert labels to numpy array
    labels = np.array(labels)

    # Calculate group centroids
    centroids = {}
    for group in unique_groups:
        group_points = points_2d[labels == group]
        centroids[group] = np.mean(group_points, axis=0)

    # Calculate distances between centroids
    print(f"\n{title} - Centroid distances between groups:")
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            dist = np.linalg.norm(centroids[group1] - centroids[group2])
            print(f"  {group1} vs {group2}: {dist:.4f}")

    # Calculate average distance of each sample to its own group centroid
    within_dists = {}
    for group in unique_groups:
        group_points = points_2d[labels == group]
        dists = np.linalg.norm(group_points - centroids[group], axis=1)
        within_dists[group] = np.mean(dists)

    print(f"\n{title} - Average within-group distances:")
    for group, dist in within_dists.items():
        print(f"  {group}: {dist:.4f}")

    # Calculate silhouette-like metric (ratio of between vs. within)
    between_dists = {}
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            between_dists[f"{group1}-{group2}"] = np.linalg.norm(centroids[group1] - centroids[group2])

    avg_within = np.mean(list(within_dists.values()))
    avg_between = np.mean(list(between_dists.values()))
    separation_ratio = avg_between / avg_within

    print(f"\n{title} - Separation quality:")
    print(f"  Average within-group distance: {avg_within:.4f}")
    print(f"  Average between-group distance: {avg_between:.4f}")
    print(f"  Separation ratio: {separation_ratio:.4f} (higher is better)")

# Load the trained VAE model from previous cells
print("Loading VAE model...")
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the full analysis
print("\nAnalyzing VAE dimensions for patient group separation...")
results = analyze_vae_dimensions_for_group_separation(vae_model, val_loader, max_samples=200)

# Analyze what top dimensions represent in brain space by visualizing them
print("\nVisualizing what top dimensions represent in brain space...")
top_dims_to_visualize = results['top_composite_dims'][:3]

for dim in top_dims_to_visualize:
    print(f"\nAnalyzing dimension {dim} in brain space:")
    visualize_vae_latent_dimension(vae_model, val_loader, dimension_idx=dim, alpha=5.0)

# Cell 26: AE vs VAE Performance Analysis with Consistent Scales

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import f_oneway
from tqdm import tqdm
import gc
import matplotlib.patches as mpatches
from matplotlib.lines import Line2D
from mpl_toolkits.axes_grid1 import make_axes_locatable

def compare_ae_vae_performance(ae_model, vae_model, dataloader, max_samples=150):
    """
    Comprehensive comparison of AE and VAE performance focusing on:
    1. Reconstruction quality
    2. Top discriminative dimensions and their group separation ability
    """
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    # Storage for data
    original_samples = []
    reconstructions_ae = []
    reconstructions_vae = []
    latent_ae = []
    latent_vae_mu = []
    labels = []
    paths = []

    print("Extracting reconstructions and latent representations...")

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Processing samples"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Get AE outputs
            ae_latent = ae_model.encode(volumes)
            ae_recon = ae_model.decode(ae_latent)

            # Get VAE outputs
            vae_mu, vae_logvar = vae_model.encode(volumes)
            vae_recon, _, _ = vae_model(volumes)

            # Store data
            original_samples.append(volumes.cpu().numpy())
            reconstructions_ae.append(ae_recon.cpu().numpy())
            reconstructions_vae.append(vae_recon.cpu().numpy())
            latent_ae.append(ae_latent.cpu().numpy())
            latent_vae_mu.append(vae_mu.cpu().numpy())
            labels.extend(batch_labels)
            paths.extend(batch_paths)

            # Memory cleanup
            del volumes, ae_latent, ae_recon, vae_mu, vae_logvar, vae_recon
            torch.cuda.empty_cache()

            if len(labels) >= max_samples:
                break

    # Concatenate data
    original_samples = np.vstack(original_samples)[:max_samples]
    reconstructions_ae = np.vstack(reconstructions_ae)[:max_samples]
    reconstructions_vae = np.vstack(reconstructions_vae)[:max_samples]
    latent_ae = np.vstack(latent_ae)[:max_samples]
    latent_vae_mu = np.vstack(latent_vae_mu)[:max_samples]
    labels = labels[:max_samples]
    paths = paths[:max_samples]

    # Get unique groups
    unique_groups = sorted(list(set(labels)))
    print(f"Analyzing {len(labels)} samples across {len(unique_groups)} groups: {unique_groups}")

    # Create a color palette for groups
    palette = {'PD': '#E41A1C', 'Control': '#377EB8', 'SWEDD': '#4DAF4A'}
    if len(unique_groups) > len(palette):
        # Generate colors for any additional groups
        additional_colors = plt.cm.tab10(np.linspace(0, 1, len(unique_groups)))
        palette = {group: additional_colors[i] for i, group in enumerate(unique_groups)}

    # 1. Reconstruction quality comparison
    compare_reconstruction_quality(original_samples, reconstructions_ae, reconstructions_vae, labels, unique_groups)

    # 2. Find top discriminative dimensions for each model
    ae_dim_results = find_discriminative_dimensions(latent_ae, labels, unique_groups, "AE")
    vae_dim_results = find_discriminative_dimensions(latent_vae_mu, labels, unique_groups, "VAE")

    # 3. Compare top dimensions
    compare_top_dimensions(ae_dim_results, vae_dim_results)

    # 4. Visualize top dimensions for group separation
    visualize_top_dimensions(latent_ae, latent_vae_mu, labels, unique_groups,
                            ae_dim_results, vae_dim_results, palette)

    return {
        'original_samples': original_samples,
        'reconstructions_ae': reconstructions_ae,
        'reconstructions_vae': reconstructions_vae,
        'latent_ae': latent_ae,
        'latent_vae_mu': latent_vae_mu,
        'labels': labels,
        'paths': paths,
        'ae_dim_results': ae_dim_results,
        'vae_dim_results': vae_dim_results
    }

def compare_reconstruction_quality(originals, recon_ae, recon_vae, labels, unique_groups):
    """Visualize and compare reconstruction quality between AE and VAE."""
    print("\n1. Reconstruction Quality Comparison")

    # Calculate MSE for each sample
    mse_ae = np.mean(np.square(originals - recon_ae).reshape(originals.shape[0], -1), axis=1)
    mse_vae = np.mean(np.square(originals - recon_vae).reshape(originals.shape[0], -1), axis=1)

    # Per-group statistics
    mse_by_group = {}
    for group in unique_groups:
        group_mask = np.array(labels) == group
        group_mse_ae = mse_ae[group_mask]
        group_mse_vae = mse_vae[group_mask]

        mse_by_group[group] = {
            'AE': {
                'mean': np.mean(group_mse_ae),
                'std': np.std(group_mse_ae)
            },
            'VAE': {
                'mean': np.mean(group_mse_vae),
                'std': np.std(group_mse_vae)
            }
        }

    # Print statistics
    print("\nReconstruction Error by Group (MSE):")
    for group in unique_groups:
        ae_stats = mse_by_group[group]['AE']
        vae_stats = mse_by_group[group]['VAE']
        winner = "AE" if ae_stats['mean'] < vae_stats['mean'] else "VAE"

        print(f"  {group}:")
        print(f"    AE:  {ae_stats['mean']:.6f} ± {ae_stats['std']:.6f}")
        print(f"    VAE: {vae_stats['mean']:.6f} ± {vae_stats['std']:.6f}")
        print(f"    Best: {winner} by {abs(ae_stats['mean'] - vae_stats['mean']):.6f}")

    # Create comparison visualization
    plt.figure(figsize=(15, 6))

    # 1. Direct comparison scatter plot
    plt.subplot(1, 2, 1)
    plt.scatter(mse_ae, mse_vae, c=np.where(mse_ae < mse_vae, 'blue', 'red'),
               alpha=0.7, s=80, edgecolor='k', linewidth=0.5)

    # Add diagonal line
    max_err = max(np.max(mse_ae), np.max(mse_vae))
    plt.plot([0, max_err], [0, max_err], 'k--', alpha=0.5)

    # Add annotations
    plt.text(max_err*0.1, max_err*0.8, "VAE Better", color='red', fontsize=12, ha='center')
    plt.text(max_err*0.8, max_err*0.1, "AE Better", color='blue', fontsize=12, ha='center')

    # Better = Lower reconstruction error
    ae_win_count = np.sum(mse_ae < mse_vae)
    vae_win_count = np.sum(mse_vae < mse_ae)
    plt.title(f"AE vs VAE Reconstruction Error\nAE better: {ae_win_count}, VAE better: {vae_win_count}", fontsize=14)
    plt.xlabel("AE Error (MSE)", fontsize=12)
    plt.ylabel("VAE Error (MSE)", fontsize=12)
    plt.grid(alpha=0.3)

    # 2. Group-wise VAE improvement percentage
    plt.subplot(1, 2, 2)

    # Calculate relative improvement (positive = VAE better, negative = AE better)
    improvement = ((mse_ae - mse_vae) / mse_ae) * 100

    # Create dataframe for plotting
    imp_df = pd.DataFrame({
        'Improvement (%)': improvement,
        'Group': labels
    })

    # Create violin plot with box plot overlay
    sns.violinplot(x='Group', y='Improvement (%)', data=imp_df)
    sns.boxplot(x='Group', y='Improvement (%)', data=imp_df, width=0.1,
              boxprops={'facecolor': 'white'})

    # Add zero line
    plt.axhline(y=0, color='r', linestyle='--')

    # Customize plot
    plt.title("VAE Improvement over AE (%)", fontsize=14)
    plt.ylabel("Improvement (%)\nPositive = VAE better, Negative = AE better", fontsize=12)
    plt.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Visual comparison of actual reconstructions
    visualize_sample_reconstructions(originals, recon_ae, recon_vae, labels, unique_groups)

def visualize_sample_reconstructions(originals, recon_ae, recon_vae, labels, unique_groups):
    """
    Compare the visual quality of reconstructions for sample images from each group
    with consistent scales across all groups.
    """
    # Get one sample per group
    sample_indices = []
    for group in unique_groups:
        group_indices = [i for i, label in enumerate(labels) if label == group]
        if group_indices:
            # Pick middle sample to avoid potential outliers
            sample_indices.append(group_indices[len(group_indices)//2])

    if not sample_indices:
        return

    # Define anatomically relevant slices
    axial_slice = 32  # Axial view

    # Create figure for reconstructions
    fig = plt.figure(figsize=(12, 4 * len(sample_indices)))
    plt.suptitle("Visual Comparison of Reconstructions", fontsize=16)

    # Define consistent scale for brain images
    brain_vmin, brain_vmax = 0, 3

    for i, idx in enumerate(sample_indices):
        # Get original and reconstructions
        orig = originals[idx].squeeze()
        ae_recon = recon_ae[idx].squeeze()
        vae_recon = recon_vae[idx].squeeze()
        group = labels[idx]

        # Original
        plt.subplot(len(sample_indices), 3, i*3 + 1)
        plt.imshow(orig[axial_slice], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Original - {group}", fontsize=12)
        plt.axis('off')

        # AE reconstruction
        plt.subplot(len(sample_indices), 3, i*3 + 2)
        plt.imshow(ae_recon[axial_slice], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title("AE Reconstruction", fontsize=12)
        plt.axis('off')

        # VAE reconstruction
        plt.subplot(len(sample_indices), 3, i*3 + 3)
        plt.imshow(vae_recon[axial_slice], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title("VAE Reconstruction", fontsize=12)
        plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # IMPROVEMENT: Calculate the global maximum error across all groups and samples
    # to ensure consistent color scales
    all_ae_errors = []
    all_vae_errors = []

    for idx in sample_indices:
        orig = originals[idx].squeeze()
        ae_recon = recon_ae[idx].squeeze()
        vae_recon = recon_vae[idx].squeeze()

        # Calculate error maps
        ae_error = np.abs(orig - ae_recon)
        vae_error = np.abs(orig - vae_recon)

        all_ae_errors.append(ae_error[axial_slice])
        all_vae_errors.append(vae_error[axial_slice])

    # Determine global maximum error for consistent scale
    global_max_error = max(
        max(np.max(err) for err in all_ae_errors),
        max(np.max(err) for err in all_vae_errors)
    )

    # Create figure for error maps with consistent scale across all groups
    fig = plt.figure(figsize=(12, 4 * len(sample_indices)))
    plt.suptitle(f"Reconstruction Error Maps (Global Scale: 0 to {global_max_error:.3f})", fontsize=16)

    for i, idx in enumerate(sample_indices):
        # Get original and reconstructions
        orig = originals[idx].squeeze()
        ae_recon = recon_ae[idx].squeeze()
        vae_recon = recon_vae[idx].squeeze()
        group = labels[idx]

        # Calculate error maps
        ae_error = np.abs(orig - ae_recon)
        vae_error = np.abs(orig - vae_recon)

        # Original
        plt.subplot(len(sample_indices), 3, i*3 + 1)
        plt.imshow(orig[axial_slice], cmap='gray', vmin=brain_vmin, vmax=brain_vmax)
        plt.title(f"Original - {group}", fontsize=12)
        plt.axis('off')

        # AE error with global consistent scale
        plt.subplot(len(sample_indices), 3, i*3 + 2)
        im = plt.imshow(ae_error[axial_slice], cmap='hot', vmin=0, vmax=global_max_error)
        plt.colorbar(im, fraction=0.046, pad=0.04)
        plt.title("AE Error", fontsize=12)
        plt.axis('off')

        # VAE error with global consistent scale
        plt.subplot(len(sample_indices), 3, i*3 + 3)
        im = plt.imshow(vae_error[axial_slice], cmap='hot', vmin=0, vmax=global_max_error)
        plt.colorbar(im, fraction=0.046, pad=0.04)
        plt.title("VAE Error", fontsize=12)
        plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # Add a quantitative comparison of error magnitudes by group
    print("\nError Magnitude Comparison by Group:")
    print(f"Global error scale: 0 to {global_max_error:.3f}")

    for i, idx in enumerate(sample_indices):
        group = labels[idx]
        orig = originals[idx].squeeze()
        ae_recon = recon_ae[idx].squeeze()
        vae_recon = recon_vae[idx].squeeze()

        # Calculate error statistics for this sample
        ae_error = np.abs(orig - ae_recon)
        vae_error = np.abs(orig - vae_recon)

        ae_mean = np.mean(ae_error[axial_slice])
        vae_mean = np.mean(vae_error[axial_slice])
        ae_max = np.max(ae_error[axial_slice])
        vae_max = np.max(vae_error[axial_slice])

        print(f"\n{group} Group:")
        print(f"  AE Mean Error: {ae_mean:.4f}, Max Error: {ae_max:.4f}")
        print(f"  VAE Mean Error: {vae_mean:.4f}, Max Error: {vae_max:.4f}")
        print(f"  Error Ratio (AE/VAE): {ae_mean/vae_mean:.4f}")

def find_discriminative_dimensions(latent_vectors, labels, unique_groups, model_name, top_n=10):
    """
    Find the most discriminative dimensions between patient groups.
    Uses F-statistic from one-way ANOVA to measure separation power.
    """
    print(f"\nFinding top discriminative dimensions for {model_name}...")

    # Convert labels to numpy array
    labels_array = np.array(labels)

    # Calculate F-statistic for each dimension
    f_values = []
    p_values = []

    for dim in range(latent_vectors.shape[1]):
        # Extract values for this dimension for each group
        groups_data = [latent_vectors[labels_array == group, dim] for group in unique_groups]

        try:
            # Run one-way ANOVA
            if all(len(g) > 1 for g in groups_data):
                f_stat, p_val = f_oneway(*groups_data)
                f_values.append(f_stat)
                p_values.append(p_val)
            else:
                f_values.append(0)
                p_values.append(1.0)
        except Exception as e:
            print(f"Error for dimension {dim}: {e}")
            f_values.append(0)
            p_values.append(1.0)

    # Convert to numpy arrays
    f_values = np.array(f_values)
    p_values = np.array(p_values)

    # Find top discriminative dimensions
    significant_dims = np.where(p_values < 0.05)[0]
    print(f"  Found {len(significant_dims)} significant dimensions (p < 0.05)")

    # Sort by F-statistic
    sorted_indices = np.argsort(f_values)[::-1]
    top_indices = sorted_indices[:top_n]

    # Get corresponding F and p values
    top_f_values = f_values[top_indices]
    top_p_values = p_values[top_indices]

    # Report top dimensions
    print("\nTop 5 discriminative dimensions:")
    for i in range(min(5, len(top_indices))):
        dim = top_indices[i]
        print(f"  Dimension {dim}: F = {top_f_values[i]:.2f}, p = {top_p_values[i]:.6f}")

    # Calculate group statistics for top dimensions
    group_stats = {}
    for dim in top_indices[:5]:  # Only store stats for top 5 dims to save memory
        dim_stats = {}
        for group in unique_groups:
            values = latent_vectors[labels_array == group, dim]
            dim_stats[group] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values)
            }
        group_stats[dim] = dim_stats

    return {
        'top_indices': top_indices,
        'top_f_values': top_f_values,
        'top_p_values': top_p_values,
        'all_f_values': f_values,
        'all_p_values': p_values,
        'group_stats': group_stats
    }

def compare_top_dimensions(ae_results, vae_results):
    """Compare statistical separation power of top dimensions for AE and VAE."""
    print("\n2. Top Dimensions Comparison")

    # Create a figure
    plt.figure(figsize=(14, 6))

    # 1. Top F-statistics comparison (left subplot)
    plt.subplot(1, 2, 1)

    # Get top 10 F-statistics for each model
    ae_f = ae_results['top_f_values'][:10]
    vae_f = vae_results['top_f_values'][:10]

    # Create index positions
    x = np.arange(len(ae_f))
    width = 0.35

    # Create bar chart
    plt.bar(x - width/2, ae_f, width, label='AE', color='#A1CAF1')
    plt.bar(x + width/2, vae_f, width, label='VAE', color='#F08080')

    # Add labels and customize plot
    plt.xlabel('Dimension Rank', fontsize=12)
    plt.ylabel('F-statistic', fontsize=12)
    plt.title('Top 10 Discriminative Dimensions by F-statistic', fontsize=14)
    plt.xticks(x, [f'{i+1}' for i in range(len(x))])
    plt.legend()
    plt.grid(axis='y', alpha=0.3)

    # 2. Significant dimensions count (right subplot)
    plt.subplot(1, 2, 2)

    # Count significant dimensions (p < 0.05)
    ae_sig_count = np.sum(ae_results['all_p_values'] < 0.05)
    vae_sig_count = np.sum(vae_results['all_p_values'] < 0.05)

    # Calculate percentages
    ae_perc = ae_sig_count / len(ae_results['all_p_values']) * 100
    vae_perc = vae_sig_count / len(vae_results['all_p_values']) * 100

    # Create bar chart
    models = ['AE', 'VAE']
    counts = [ae_sig_count, vae_sig_count]
    percentages = [ae_perc, vae_perc]

    bars = plt.bar(models, counts, color=['#A1CAF1', '#F08080'])

    # Add count labels
    for i, (bar, count, percentage) in enumerate(zip(bars, counts, percentages)):
        plt.text(bar.get_x() + bar.get_width()/2, count + 1,
               f"{count} ({percentage:.1f}%)", ha='center', fontsize=12)

    # Customize plot
    plt.xlabel('Model', fontsize=12)
    plt.ylabel('Number of Significant Dimensions (p < 0.05)', fontsize=12)
    plt.title('Dimensions with Significant Group Separation', fontsize=14)
    plt.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()

    # 3. Distribution of F-statistics (supplementary plot)
    plt.figure(figsize=(10, 5))

    # Get all F-values
    ae_all_f = ae_results['all_f_values']
    vae_all_f = vae_results['all_f_values']

    # Create histogram
    bins = np.linspace(0, max(max(ae_all_f), max(vae_all_f)), 30)
    plt.hist(ae_all_f, bins=bins, alpha=0.5, label='AE', color='#A1CAF1')
    plt.hist(vae_all_f, bins=bins, alpha=0.5, label='VAE', color='#F08080')

    # Customize plot
    plt.xlabel('F-statistic', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.title('Distribution of F-statistics (higher = better group separation)', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

def visualize_top_dimensions(latent_ae, latent_vae, labels, unique_groups,
                            ae_results, vae_results, palette):
    """
    Visualize how top dimensions separate patient groups in AE and VAE.
    Shows 2D plots of the 2 most discriminative dimensions with group centroids.
    """
    print("\n3. Top Dimensions Group Separation Visualization")

    # Convert labels to numpy array
    labels_array = np.array(labels)

    # A. First, visualize AE top 2 dimensions
    ae_top_dims = ae_results['top_indices'][:2]
    ae_top_f = ae_results['top_f_values'][:2]
    ae_top_p = ae_results['top_p_values'][:2]

    # B. Then, visualize VAE top 2 dimensions
    vae_top_dims = vae_results['top_indices'][:2]
    vae_top_f = vae_results['top_f_values'][:2]
    vae_top_p = vae_results['top_p_values'][:2]

    # Create a figure with AE and VAE side by side
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))

    # 1. AE Top 2 Dimensions Scatter Plot
    visualize_2d_separation(latent_ae, labels_array, unique_groups, ae_top_dims,
                           ae_top_f, ae_top_p, palette, ax1, "AE")

    # 2. VAE Top 2 Dimensions Scatter Plot
    visualize_2d_separation(latent_vae, labels_array, unique_groups, vae_top_dims,
                           vae_top_f, vae_top_p, palette, ax2, "VAE")

    plt.tight_layout()
    plt.show()

    # Additional visualization: Show distribution of each dimension by group
    visualize_top_dim_distributions(latent_ae, latent_vae, labels_array, unique_groups,
                                   ae_top_dims, vae_top_dims, palette)

def visualize_2d_separation(latent_vectors, labels, unique_groups, top_dims,
                           f_values, p_values, palette, ax, model_name):
    """
    Create a 2D scatter plot showing how the top 2 dimensions separate groups.
    Also shows centroids and calculates separation metrics.
    """
    # Extract the top 2 dimensions
    dim1, dim2 = top_dims

    # Create a dataframe for the plot
    plot_df = pd.DataFrame({
        'x': latent_vectors[:, dim1],
        'y': latent_vectors[:, dim2],
        'group': labels
    })

    # Calculate centroids for each group
    centroids = {}
    for group in unique_groups:
        group_data = plot_df[plot_df['group'] == group]
        centroids[group] = {
            'x': group_data['x'].mean(),
            'y': group_data['y'].mean()
        }

    # Plot each group's points
    for group in unique_groups:
        group_data = plot_df[plot_df['group'] == group]
        ax.scatter(group_data['x'], group_data['y'], label=group,
                  color=palette[group], s=80, alpha=0.7, edgecolor='w')

    # Plot centroids
    for group, coords in centroids.items():
        ax.scatter(coords['x'], coords['y'], s=200, color=palette[group],
                 marker='X', edgecolor='black', linewidth=2)

    # Calculate and plot the connecting lines between centroids
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            ax.plot([centroids[group1]['x'], centroids[group2]['x']],
                   [centroids[group1]['y'], centroids[group2]['y']],
                   'k--', alpha=0.5, linewidth=1)

            # Calculate and show distance
            dist = np.sqrt((centroids[group1]['x'] - centroids[group2]['x'])**2 +
                          (centroids[group1]['y'] - centroids[group2]['y'])**2)

            # Position the distance label at the midpoint of the line
            mid_x = (centroids[group1]['x'] + centroids[group2]['x']) / 2
            mid_y = (centroids[group1]['y'] + centroids[group2]['y']) / 2

            ax.text(mid_x, mid_y, f"{dist:.2f}",
                  backgroundcolor='white', ha='center', va='center', fontsize=10)

    # Customize plot
    ax.set_title(f"{model_name} Top Dimensions Separation\n(Dim {dim1}: F={f_values[0]:.2f}, p={p_values[0]:.6f},\nDim {dim2}: F={f_values[1]:.2f}, p={p_values[1]:.6f})",
               fontsize=14)
    ax.set_xlabel(f"Dimension {dim1}", fontsize=12)
    ax.set_ylabel(f"Dimension {dim2}", fontsize=12)
    ax.grid(alpha=0.3)

    # Create custom legend with both groups and centroids
    legend_elements = []

    # Group markers
    for group in unique_groups:
        legend_elements.append(
            mpatches.Patch(color=palette[group], label=group))

    # Centroid marker
    legend_elements.append(
        Line2D([0], [0], marker='X', color='w', markerfacecolor='gray',
              markersize=10, label='Centroids'))

    ax.legend(handles=legend_elements, loc='best')

    # Calculate separation quality metrics
    within_group_distances = []
    for group in unique_groups:
        group_mask = labels == group
        points = np.column_stack((latent_vectors[group_mask, dim1],
                                 latent_vectors[group_mask, dim2]))
        centroid = np.array([centroids[group]['x'], centroids[group]['y']])

        # Calculate distances from each point to its centroid
        distances = np.sqrt(np.sum((points - centroid)**2, axis=1))
        within_group_distances.extend(distances)

    # Calculate between-group distances (centroid to centroid)
    between_group_distances = []
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            dist = np.sqrt((centroids[group1]['x'] - centroids[group2]['x'])**2 +
                          (centroids[group1]['y'] - centroids[group2]['y'])**2)
            between_group_distances.append(dist)

    # Calculate average distances
    avg_within = np.mean(within_group_distances)
    avg_between = np.mean(between_group_distances)
    separation_ratio = avg_between / avg_within if avg_within > 0 else 0

    # Display metrics on the plot
    ax.text(0.05, 0.05,
           f"Avg within-group: {avg_within:.2f}\nAvg between-group: {avg_between:.2f}\nSeparation ratio: {separation_ratio:.2f}",
           transform=ax.transAxes,
           bbox=dict(facecolor='white', alpha=0.8))

    return {
        'centroids': centroids,
        'avg_within': avg_within,
        'avg_between': avg_between,
        'separation_ratio': separation_ratio
    }

def visualize_top_dim_distributions(latent_ae, latent_vae, labels, unique_groups,
                                   ae_top_dims, vae_top_dims, palette):
    """
    Visualize the distribution of values for top dimensions across patient groups.
    Shows violin plots for each group in each dimension.
    """
    # Convert to pandas format for easier plotting
    ae_dim1, ae_dim2 = ae_top_dims
    vae_dim1, vae_dim2 = vae_top_dims

    # Create dataframes for top dimensions
    ae_df = pd.DataFrame({
        f'AE Dim {ae_dim1}': latent_ae[:, ae_dim1],
        f'AE Dim {ae_dim2}': latent_ae[:, ae_dim2],
        'Group': labels
    })

    vae_df = pd.DataFrame({
        f'VAE Dim {vae_dim1}': latent_vae[:, vae_dim1],
        f'VAE Dim {vae_dim2}': latent_vae[:, vae_dim2],
        'Group': labels
    })

    # Create figure for top dimension distributions
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Determine global min/max values for consistent y-axis scales
    # For AE dimensions
    ae_dim1_min = ae_df[f'AE Dim {ae_dim1}'].min()
    ae_dim1_max = ae_df[f'AE Dim {ae_dim1}'].max()
    ae_dim2_min = ae_df[f'AE Dim {ae_dim2}'].min()
    ae_dim2_max = ae_df[f'AE Dim {ae_dim2}'].max()

    ae_ymin = min(ae_dim1_min, ae_dim2_min)
    ae_ymax = max(ae_dim1_max, ae_dim2_max)

    # Add some padding
    ae_range = ae_ymax - ae_ymin
    ae_ymin -= ae_range * 0.1
    ae_ymax += ae_range * 0.1

    # For VAE dimensions
    vae_dim1_min = vae_df[f'VAE Dim {vae_dim1}'].min()
    vae_dim1_max = vae_df[f'VAE Dim {vae_dim1}'].max()
    vae_dim2_min = vae_df[f'VAE Dim {vae_dim2}'].min()
    vae_dim2_max = vae_df[f'VAE Dim {vae_dim2}'].max()

    vae_ymin = min(vae_dim1_min, vae_dim2_min)
    vae_ymax = max(vae_dim1_max, vae_dim2_max)

    # Add some padding
    vae_range = vae_ymax - vae_ymin
    vae_ymin -= vae_range * 0.1
    vae_ymax += vae_range * 0.1

    # 1. AE Dimension 1
    ax = axes[0, 0]
    sns.violinplot(x='Group', y=f'AE Dim {ae_dim1}', data=ae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'AE Dim {ae_dim1}', data=ae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"AE Dimension {ae_dim1} Distribution", fontsize=14)
    ax.set_ylim(ae_ymin, ae_ymax)  # Use consistent y-axis scale for AE dimensions
    ax.grid(axis='y', alpha=0.3)

    # 2. AE Dimension 2
    ax = axes[0, 1]
    sns.violinplot(x='Group', y=f'AE Dim {ae_dim2}', data=ae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'AE Dim {ae_dim2}', data=ae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"AE Dimension {ae_dim2} Distribution", fontsize=14)
    ax.set_ylim(ae_ymin, ae_ymax)  # Use consistent y-axis scale for AE dimensions
    ax.grid(axis='y', alpha=0.3)

    # 3. VAE Dimension 1
    ax = axes[1, 0]
    sns.violinplot(x='Group', y=f'VAE Dim {vae_dim1}', data=vae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'VAE Dim {vae_dim1}', data=vae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"VAE Dimension {vae_dim1} Distribution", fontsize=14)
    ax.set_ylim(vae_ymin, vae_ymax)  # Use consistent y-axis scale for VAE dimensions
    ax.grid(axis='y', alpha=0.3)

    # 4. VAE Dimension 2
    ax = axes[1, 1]
    sns.violinplot(x='Group', y=f'VAE Dim {vae_dim2}', data=vae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'VAE Dim {vae_dim2}', data=vae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"VAE Dimension {vae_dim2} Distribution", fontsize=14)
    ax.set_ylim(vae_ymin, vae_ymax)  # Use consistent y-axis scale for VAE dimensions
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.suptitle("Distribution of Top Discriminative Dimensions by Patient Group", fontsize=16)
    plt.subplots_adjust(top=0.93)
    plt.show()

    # Create additional plot showing top 3-5 dimensions as heatmap of means
    visualize_dimension_group_means(latent_ae, latent_vae, labels, unique_groups,
                                   ae_top_dims[:5], vae_top_dims[:5], palette)

def visualize_dimension_group_means(latent_ae, latent_vae, labels, unique_groups,
                                   ae_top_dims, vae_top_dims, palette):
    """
    Create a heatmap visualization showing how the top dimensions
    differ in mean values across patient groups for both models.
    """
    # Calculate group means for top AE dimensions
    ae_means = np.zeros((len(unique_groups), len(ae_top_dims)))
    for i, group in enumerate(unique_groups):
        group_mask = labels == group
        for j, dim in enumerate(ae_top_dims):
            ae_means[i, j] = np.mean(latent_ae[group_mask, dim])

    # Calculate group means for top VAE dimensions
    vae_means = np.zeros((len(unique_groups), len(vae_top_dims)))
    for i, group in enumerate(unique_groups):
        group_mask = labels == group
        for j, dim in enumerate(vae_top_dims):
            vae_means[i, j] = np.mean(latent_vae[group_mask, dim])

    # Determine the global min/max for both heatmaps to use a consistent colormap scale
    global_min = min(np.min(ae_means), np.min(vae_means))
    global_max = max(np.max(ae_means), np.max(vae_means))

    # Make the colormap symmetric around zero if values cross zero
    if global_min < 0 and global_max > 0:
        abs_max = max(abs(global_min), abs(global_max))
        global_min = -abs_max
        global_max = abs_max

    # Create a figure for the heatmaps
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))

    # 1. AE heatmap with consistent scale
    im1 = ax1.imshow(ae_means, cmap='coolwarm', aspect='auto', vmin=global_min, vmax=global_max)

    # Add axis labels
    ax1.set_yticks(np.arange(len(unique_groups)))
    ax1.set_yticklabels(unique_groups)
    ax1.set_xticks(np.arange(len(ae_top_dims)))
    ax1.set_xticklabels([f'Dim {dim}' for dim in ae_top_dims])

    # Add colorbar
    divider = make_axes_locatable(ax1)
    cax1 = divider.append_axes("right", size="5%", pad=0.1)
    cbar1 = plt.colorbar(im1, cax=cax1)
    cbar1.set_label('Mean Dimension Value')

    # Add title
    ax1.set_title("AE Top Dimensions - Mean Values by Group", fontsize=14)

    # Add value annotations
    for i in range(len(unique_groups)):
        for j in range(len(ae_top_dims)):
            text_color = "white" if abs(ae_means[i, j]) > (global_max - global_min) * 0.7 else "black"
            ax1.text(j, i, f"{ae_means[i, j]:.2f}",
                    ha="center", va="center", color=text_color)

    # 2. VAE heatmap with same consistent scale
    im2 = ax2.imshow(vae_means, cmap='coolwarm', aspect='auto', vmin=global_min, vmax=global_max)

    # Add axis labels
    ax2.set_yticks(np.arange(len(unique_groups)))
    ax2.set_yticklabels(unique_groups)
    ax2.set_xticks(np.arange(len(vae_top_dims)))
    ax2.set_xticklabels([f'Dim {dim}' for dim in vae_top_dims])

    # Add colorbar
    divider = make_axes_locatable(ax2)
    cax2 = divider.append_axes("right", size="5%", pad=0.1)
    cbar2 = plt.colorbar(im2, cax=cax2)
    cbar2.set_label('Mean Dimension Value')

    # Add title
    ax2.set_title("VAE Top Dimensions - Mean Values by Group", fontsize=14)

    # Add value annotations
    for i in range(len(unique_groups)):
        for j in range(len(vae_top_dims)):
            text_color = "white" if abs(vae_means[i, j]) > (global_max - global_min) * 0.7 else "black"
            ax2.text(j, i, f"{vae_means[i, j]:.2f}",
                    ha="center", va="center", color=text_color)

    plt.suptitle(f"Dimension Mean Values (Scale: {global_min:.2f} to {global_max:.2f})", fontsize=16)
    plt.tight_layout()
    plt.subplots_adjust(top=0.90)
    plt.show()

# Load the trained models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the comparison analysis with focus on discriminative dimensions
results = compare_ae_vae_performance(ae_model, vae_model, val_loader, max_samples=150)

"""## Identifiability of the same Patient, is it possible?"""

# Cell 27: Identifying Patients with Multiple Exams
import os
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
from datetime import datetime
import torch
from tqdm import tqdm
import gc

def extract_patient_info(file_path):
    """
    Extract patient ID and exam date from file path.
    Returns a tuple (patient_id, exam_date, group)
    """
    # Normalize path
    file_path = file_path.replace('\\', '/')

    # Extract patient group (PD, Control, SWEDD)
    if 'PPMI_Images_PD' in file_path:
        patient_group = 'PD'
    elif 'PPMI_Images_Cont' in file_path:
        patient_group = 'Control'
    elif 'PPMI_Images_SWEDD' in file_path:
        patient_group = 'SWEDD'
    else:
        patient_group = 'Unknown'

    # Extract patient ID - should be a folder after the group folder
    patient_id_match = re.search(r'PPMI_Images_\w+/(\d+)/', file_path)
    if not patient_id_match:
        patient_id_match = re.search(r'PPMI_(\d+)_', file_path)

    patient_id = patient_id_match.group(1) if patient_id_match else None

    # Extract exam date - typically found in a format like "2011-01-20_16_28_47.0"
    date_match = re.search(r'(\d{4}-\d{2}-\d{2})_\d{2}_\d{2}_\d{2}', file_path)
    if date_match:
        exam_date = date_match.group(1)
    else:
        # Try another common format
        date_match = re.search(r'(\d{8})', file_path)
        if date_match:
            date_str = date_match.group(1)
            # Format YYYYMMDD
            exam_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        else:
            exam_date = None

    return patient_id, exam_date, patient_group

def identify_longitudinal_patients(dataloader, min_exams=3, max_patients=10):
    """
    Identify patients with multiple exams and select a subset for analysis.
    Prioritizes patients with the MOST exams in each group.

    Parameters:
        dataloader: DataLoader containing DATSCAN images
        min_exams: Minimum number of exams required to consider a patient for analysis
        max_patients: Maximum number of patients to include in the analysis

    Returns:
        Dictionary with patient info and DataFrame of longitudinal patients
    """
    print("Identifying patients with multiple exams...")

    # Dictionary to store patient info
    patient_exams = defaultdict(lambda: defaultdict(list))

    # Extract patient info from all file paths in the dataloader
    for batch in tqdm(dataloader, desc="Processing files"):
        paths = batch['path']
        labels = batch['label']

        for path, label in zip(paths, labels):
            patient_id, exam_date, patient_group = extract_patient_info(path)

            if patient_id and exam_date:
                # Store the path along with the exam date
                patient_exams[patient_id][exam_date].append({
                    'path': path,
                    'group': label if label else patient_group
                })

    # Count number of exams per patient
    exam_counts = {patient_id: len(exams) for patient_id, exams in patient_exams.items()}

    # Create a DataFrame for analysis
    patient_info = []
    for patient_id, exam_dates in patient_exams.items():
        # Get the patient group (should be the same for all exams)
        patient_group = next(iter(next(iter(exam_dates.values()))))['group']
        num_exams = len(exam_dates)

        # Get the first and last exam dates
        exam_date_list = list(exam_dates.keys())
        first_exam = min(exam_date_list) if exam_date_list else None
        last_exam = max(exam_date_list) if exam_date_list else None

        # Calculate the time span in days if possible
        time_span = None
        if first_exam and last_exam:
            try:
                first_date = datetime.strptime(first_exam, "%Y-%m-%d")
                last_date = datetime.strptime(last_exam, "%Y-%m-%d")
                time_span = (last_date - first_date).days
            except ValueError:
                pass

        patient_info.append({
            'patient_id': patient_id,
            'group': patient_group,
            'num_exams': num_exams,
            'first_exam': first_exam,
            'last_exam': last_exam,
            'time_span_days': time_span
        })

    patient_df = pd.DataFrame(patient_info)

    # Sort by number of exams in descending order
    patient_df = patient_df.sort_values(by='num_exams', ascending=False)

    print(f"Found {len(patient_df)} unique patients.")
    print(f"Patients with {min_exams}+ exams: {len(patient_df[patient_df['num_exams'] >= min_exams])}")

    # Distribution of exams per patient
    plt.figure(figsize=(10, 6))
    sns.histplot(data=patient_df, x='num_exams', hue='group', discrete=True, multiple='stack')
    plt.title('Distribution of Exams per Patient')
    plt.xlabel('Number of Exams')
    plt.ylabel('Number of Patients')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # Filter for patients with multiple exams (at least min_exams)
    longitudinal_df = patient_df[patient_df['num_exams'] >= min_exams].copy()

    # Show the top patients from each group
    print("\nTop patients with most exams by group:")
    for group in sorted(longitudinal_df['group'].unique()):
        group_patients = longitudinal_df[longitudinal_df['group'] == group].sort_values(by='num_exams', ascending=False)
        print(f"\n{group} group:")
        if len(group_patients) > 0:
            print(group_patients[['patient_id', 'num_exams', 'time_span_days']].head(5).to_string(index=False))
        else:
            print("No patients with sufficient exams.")

    # Time span distribution for longitudinal patients
    plt.figure(figsize=(10, 6))
    sns.histplot(data=longitudinal_df, x='time_span_days', hue='group', bins=20, multiple='stack')
    plt.title('Time Span of Exams for Longitudinal Patients')
    plt.xlabel('Time Span (days)')
    plt.ylabel('Number of Patients')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # GUARANTEED GROUP REPRESENTATION STRATEGY
    # Allocate slots for each group to ensure representation
    selected_patients = []
    all_groups = patient_df['group'].unique()
    slots_per_group = max(1, max_patients // len(all_groups))
    remaining_slots = max_patients - (slots_per_group * len(all_groups))

    print(f"\nAllocating {slots_per_group} slots per group with {remaining_slots} remaining slots")

    # First, try to fill with patients meeting minimum exam criteria
    for group in all_groups:
        group_patients = longitudinal_df[longitudinal_df['group'] == group]

        # If we don't have enough patients with min_exams, fall back to patients with fewer exams
        if len(group_patients) < slots_per_group:
            # Get all patients from this group
            all_group_patients = patient_df[patient_df['group'] == group].sort_values(by='num_exams', ascending=False)

            # Take top patients even if they don't meet min_exams
            fallback_count = slots_per_group - len(group_patients)
            fallback_patients = all_group_patients[~all_group_patients['patient_id'].isin(group_patients['patient_id'])].head(fallback_count)

            # Add to the group patients
            group_patients = pd.concat([group_patients, fallback_patients])

            print(f"Added {len(fallback_patients)} patients from {group} group with fewer than {min_exams} exams")

        # Select top patients from this group
        selected_from_group = group_patients.head(slots_per_group)
        selected_patients.append(selected_from_group)

        print(f"Selected {len(selected_from_group)} patients from {group} group")

    # Combine selected patients and sort by number of exams
    selected_df = pd.concat(selected_patients).sort_values(by=['num_exams', 'time_span_days'], ascending=[False, False])

    # Allocate remaining slots to patients with the most exams
    if remaining_slots > 0:
        # Get eligible patients not already selected
        remaining_patients = longitudinal_df[~longitudinal_df['patient_id'].isin(selected_df['patient_id'])]

        # If we have eligible patients, add them
        if len(remaining_patients) > 0:
            additional = remaining_patients.head(remaining_slots)
            selected_df = pd.concat([selected_df, additional])
            print(f"Added {len(additional)} additional patients with the most exams")

    # Final sort by exam count
    selected_df = selected_df.sort_values(by='num_exams', ascending=False)

    print("\nSelected patients for analysis:")
    print(selected_df[['patient_id', 'group', 'num_exams', 'time_span_days']].reset_index(drop=True))

    # Verify we have representation from all groups
    selected_groups = selected_df['group'].unique()
    if len(selected_groups) == len(all_groups):
        print("\n✅ All patient groups are represented in the selection")
    else:
        missing_groups = set(all_groups) - set(selected_groups)
        print(f"\n⚠️ Missing representation from groups: {missing_groups}")

    return {
        'patient_exams': patient_exams,
        'patient_df': patient_df,
        'longitudinal_df': longitudinal_df,
        'selected_patients': selected_df
    }, selected_df

# Run the function to identify longitudinal patients
# We're now GUARANTEEING representation from all groups
patient_data, selected_patients = identify_longitudinal_patients(val_loader, min_exams=2, max_patients=10)

# Cell 26: Extracting and Analyzing Latent Representations for Longitudinal Patients
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.manifold import TSNE
from tqdm import tqdm
import time
import gc

def extract_patient_latent_representations(patient_exams, selected_patients, ae_model, vae_model, dataloader):
    """
    Extract latent representations for all exams of selected patients.

    Parameters:
        patient_exams: Dictionary with patient exam info
        selected_patients: DataFrame of patients selected for analysis
        ae_model: Trained autoencoder model
        vae_model: Trained VAE model
        dataloader: DataLoader containing all images

    Returns:
        Dictionary with latent representations for each patient and exam
    """
    print("Extracting latent representations for longitudinal patients...")

    # Set models to evaluation mode
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    # Create a set of selected patient IDs for faster lookup
    selected_patient_ids = set(selected_patients['patient_id'])

    # Dictionary to store latent representations
    patient_latent_reps = {
        'ae': defaultdict(lambda: defaultdict(list)),
        'vae': defaultdict(lambda: defaultdict(list))
    }

    # Process all images in the dataloader
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume']
            paths = batch['path']

            # Check if any image in this batch belongs to our selected patients
            batch_has_selected = False
            for path in paths:
                patient_id, _, _ = extract_patient_info(path)
                if patient_id in selected_patient_ids:
                    batch_has_selected = True
                    break

            # Skip batch if it doesn't contain any of our selected patients
            if not batch_has_selected:
                continue

            # Process the batch
            volumes = volumes.to(device)

            # Get latent vectors
            ae_latent = ae_model.encode(volumes)
            vae_mu, _ = vae_model.encode(volumes)

            # Store latent vectors for selected patients
            for i, path in enumerate(paths):
                patient_id, exam_date, _ = extract_patient_info(path)

                if patient_id in selected_patient_ids and exam_date:
                    patient_latent_reps['ae'][patient_id][exam_date].append(ae_latent[i].cpu().numpy())
                    patient_latent_reps['vae'][patient_id][exam_date].append(vae_mu[i].cpu().numpy())

            # Memory cleanup
            del volumes, ae_latent, vae_mu
            torch.cuda.empty_cache()

    # Average latent vectors for each exam (in case there are multiple images per exam)
    for model_type in ['ae', 'vae']:
        for patient_id in patient_latent_reps[model_type]:
            for exam_date in patient_latent_reps[model_type][patient_id]:
                vectors = patient_latent_reps[model_type][patient_id][exam_date]
                if vectors:
                    # Average the vectors
                    avg_vector = np.mean(vectors, axis=0)
                    patient_latent_reps[model_type][patient_id][exam_date] = avg_vector

    # Convert to a more accessible format for analysis
    latent_data = []

    for model_type in ['ae', 'vae']:
        for patient_id in patient_latent_reps[model_type]:
            for exam_date, latent_vector in patient_latent_reps[model_type][patient_id].items():
                # Get patient group from selected_patients
                patient_group = selected_patients[selected_patients['patient_id'] == patient_id]['group'].iloc[0]

                latent_data.append({
                    'patient_id': patient_id,
                    'group': patient_group,
                    'exam_date': exam_date,
                    'model_type': model_type,
                    'latent_vector': latent_vector
                })

    latent_df = pd.DataFrame(latent_data)

    print(f"Extracted latent representations for {len(latent_df)} exams across {len(selected_patient_ids)} patients.")

    return latent_df

def analyze_patient_latent_consistency(latent_df):
    """
    Analyze the consistency of latent representations across exams for the same patient.

    Parameters:
        latent_df: DataFrame with latent representations for each patient and exam

    Returns:
        Dictionary with analysis results
    """
    print("\nAnalyzing consistency of latent representations...")

    # Calculate intra-patient and inter-patient similarity
    results = {
        'ae': {'intra_sim': [], 'inter_sim': [], 'stable_dims': []},
        'vae': {'intra_sim': [], 'inter_sim': [], 'stable_dims': []}
    }

    # Calculate pairwise similarities for each model type
    for model_type in ['ae', 'vae']:
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Initialize arrays for dimension-wise analysis
        latent_dim = len(model_data.iloc[0]['latent_vector'])
        dim_stability = np.zeros(latent_dim)
        dim_inter_variation = np.zeros(latent_dim)

        # Group by patient
        patient_groups = model_data.groupby('patient_id')

        # Calculate intra-patient similarities
        for patient_id, patient_df in patient_groups:
            patient_vectors = np.array(patient_df['latent_vector'].tolist())

            # Calculate pairwise similarities within patient
            if len(patient_vectors) > 1:
                # Cosine similarity between all pairs of exams
                sim_matrix = cosine_similarity(patient_vectors)

                # Average similarity (excluding self-similarity along diagonal)
                intra_sim = (sim_matrix.sum() - len(patient_vectors)) / (len(patient_vectors) * (len(patient_vectors) - 1))
                results[model_type]['intra_sim'].append(intra_sim)

                # Analyze dimension-wise stability
                for dim in range(latent_dim):
                    dim_values = patient_vectors[:, dim]
                    dim_stability[dim] += np.std(dim_values)

        # Normalize dimension stability by number of patients
        dim_stability /= len(patient_groups)

        # Find the most stable dimensions (lowest standard deviation across exams)
        stable_dims = np.argsort(dim_stability)[:20]  # Top 20 most stable dimensions
        results[model_type]['stable_dims'] = stable_dims.tolist()

        # Calculate inter-patient similarities
        patient_avg_vectors = {}

        # Get average vector for each patient
        for patient_id, patient_df in patient_groups:
            patient_vectors = np.array(patient_df['latent_vector'].tolist())
            patient_avg_vectors[patient_id] = np.mean(patient_vectors, axis=0)

        # Calculate pairwise similarities between different patients
        patient_ids = list(patient_avg_vectors.keys())
        for i in range(len(patient_ids)):
            for j in range(i+1, len(patient_ids)):
                vec1 = patient_avg_vectors[patient_ids[i]]
                vec2 = patient_avg_vectors[patient_ids[j]]

                # Cosine similarity between patients
                sim = cosine_similarity([vec1], [vec2])[0, 0]
                results[model_type]['inter_sim'].append(sim)

                # Calculate dimension-wise variation between patients
                for dim in range(latent_dim):
                    dim_inter_variation[dim] += abs(vec1[dim] - vec2[dim])

        # Normalize inter-patient variation by number of pairs
        if len(patient_ids) > 1:
            num_pairs = len(patient_ids) * (len(patient_ids) - 1) / 2
            dim_inter_variation /= num_pairs

        # Find most discriminative dimensions (highest variation between patients)
        discrim_dims = np.argsort(dim_inter_variation)[::-1][:20]  # Top 20 most discriminative dimensions
        results[model_type]['discrim_dims'] = discrim_dims.tolist()

    # Plot intra vs inter patient similarity distributions
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    sns.kdeplot(results['ae']['intra_sim'], label='Intra-patient', shade=True)
    sns.kdeplot(results['ae']['inter_sim'], label='Inter-patient', shade=True)
    plt.title('AE: Intra vs. Inter-Patient Similarity')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Density')
    plt.grid(alpha=0.3)
    plt.legend()

    plt.subplot(1, 2, 2)
    sns.kdeplot(results['vae']['intra_sim'], label='Intra-patient', shade=True)
    sns.kdeplot(results['vae']['inter_sim'], label='Inter-patient', shade=True)
    plt.title('VAE: Intra vs. Inter-Patient Similarity')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Density')
    plt.grid(alpha=0.3)
    plt.legend()

    plt.tight_layout()
    plt.show()

    # Create summary statistics table
    summary_stats = []
    for model_type in ['ae', 'vae']:
        intra_mean = np.mean(results[model_type]['intra_sim'])
        intra_std = np.std(results[model_type]['intra_sim'])
        inter_mean = np.mean(results[model_type]['inter_sim'])
        inter_std = np.std(results[model_type]['inter_sim'])

        # Separation ratio (higher is better)
        separation_ratio = intra_mean / inter_mean if inter_mean > 0 else float('inf')

        summary_stats.append({
            'Model': model_type.upper(),
            'Intra-Patient Similarity': f"{intra_mean:.4f} ± {intra_std:.4f}",
            'Inter-Patient Similarity': f"{inter_mean:.4f} ± {inter_std:.4f}",
            'Separation Ratio': f"{separation_ratio:.4f}"
        })

    summary_df = pd.DataFrame(summary_stats)
    print("\nSummary Statistics:")
    print(summary_df)

    # Print most stable dimensions
    for model_type in ['ae', 'vae']:
        print(f"\n{model_type.upper()} - Top 10 most stable dimensions:")
        for dim in results[model_type]['stable_dims'][:10]:
            print(f"  Dimension {dim}")

        print(f"\n{model_type.upper()} - Top 10 most discriminative dimensions:")
        for dim in results[model_type]['discrim_dims'][:10]:
            print(f"  Dimension {dim}")

    return results

# Load AE and VAE models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Extract latent representations for longitudinal patients
latent_df = extract_patient_latent_representations(
    patient_data['patient_exams'],
    selected_patients,
    ae_model,
    vae_model,
    val_loader
)

# Analyze consistency of latent representations
consistency_results = analyze_patient_latent_consistency(latent_df)

# Cell 28: Visualizing Patient Identity in Latent Space
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import LeaveOneOut
import itertools
from matplotlib.colors import ListedColormap

def visualize_patient_latent_evolution(latent_df, stable_dims):
    """
    Visualize how the latent representations of patients evolve over time,
    focusing on the most stable dimensions identified.

    Parameters:
        latent_df: DataFrame with latent representations
        stable_dims: Dictionary with stable dimensions for AE and VAE
    """
    print("Visualizing patient latent space evolution...")

    # Create a figure for both models
    for model_type in ['ae', 'vae']:
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Get top stable dimensions
        top_dims = stable_dims[model_type]['stable_dims'][:2]
        top_discrim_dims = stable_dims[model_type]['discrim_dims'][:2]

        # Create plots
        fig, axes = plt.subplots(1, 2, figsize=(18, 8))
        plt.suptitle(f'{model_type.upper()}: Patient Evolution in Latent Space', fontsize=16)

        # Plot using stable dimensions
        ax = axes[0]
        visualize_dimensions(model_data, top_dims, ax, f'Most Stable Dimensions ({top_dims[0]}, {top_dims[1]})')

        # Plot using discriminative dimensions
        ax = axes[1]
        visualize_dimensions(model_data, top_discrim_dims, ax, f'Most Discriminative Dimensions ({top_discrim_dims[0]}, {top_discrim_dims[1]})')

        plt.tight_layout()
        plt.subplots_adjust(top=0.9)
        plt.show()

    # Create dimension evolution plots for each patient
    for model_type in ['ae', 'vae']:
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Get top stable & discriminative dimensions
        top_stable = stable_dims[model_type]['stable_dims'][:5]
        top_discrim = stable_dims[model_type]['discrim_dims'][:5]

        # For each patient, visualize how these dimensions evolve over time
        for patient_id, patient_df in model_data.groupby('patient_id'):
            # Skip if there are fewer than 3 exams
            if len(patient_df) < 3:
                continue

            # Sort by exam date
            patient_df = patient_df.sort_values('exam_date')

            # Get patient group
            patient_group = patient_df['group'].iloc[0]

            # Convert exam dates to numerical indices for x-axis
            exam_dates = patient_df['exam_date'].tolist()

            # Plot evolution of top dimensions
            fig, axes = plt.subplots(2, 1, figsize=(12, 10))
            plt.suptitle(f'{model_type.upper()}: Patient {patient_id} ({patient_group}) - Dimension Evolution', fontsize=16)

            # Stable dimensions
            ax = axes[0]
            for i, dim in enumerate(top_stable):
                dim_values = [vec[dim] for vec in patient_df['latent_vector']]
                ax.plot(range(len(exam_dates)), dim_values, 'o-', label=f'Dim {dim}')

            ax.set_title('Most Stable Dimensions')
            ax.set_xlabel('Exam Index')
            ax.set_ylabel('Dimension Value')
            ax.set_xticks(range(len(exam_dates)))
            ax.set_xticklabels(exam_dates, rotation=45)
            ax.grid(alpha=0.3)
            ax.legend()

            # Discriminative dimensions
            ax = axes[1]
            for i, dim in enumerate(top_discrim):
                dim_values = [vec[dim] for vec in patient_df['latent_vector']]
                ax.plot(range(len(exam_dates)), dim_values, 'o-', label=f'Dim {dim}')

            ax.set_title('Most Discriminative Dimensions')
            ax.set_xlabel('Exam Index')
            ax.set_ylabel('Dimension Value')
            ax.set_xticks(range(len(exam_dates)))
            ax.set_xticklabels(exam_dates, rotation=45)
            ax.grid(alpha=0.3)
            ax.legend()

            plt.tight_layout()
            plt.subplots_adjust(top=0.9)
            plt.show()

def visualize_dimensions(data, dimensions, ax, title):
    """Helper function to visualize patient trajectories in two dimensions"""
    # Create a colormap with one color per patient
    patient_ids = data['patient_id'].unique()
    colors = plt.cm.tab20(np.linspace(0, 1, len(patient_ids)))
    patient_colors = {pid: colors[i] for i, pid in enumerate(patient_ids)}

    # Plot each patient's trajectory
    for patient_id, patient_df in data.groupby('patient_id'):
        # Sort by exam date
        patient_df = patient_df.sort_values('exam_date')

        # Get group for marker shape
        group = patient_df['group'].iloc[0]
        marker = 'o' if group == 'PD' else ('s' if group == 'Control' else '^')

        # Extract dimension values
        x_values = [vec[dimensions[0]] for vec in patient_df['latent_vector']]
        y_values = [vec[dimensions[1]] for vec in patient_df['latent_vector']]

        # Plot trajectory with connecting lines
        ax.plot(x_values, y_values, '-', color=patient_colors[patient_id], alpha=0.5)

        # Plot individual points with patient labels
        for i, (x, y, date) in enumerate(zip(x_values, y_values, patient_df['exam_date'])):
            # Larger and darker marker for first and last exam
            if i == 0 or i == len(x_values) - 1:
                ax.scatter(x, y, s=100, color=patient_colors[patient_id], marker=marker,
                          edgecolor='black', linewidth=1, alpha=1.0, zorder=3)
                # Add date label for first and last
                date_label = date.split('-')[0] + ('-' + date.split('-')[1] if '-' in date else '')
                ax.annotate(date_label, (x, y), xytext=(5, 5), textcoords='offset points',
                           fontsize=8, bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.7))
            else:
                ax.scatter(x, y, s=60, color=patient_colors[patient_id], marker=marker,
                          edgecolor='black', linewidth=0.5, alpha=0.7, zorder=2)

    # Add legend for patients
    legend_elements = []
    for patient_id in patient_ids:
        patient_data = data[data['patient_id'] == patient_id]
        group = patient_data['group'].iloc[0]
        marker = 'o' if group == 'PD' else ('s' if group == 'Control' else '^')
        legend_elements.append(plt.Line2D([0], [0], marker=marker, color='w', markerfacecolor=patient_colors[patient_id],
                                         markersize=10, label=f"{patient_id} ({group})"))

    ax.legend(handles=legend_elements, loc='best', fontsize=8)
    ax.set_title(title)
    ax.grid(alpha=0.3)

def evaluate_patient_identification(latent_df, stable_dims):
    """
    Evaluate whether patients can be identified from their latent representations
    using leave-one-exam-out cross-validation.

    Parameters:
        latent_df: DataFrame with latent representations
        stable_dims: Dictionary with stable dimensions for AE and VAE
    """
    print("\nEvaluating patient identification from latent space...")

    # Results for each model
    identification_results = {}

    for model_type in ['ae', 'vae']:
        print(f"\nEvaluating {model_type.upper()}...")
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Get different dimension sets to evaluate
        dim_sets = {
            'all_dims': None,  # Use all dimensions
            'stable_dims': stable_dims[model_type]['stable_dims'][:20],
            'discrim_dims': stable_dims[model_type]['discrim_dims'][:20]
        }

        # Store results for this model
        results = {}

        # Evaluate each dimension set
        for dim_set_name, dims in dim_sets.items():
            print(f"\n  Using {dim_set_name}...")

            # Prepare data for cross-validation
            X_all = []
            y_all = []

            for _, row in model_data.iterrows():
                latent_vector = row['latent_vector']

                # Select only the specified dimensions if applicable
                if dims is not None:
                    latent_vector = latent_vector[dims]

                X_all.append(latent_vector)
                y_all.append(row['patient_id'])

            X_all = np.array(X_all)
            y_all = np.array(y_all)

            # Leave-one-exam-out cross-validation
            loo = LeaveOneOut()
            predictions = []
            actual = []

            for train_index, test_index in tqdm(loo.split(X_all), total=len(X_all), desc="LOO Cross-validation"):
                X_train, X_test = X_all[train_index], X_all[test_index]
                y_train, y_test = y_all[train_index], y_all[test_index]

                # Train a simple KNN classifier
                knn = KNeighborsClassifier(n_neighbors=1)
                knn.fit(X_train, y_train)

                # Predict
                pred = knn.predict(X_test)

                predictions.extend(pred)
                actual.extend(y_test)

            # Calculate accuracy
            accuracy = np.mean(np.array(predictions) == np.array(actual))

            print(f"  Accuracy: {accuracy:.4f}")

            # Store results
            results[dim_set_name] = {
                'accuracy': accuracy
            }

        identification_results[model_type] = results

    return identification_results

# Visualize patient latent space evolution
visualize_patient_latent_evolution(latent_df, consistency_results)

# Evaluate patient identification from latent space
identification_results = evaluate_patient_identification(latent_df, consistency_results)

# Final summary
print("\nFinal Insights:")
print("1. Most stable dimensions (consistent within patients):")
for model_type in ['ae', 'vae']:
    print(f"   - {model_type.upper()}: {', '.join(map(str, consistency_results[model_type]['stable_dims'][:5]))}")

print("\n2. Most discriminative dimensions (varying between patients):")
for model_type in ['ae', 'vae']:
    print(f"   - {model_type.upper()}: {', '.join(map(str, consistency_results[model_type]['discrim_dims'][:5]))}")

print("\n3. Patient identification accuracy:")
for model_type in ['ae', 'vae']:
    for dim_set in identification_results[model_type]:
        accuracy = identification_results[model_type][dim_set]['accuracy']
        print(f"   - {model_type.upper()} using {dim_set}: {accuracy:.4f}")

"""# SBR Study with Latent Representations"""

