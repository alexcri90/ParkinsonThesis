# -*- coding: utf-8 -*-
"""Project_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zkbb1EDlzyb3Th4K0IOr--4MKPeUN-z5

# Setup
"""

# Cell 1: Install dependencies
# Uncomment and run the following command if dependencies are not already installed.
# %pip install scikit-learn scikit-image SimpleITK nibabel nilearn albumentations seaborn pandas numpy matplotlib tqdm pydicom scipy
# %pip install umap-learn

# CUDA verification
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
    print(f"CUDA device capability: {torch.cuda.get_device_capability(0)}")

# Cell 2: Import statements and environment setup
import torch

def configure_gpu():
    """
    Configures GPU settings:
    - Detects CUDA device
    - Enables CUDNN benchmarking for improved performance on NVIDIA 4070Ti
    """
    if torch.cuda.is_available():
        device = torch.device("cuda")
        # Enable CUDNN benchmark for optimized convolution algorithm selection
        torch.backends.cudnn.benchmark = True
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
    else:
        raise EnvironmentError("CUDA-compatible GPU not found. Please check your GPU configuration.")

def print_gpu_memory_stats():
    """
    Prints current GPU memory usage for monitoring.
    """
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024 ** 2)
        reserved = torch.cuda.memory_reserved() / (1024 ** 2)
        print(f"GPU Memory Allocated: {allocated:.2f} MB")
        print(f"GPU Memory Reserved: {reserved:.2f} MB")
    else:
        print("CUDA not available.")

# Configure GPU on startup
configure_gpu()
print_gpu_memory_stats()

import warnings
warnings.filterwarnings('ignore')

# Cell 3: GPU Setup and Memory Management
import os
import logging
import warnings
import pandas as pd

# Configure logging for quality assurance (logs will be written to data_ingestion.log)
logging.basicConfig(level=logging.INFO, filename="data_ingestion.log", filemode="w",
                    format="%(asctime)s - %(levelname)s - %(message)s")

def collect_files(base_dir):
    """
    Recursively collects DICOM files only from the expected folders:
    - PPMI_Images_PD: Label "PD"
    - PPMI_Images_SWEDD: Label "SWEDD"
    - PPMI_Images_Cont: Label "Control"

    Excludes any file containing "br_raw" in its path and logs all skipped folders.

    :param base_dir: Base directory containing the Images folder.
    :return: (included_files, excluded_files)
             included_files: list of tuples (full_path, label)
             excluded_files: list of file paths that were excluded.
    """
    included_files = []
    excluded_files = []

    # Define the expected folders and corresponding labels
    expected_folders = {
        "PPMI_Images_PD": "PD",
        "PPMI_Images_SWEDD": "SWEDD",
        "PPMI_Images_Cont": "Control"
    }

    # Iterate over immediate subdirectories in base_dir
    for folder in os.listdir(base_dir):
        folder_path = os.path.join(base_dir, folder)
        if os.path.isdir(folder_path) and folder in expected_folders:
            logging.info(f"Processing folder: {folder_path}")
            # Recursively traverse the expected folder
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    if file.endswith(".dcm"):
                        full_path = os.path.join(root, file)
                        # Exclude any file with "br_raw" in its full path
                        if "br_raw" in full_path:
                            excluded_files.append(full_path)
                            logging.info(f"Excluding raw file: {full_path}")
                        else:
                            included_files.append((full_path, expected_folders[folder]))
        else:
            logging.info(f"Skipping folder: {folder_path}")

    return included_files, excluded_files

def generate_dataframe(included_files):
    """
    Creates a DataFrame from the list of validated file paths.

    :param included_files: List of tuples (file_path, label)
    :return: DataFrame with columns 'file_path' and 'label'
    """
    df = pd.DataFrame(included_files, columns=["file_path", "label"])
    return df

def save_qa_report(total_files, included_count, excluded_count, output_path="data_ingestion_QA_report.csv"):
    """
    Generates and saves a QA report of the file collection process.

    :param total_files: Total number of DICOM files encountered.
    :param included_count: Count of files included after filtering.
    :param excluded_count: Count of files excluded.
    :param output_path: File path for the QA report CSV.
    """
    exclusion_ratio = excluded_count / total_files if total_files > 0 else 0
    qa_report = {
        "total_files": total_files,
        "included_files": included_count,
        "excluded_files": excluded_count,
        "exclusion_ratio": exclusion_ratio,
    }
    qa_df = pd.DataFrame([qa_report])
    qa_df.to_csv(output_path, index=False)
    logging.info("QA report saved to %s", output_path)

    if exclusion_ratio > 0.5:
        warnings.warn(f"High proportion of raw files excluded: {exclusion_ratio:.2%}")

"""## Data Ingestion"""

# !pip install pydicom
# !pip install nibabel

# Cell 4: Data Ingestion Pipeline
import pydicom
import numpy as np

def load_dicom(file_path):
    """
    Loads and processes a DICOM file:
    - Reads the file using pydicom.
    - Converts the pixel array to float32.
    - Applies RescaleSlope and RescaleIntercept if available.

    :param file_path: Path to the DICOM file.
    :return: Tuple (processed_pixel_array, dicom_metadata)
    """
    try:
        ds = pydicom.dcmread(file_path)
    except Exception as e:
        raise IOError(f"Error reading DICOM file {file_path}: {e}")

    # Extract pixel array and convert to float32
    pixel_array = ds.pixel_array.astype(np.float32)

    # Apply rescaling if attributes are present
    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):
        slope = ds.RescaleSlope
        intercept = ds.RescaleIntercept
        pixel_array = pixel_array * slope + intercept

    return pixel_array, ds

# Cell 5: Execute Data Ingestion Pipeline
# Define the base directory containing the "Images" folder (adjust if necessary)
base_dir = "Images"

# Collect files from only the expected subdirectories
included_files, excluded_files = collect_files(base_dir)

# Create a DataFrame for the validated file paths and their labels
df = generate_dataframe(included_files)

# Final validation: Ensure that no "br_raw" files are included
if df["file_path"].str.contains("br_raw").any():
    raise ValueError("Validation failed: 'br_raw' files detected in the final dataset!")

# Save the validated file paths to CSV for reproducibility
df.to_csv("validated_file_paths.csv", index=False)
print("Validated file paths saved to validated_file_paths.csv")

# Generate and save the QA report
total_files = len(included_files) + len(excluded_files)
save_qa_report(total_files, len(included_files), len(excluded_files))
print("QA report generated and saved as data_ingestion_QA_report.csv")

"""## Data Visualization"""

# Cell 6: Visualize One Axial, Coronal, and Sagittal Slice for a Random Patient per Group

import pandas as pd
import random
import matplotlib.pyplot as plt
import numpy as np
import nibabel as nib

# Read the validated file paths CSV generated earlier
df = pd.read_csv("validated_file_paths.csv")

# Function to extract the three orthogonal slices from a 3D volume
def extract_slices(volume):
    """
    Given a 3D volume, returns one axial, one coronal, and one sagittal slice.
    Assumes volume shape is (depth, height, width).
    """
    d, h, w = volume.shape
    axial = volume[32, :, :]         # Axial: slice along depth
    coronal = volume[:, 50, :]        # Coronal: slice along height
    sagittal = volume[:, :, 55]       # Sagittal: slice along width
    return axial, coronal, sagittal

# List of groups and their expected labels
groups = {"PD": "PD", "SWEDD": "SWEDD", "Control": "Control"}
maskH = nib.load('rmask_ICV.nii')
mask = maskH.get_fdata()>0.5
mask = np.transpose(mask,[2, 1, 0])
mask = np.flip(mask,axis=1)
# Create a figure with one row per group and three columns for the views
fig, axes = plt.subplots(nrows=len(groups), ncols=3, figsize=(12, 4 * len(groups)))
fig.suptitle("Axial, Coronal, and Sagittal Slices for a Random Patient per Group", fontsize=16)

for i, (group_key, group_label) in enumerate(groups.items()):
    # Filter DataFrame for the current group
    group_df = df[df["label"] == group_label]
    if group_df.empty:
        print(f"No data found for group {group_label}")
        continue

    # Select a random file from the group
    random_file = group_df.sample(1)["file_path"].values[0]
    print(f"Loading file for group {group_label}: {random_file}")

    # Load the DICOM volume using the previously defined load_dicom() function
    volume, _ = load_dicom(random_file)

    # Verify the volume is 3D (if not, skip or raise an error)
    if volume.ndim != 3:
        raise ValueError(f"Expected 3D volume, got shape {volume.shape} for file: {random_file}")

    axial, coronal, sagittal = extract_slices(volume)

    # Plot Axial slice
    ax = axes[i, 0]
    ax.imshow(axial, cmap="gray")
    ax.set_title(f"{group_label} - Axial")
    ax.axis("off")

    # Plot Coronal slice
    ax = axes[i, 1]
    ax.imshow(coronal, cmap="gray")
    ax.set_title(f"{group_label} - Coronal")
    ax.axis("off")

    # Plot Sagittal slice
    ax = axes[i, 2]
    ax.imshow(sagittal, cmap="gray")
    ax.set_title(f"{group_label} - Sagittal")
    ax.axis("off")

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""## Data Preprocessing

# Performance Metrics & Visualizations

## KL Divergence
"""

# Cell 20: VAE Latent Space Analysis through KL Divergence

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import scipy.stats as stats
from tqdm import tqdm
import gc

def analyze_vae_kl_dimensions(model, dataloader, max_samples=150):
    """
    Analyze the KL divergence contribution of each dimension in the VAE latent space.

    KL divergence in VAEs measures how much the encoded distribution differs from
    the prior (standard normal) distribution. Dimensions with higher KL divergence
    are more "active" and potentially encode more meaningful features.
    """
    device = next(model.parameters()).device
    model.eval()

    # Storage for per-dimension KL and sample metadata
    kl_per_dim = []
    labels = []
    paths = []

    sample_count = 0
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Analyzing KL divergence per dimension"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Encode samples to get mu and log_var
            mu, log_var = model.encode(volumes)

            # Calculate KL divergence per dimension: 0.5 * (mu^2 + exp(log_var) - log_var - 1)
            kl_dims = 0.5 * (mu.pow(2) + log_var.exp() - log_var - 1)

            # Store results
            kl_per_dim.append(kl_dims.cpu().numpy())
            labels.extend(batch_labels)
            paths.extend(batch_paths)

            sample_count += volumes.shape[0]

            # Memory cleanup
            del volumes, mu, log_var, kl_dims
            torch.cuda.empty_cache()

            if sample_count >= max_samples:
                break

    # Stack arrays and trim to max_samples if needed
    kl_per_dim = np.vstack(kl_per_dim)
    if max_samples and len(labels) > max_samples:
        kl_per_dim = kl_per_dim[:max_samples]
        labels = labels[:max_samples]
        paths = paths[:max_samples]

    # Analyze overall KL divergence per dimension
    mean_kl_per_dim = np.mean(kl_per_dim, axis=0)

    # Find most active dimensions (highest KL)
    top_dims_idx = np.argsort(mean_kl_per_dim)[-20:][::-1]
    top_dims_kl = mean_kl_per_dim[top_dims_idx]

    # Plot overall KL per dimension (sorted)
    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    plt.bar(range(len(mean_kl_per_dim)), sorted(mean_kl_per_dim, reverse=True))
    plt.axhline(y=np.mean(mean_kl_per_dim), color='r', linestyle='--', label=f'Mean KL: {np.mean(mean_kl_per_dim):.4f}')
    plt.title('KL Divergence per Dimension (Sorted)')
    plt.xlabel('Dimension Index (Sorted)')
    plt.ylabel('Mean KL Divergence')
    plt.grid(alpha=0.3)
    plt.legend()

    # Plot top 20 dimensions with actual indices
    plt.subplot(1, 2, 2)
    plt.bar(top_dims_idx, top_dims_kl)
    plt.title('Top 20 Most Active Dimensions')
    plt.xlabel('Dimension Index')
    plt.ylabel('Mean KL Divergence')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # Analyze distribution of top dimensions across patient groups
    print(f"\nAnalyzing top 5 most active dimensions across patient groups:")

    # Get unique labels
    unique_labels = list(set(labels))

    # Prepare data for violin plots
    top5_dims = top_dims_idx[:5]

    plt.figure(figsize=(15, 8))
    for i, dim in enumerate(top5_dims):
        plt.subplot(1, 5, i+1)

        # Create a dataframe for this dimension
        dim_df = pd.DataFrame({
            'KL': kl_per_dim[:, dim],
            'Group': labels
        })

        # Create violin plot
        sns.violinplot(x='Group', y='KL', data=dim_df, palette='viridis')
        plt.title(f'Dimension {dim}')
        plt.ylabel('KL Divergence' if i == 0 else '')
        plt.grid(alpha=0.3)

        # Add ANOVA p-value to see if groups are significantly different
        groups_data = [dim_df[dim_df['Group'] == group]['KL'].values for group in unique_labels]
        f_val, p_val = stats.f_oneway(*groups_data)
        plt.annotate(f'p={p_val:.4f}', xy=(0.5, 0.9), xycoords='axes fraction', ha='center')

    plt.tight_layout()
    plt.show()

    # Test predictive power of top dimensions using a simple classifier
    print("\nTesting predictive power of top KL dimensions:")

    # Prepare train/test split (70/30)
    np.random.seed(42)
    indices = np.random.permutation(len(labels))
    train_idx, test_idx = indices[:int(0.7*len(indices))], indices[int(0.7*len(indices)):]

    # Convert labels to numeric for the classifier
    label_map = {label: i for i, label in enumerate(unique_labels)}
    y = np.array([label_map[label] for label in labels])

    # Train a random forest on different sets of dimensions
    for n_dims in [5, 10, 20, 50, 100]:
        if n_dims <= len(top_dims_idx):
            # Get top n dimensions
            selected_dims = top_dims_idx[:n_dims]
            X_selected = kl_per_dim[:, selected_dims]

            # Train model
            clf = RandomForestClassifier(n_estimators=100, random_state=42)
            clf.fit(X_selected[train_idx], y[train_idx])

            # Test model
            y_pred = clf.predict(X_selected[test_idx])
            accuracy = accuracy_score(y[test_idx], y_pred)

            print(f"Accuracy using top {n_dims} KL dimensions: {accuracy:.4f}")

            # Feature importance
            if n_dims <= 20:  # Only show for smaller sets
                importances = clf.feature_importances_
                indices = np.argsort(importances)[::-1]

                print("  Top 5 most important dimensions:")
                for i in range(min(5, n_dims)):
                    print(f"    Dim {selected_dims[indices[i]]}: {importances[indices[i]]:.4f}")

    return kl_per_dim, top_dims_idx, labels, paths

# Load the trained VAE model from previous cells
print("Loading trained VAE model...")
# Using the load_trained_vae function from Cell 18
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Analyze VAE KL divergence per dimension
print("\nAnalyzing VAE latent dimensions through KL divergence...")
kl_per_dim, top_dims, labels, paths = analyze_vae_kl_dimensions(
    vae_model, val_loader, max_samples=150)

print("KL Divergence Analysis completed!")

# Cell 21: Visualization of Top KL Dimensions in Brain Space

# Now let's visualize what the top dimensions represent in the brain space
print("Visualizing top KL dimensions in brain space...")

# Select the top 3 dimensions with highest KL divergence
top_3_dims = top_dims[:3]
print(f"Analyzing dimensions: {top_3_dims}")

# For each dimension, visualize its effect on reconstruction
for dim_idx in top_3_dims:
    print(f"\nVisualizing dimension {dim_idx}...")

    # Use the existing function from Cell 15
    visualize_vae_latent_dimension(vae_model, val_loader, dimension_idx=dim_idx, alpha=5.0)

    # Generate feature importance map
    print(f"Generating feature importance map for dimension {dim_idx}")
    for group in ['PD', 'Control']:
        generate_vae_feature_importance_map(
            vae_model, val_loader, dimension_idx=dim_idx, group=group, num_samples=8)

print("Top dimensions visualization completed!")

# Cell 22: Analysis of Latent Space Distributions and Alpha Values

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# Function to analyze autoencoder
def analyze_ae_alpha(ae_model, dataloader, alpha_value=8.0, max_samples=200):
    """Calculate how many standard deviations alpha represents for AE dimensions"""
    device = next(ae_model.parameters()).device
    ae_model.eval()

    print(f"Analyzing Autoencoder latent space (alpha = {alpha_value})...")

    # Storage for latent vectors
    latent_vectors = []

    # Extract latent vectors
    with torch.no_grad():
        sample_count = 0
        for batch in tqdm(dataloader, desc="Extracting AE latent vectors"):
            volumes = batch['volume'].to(device)

            # Get AE latent vectors
            z = ae_model.encode(volumes)

            # Store results
            latent_vectors.append(z.cpu().numpy())

            # Update counter and check limit
            sample_count += len(volumes)
            if sample_count >= max_samples:
                break

            # Memory cleanup
            del volumes, z
            torch.cuda.empty_cache()

    # Stack arrays
    latent_vectors = np.vstack(latent_vectors)
    print(f"Collected {latent_vectors.shape[0]} samples with {latent_vectors.shape[1]} dimensions")

    # Calculate statistics
    dim_stds = np.std(latent_vectors, axis=0)
    alpha_in_std_devs = alpha_value / dim_stds

    # Print statistics
    print(f"\nAutoencoder Latent Space Statistics:")
    print(f"  Alpha value: {alpha_value}")
    print(f"  Mean standard deviation: {np.mean(dim_stds):.4f}")
    print(f"  Alpha in std devs: mean = {np.mean(alpha_in_std_devs):.2f}, min = {np.min(alpha_in_std_devs):.2f}, max = {np.max(alpha_in_std_devs):.2f}")

    # Create histogram
    plt.figure(figsize=(10, 6))
    plt.hist(alpha_in_std_devs, bins=30, color='#A1CAF1')
    plt.axvline(x=1, color='r', linestyle='--', label='1 std dev')
    plt.axvline(x=2, color='r', linestyle=':', label='2 std devs')
    plt.axvline(x=3, color='r', linestyle='-.', label='3 std devs')
    plt.xlabel(f'Alpha ({alpha_value}) in Standard Deviations', fontsize=12)
    plt.ylabel('Count of Dimensions', fontsize=12)
    plt.title('Autoencoder: How Many Standard Deviations Does Alpha Represent?', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    return latent_vectors, dim_stds, alpha_in_std_devs

# Function to analyze VAE
def analyze_vae_alpha(vae_model, dataloader, alpha_value=5.0, max_samples=200):
    """Calculate how many standard deviations alpha represents for VAE dimensions"""
    device = next(vae_model.parameters()).device
    vae_model.eval()

    print(f"Analyzing VAE latent space (alpha = {alpha_value})...")

    # Storage for latent vectors
    latent_means = []

    # Extract latent vectors
    with torch.no_grad():
        sample_count = 0
        for batch in tqdm(dataloader, desc="Extracting VAE latent vectors"):
            volumes = batch['volume'].to(device)

            # Get VAE latent vectors - return is (mu, log_var)
            mu, _ = vae_model.encode(volumes)

            # Store results
            latent_means.append(mu.cpu().numpy())

            # Update counter and check limit
            sample_count += len(volumes)
            if sample_count >= max_samples:
                break

            # Memory cleanup
            del volumes, mu
            torch.cuda.empty_cache()

    # Stack arrays
    latent_means = np.vstack(latent_means)
    print(f"Collected {latent_means.shape[0]} samples with {latent_means.shape[1]} dimensions")

    # Calculate statistics
    dim_stds = np.std(latent_means, axis=0)
    alpha_in_std_devs = alpha_value / dim_stds

    # Print statistics
    print(f"\nVAE Latent Space Statistics:")
    print(f"  Alpha value: {alpha_value}")
    print(f"  Mean standard deviation: {np.mean(dim_stds):.4f}")
    print(f"  Alpha in std devs: mean = {np.mean(alpha_in_std_devs):.2f}, min = {np.min(alpha_in_std_devs):.2f}, max = {np.max(alpha_in_std_devs):.2f}")

    # Create histogram
    plt.figure(figsize=(10, 6))
    plt.hist(alpha_in_std_devs, bins=30, color='#F08080')
    plt.axvline(x=1, color='r', linestyle='--', label='1 std dev')
    plt.axvline(x=2, color='r', linestyle=':', label='2 std devs')
    plt.axvline(x=3, color='r', linestyle='-.', label='3 std devs')
    plt.xlabel(f'Alpha ({alpha_value}) in Standard Deviations', fontsize=12)
    plt.ylabel('Count of Dimensions', fontsize=12)
    plt.title('VAE: How Many Standard Deviations Does Alpha Represent?', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    return latent_means, dim_stds, alpha_in_std_devs

# Function to analyze specific dimensions
def analyze_specific_dimension(model, dataloader, dimension, is_vae=False, alpha_value=8.0, max_samples=200):
    """Analyze a specific latent dimension in detail"""
    device = next(model.parameters()).device
    model.eval()
    model_name = "VAE" if is_vae else "Autoencoder"

    print(f"Analyzing {model_name} dimension {dimension} (alpha = {alpha_value})...")

    # Storage for dimension values
    dim_values = []

    # Extract latent vectors
    with torch.no_grad():
        sample_count = 0
        for batch in tqdm(dataloader, desc=f"Extracting {model_name} dimension {dimension}"):
            volumes = batch['volume'].to(device)

            # Get latent vectors
            if is_vae:
                z, _ = model.encode(volumes)  # For VAE, get mean vectors
            else:
                z = model.encode(volumes)  # For AE, get latent vectors

            # Extract the specific dimension
            dim_values.extend(z[:, dimension].cpu().numpy())

            # Update counter and check limit
            sample_count += len(volumes)
            if sample_count >= max_samples:
                break

            # Memory cleanup
            del volumes, z
            torch.cuda.empty_cache()

    # Convert to numpy array
    dim_values = np.array(dim_values)

    # Calculate statistics
    dim_mean = np.mean(dim_values)
    dim_std = np.std(dim_values)

    # Print statistics
    print(f"\n{model_name} Dimension {dimension} Statistics:")
    print(f"  Mean: {dim_mean:.4f}")
    print(f"  Standard deviation: {dim_std:.4f}")
    print(f"  Alpha ({alpha_value}) in std devs: {alpha_value / dim_std:.2f}")

    # Create visualization
    plt.figure(figsize=(10, 6))

    # Plot histogram with KDE
    sns.histplot(dim_values, kde=True)

    # Add lines for mean and perturbations
    plt.axvline(x=dim_mean, color='r', linestyle='-', label='Mean')
    plt.axvline(x=dim_mean + alpha_value, color='g', linestyle='--', label=f'Mean + α ({alpha_value})')
    plt.axvline(x=dim_mean - alpha_value, color='b', linestyle='--', label=f'Mean - α ({alpha_value})')

    # Add lines for standard deviations
    for i in range(1, 4):
        plt.axvline(x=dim_mean + i*dim_std, color='k', linestyle=':', alpha=0.5, label=f'+{i} std' if i == 1 else None)
        plt.axvline(x=dim_mean - i*dim_std, color='k', linestyle=':', alpha=0.5, label=f'-{i} std' if i == 1 else None)

    plt.xlabel('Dimension Value', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.title(f'{model_name} Dimension {dimension} Distribution\nAlpha={alpha_value} = {alpha_value/dim_std:.2f} std devs', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    return dim_values, dim_mean, dim_std

# Load the trained models (if not already loaded)
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Analyze both models
print("\nAnalyzing alpha values in terms of standard deviations...")
ae_vectors, ae_stds, ae_alpha_in_stds = analyze_ae_alpha(ae_model, val_loader, alpha_value=8.0, max_samples=200)
vae_means, vae_stds, vae_alpha_in_stds = analyze_vae_alpha(vae_model, val_loader, alpha_value=5.0, max_samples=200)

# Analyze specific dimensions mentioned in the original code
print("\nAnalyzing specific dimensions of interest:")
for dim in [231, 94, 154]:  # Top dimensions analyzed in previous cells
    print(f"\nDimension {dim}:")
    analyze_specific_dimension(ae_model, val_loader, dim, is_vae=False, alpha_value=8.0, max_samples=200)
    analyze_specific_dimension(vae_model, val_loader, dim, is_vae=True, alpha_value=5.0, max_samples=200)

"""## Metadata Analysis with Latent Dimensions"""

# Cell 23: Metadata Dimension Analysis with Improved Visualization

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import torch
import re
import scipy.stats as stats

def analyze_metadata_dimensions(ae_model, vae_model, dataloader, metadata_path="dicom_metadata.csv", max_samples=150):
    """
    Analyze how specific dimensions in the latent spaces correlate with metadata.
    """
    print("\nAnalyzing correlation between latent dimensions and metadata...")

    # Load metadata CSV
    if not os.path.exists(metadata_path):
        print(f"Error: Metadata file {metadata_path} not found!")
        return None

    # Load with proper type handling
    metadata_df = pd.read_csv(metadata_path)
    print(f"Loaded metadata with {len(metadata_df)} entries and columns: {metadata_df.columns.tolist()}")

    # Check data types and missing values
    print("\nData types in metadata:")
    print(metadata_df.dtypes)

    print("\nMissing values in metadata:")
    print(metadata_df.isnull().sum())

    # Extract latent vectors from models
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    sample_paths = []
    sample_labels = []
    ae_latent_vecs = []
    vae_latent_means = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Get latent vectors
            ae_z = ae_model.encode(volumes)
            vae_mu, _ = vae_model.encode(volumes)

            # Store results
            ae_latent_vecs.append(ae_z.cpu().numpy())
            vae_latent_means.append(vae_mu.cpu().numpy())
            sample_paths.extend(batch_paths)
            sample_labels.extend(batch_labels)

            # Memory cleanup
            del volumes, ae_z, vae_mu
            torch.cuda.empty_cache()

            if len(sample_paths) >= max_samples:
                break

    # Stack arrays
    ae_latent_vecs = np.vstack(ae_latent_vecs)
    vae_latent_means = np.vstack(vae_latent_means)

    # Create dataframe with sample info
    sample_df = pd.DataFrame({
        'file_path': sample_paths,
        'group': sample_labels
    })

    # Normalize paths for matching
    sample_df['file_path_norm'] = sample_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )
    metadata_df['file_path_norm'] = metadata_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )

    # Extract patient IDs as a fallback matching strategy
    def extract_patient_id(path):
        path = path.replace('\\', '/')
        match = re.search(r'PPMI_(\d+)_', path)
        if match:
            return match.group(1)
        match = re.search(r'PPMI_Images_\w+/(\d+)/', path)
        if match:
            return match.group(1)
        return None

    sample_df['patient_id'] = sample_df['file_path'].apply(extract_patient_id)
    metadata_df['patient_id'] = metadata_df['file_path'].apply(extract_patient_id)

    # Try to match by filename first
    merged_df = pd.merge(sample_df, metadata_df, on='file_path_norm', how='inner', suffixes=('_sample', '_meta'))

    # If that doesn't work well, try matching by patient ID
    if len(merged_df) < 10:
        print("Filename matching failed, trying patient ID matching...")
        merged_df = pd.merge(sample_df, metadata_df, on='patient_id', how='inner', suffixes=('_sample', '_meta'))

    print(f"Successfully matched {len(merged_df)} samples with metadata")

    if len(merged_df) < 10:
        print("Error: Insufficient matches for analysis. Check file paths.")
        print("Sample patient IDs:", sample_df['patient_id'].dropna().unique()[:10])
        print("Metadata patient IDs:", metadata_df['patient_id'].dropna().unique()[:10])
        return None

    # Get indices of matched samples to extract latent vectors
    matched_indices = [sample_paths.index(path) for path in merged_df['file_path_sample']]
    ae_matched = ae_latent_vecs[matched_indices]
    vae_matched = vae_latent_means[matched_indices]

    # Analyze categorical metadata fields
    categorical_fields = ['PatientSex', 'StudyDescription', 'Manufacturer', 'ManufacturerModelName']

    # Results storage
    dimension_analysis = {
        'ae': {field: {} for field in categorical_fields},
        'vae': {field: {} for field in categorical_fields}
    }

    # Analyze each metadata field
    for field in categorical_fields:
        field_meta = field + '_meta' if field + '_meta' in merged_df.columns else field

        if field_meta not in merged_df.columns:
            print(f"Warning: Field '{field}' not found in metadata")
            continue

        print(f"\nAnalyzing field '{field}'...")

        # Check data type and handle properly
        print(f"Data type for {field_meta}: {merged_df[field_meta].dtype}")

        # Handle nulls and convert to string for consistent processing
        field_values = merged_df[field_meta].fillna('Unknown').astype(str).values

        # Now get unique values safely
        unique_values = np.unique(field_values)
        print(f"Unique values: {unique_values}")

        # Skip if less than 2 categories
        if len(unique_values) < 2:
            print(f"Skipping '{field}' - only one unique value found")
            continue

        # Count samples per category
        value_counts = pd.Series(field_values).value_counts()
        print(f"Counts per category: {dict(value_counts)}")

        # Skip categories with too few samples
        keep_values = value_counts[value_counts >= 5].index.tolist()
        if len(keep_values) < 2:
            print(f"Skipping '{field}' - insufficient samples per category")
            continue

        # Filter to keep only samples with sufficient category representation
        keep_mask = np.array([v in keep_values for v in field_values])
        if keep_mask.sum() < 10:
            print(f"Skipping '{field}' - insufficient samples after filtering")
            continue

        filtered_values = field_values[keep_mask]
        ae_filtered = ae_matched[keep_mask]
        vae_filtered = vae_matched[keep_mask]

        print(f"Analyzing with {len(filtered_values)} samples across {len(keep_values)} categories")

        # Calculate dimension scores
        ae_scores = np.zeros(ae_filtered.shape[1])
        vae_scores = np.zeros(vae_filtered.shape[1])
        ae_p_values = np.ones(ae_filtered.shape[1])
        vae_p_values = np.ones(vae_filtered.shape[1])

        # Convert categorical values to numeric for analysis
        value_map = {val: i for i, val in enumerate(keep_values)}
        y = np.array([value_map[val] for val in filtered_values])

        # DIMENSION SELECTION METHOD:
        # Using ANOVA F-statistic to measure how well each dimension separates different categories
        for dim in range(ae_filtered.shape[1]):
            try:
                # Group data by category for ANOVA
                groups = [ae_filtered[filtered_values == val, dim] for val in keep_values]
                # Some groups might be empty or have only one sample
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    ae_scores[dim] = f_val
                    ae_p_values[dim] = p_val
                else:
                    ae_scores[dim] = 0
                    ae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing AE dimension {dim}: {e}")
                ae_scores[dim] = 0
                ae_p_values[dim] = 1.0

        for dim in range(vae_filtered.shape[1]):
            try:
                groups = [vae_filtered[filtered_values == val, dim] for val in keep_values]
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    vae_scores[dim] = f_val
                    vae_p_values[dim] = p_val
                else:
                    vae_scores[dim] = 0
                    vae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing VAE dimension {dim}: {e}")
                vae_scores[dim] = 0
                vae_p_values[dim] = 1.0

        # Find top dimensions (highest F-statistic and p < 0.05)
        ae_signif_dims = np.where(ae_p_values < 0.05)[0]
        vae_signif_dims = np.where(vae_p_values < 0.05)[0]

        ae_top_dims = ae_signif_dims[np.argsort(ae_scores[ae_signif_dims])[::-1][:10]]
        vae_top_dims = vae_signif_dims[np.argsort(vae_scores[vae_signif_dims])[::-1][:10]]

        print(f"\nTop 10 AE dimensions for {field}:")
        for i, dim in enumerate(ae_top_dims):
            print(f"  Dimension {dim}: F-statistic={ae_scores[dim]:.2f}, p-value={ae_p_values[dim]:.4f}")

        print(f"\nTop 10 VAE dimensions for {field}:")
        for i, dim in enumerate(vae_top_dims):
            print(f"  Dimension {dim}: F-statistic={vae_scores[dim]:.2f}, p-value={vae_p_values[dim]:.4f}")

        # Visualize top dimensions with separate plots for AE and VAE
        if len(ae_top_dims) > 0 or len(vae_top_dims) > 0:
            # Abbreviate labels if needed
            labels = []
            for val in keep_values:
                if len(val) > 20:  # If label is too long
                    shortened = val[:17] + "..."
                else:
                    shortened = val
                labels.append(shortened)

            # AE DIMENSIONS PLOT (if we have significant dimensions)
            if len(ae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"AE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top AE dimensions
                for i, dim in enumerate(ae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(ae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'AE Dimension {dim}', fontsize=14)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)  # Add padding for better readability
                        plt.grid(axis='y', alpha=0.3)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

            # VAE DIMENSIONS PLOT (if we have significant dimensions)
            if len(vae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"VAE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top VAE dimensions
                for i, dim in enumerate(vae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(vae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'VAE Dimension {dim}', fontsize=14)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)  # Add padding for better readability
                        plt.grid(axis='y', alpha=0.3)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

        # Store results
        dimension_analysis['ae'][field] = {
            'scores': ae_scores,
            'p_values': ae_p_values,
            'top_dims': ae_top_dims.tolist()
        }

        dimension_analysis['vae'][field] = {
            'scores': vae_scores,
            'p_values': vae_p_values,
            'top_dims': vae_top_dims.tolist()
        }

    return dimension_analysis

# Load both models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the dimension analysis
print("\nAnalyzing which dimensions correlate with metadata...")
dimension_results = analyze_metadata_dimensions(
    ae_model, vae_model, val_loader,
    metadata_path="dicom_metadata.csv", max_samples=150)

print("\nDimension analysis completed!")

# Cell 24: Metadata Dimension Analysis with Debug Output

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import torch
import re
import scipy.stats as stats

def analyze_metadata_dimensions(ae_model, vae_model, dataloader, metadata_path="dicom_metadata.csv", max_samples=150, debug=True):
    """
    Analyze how specific dimensions in the latent spaces correlate with metadata.
    """
    print("\nAnalyzing correlation between latent dimensions and metadata...")

    # Load metadata CSV
    if not os.path.exists(metadata_path):
        print(f"Error: Metadata file {metadata_path} not found!")
        return None

    # Load with proper type handling
    metadata_df = pd.read_csv(metadata_path)
    print(f"Loaded metadata with {len(metadata_df)} entries and columns: {metadata_df.columns.tolist()}")

    # Check data types and missing values
    print("\nData types in metadata:")
    print(metadata_df.dtypes)

    print("\nMissing values in metadata:")
    print(metadata_df.isnull().sum())

    # Extract latent vectors from models
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    sample_paths = []
    sample_labels = []
    ae_latent_vecs = []
    vae_latent_means = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Get latent vectors
            ae_z = ae_model.encode(volumes)
            vae_mu, _ = vae_model.encode(volumes)

            # Store results
            ae_latent_vecs.append(ae_z.cpu().numpy())
            vae_latent_means.append(vae_mu.cpu().numpy())
            sample_paths.extend(batch_paths)
            sample_labels.extend(batch_labels)

            # Memory cleanup
            del volumes, ae_z, vae_mu
            torch.cuda.empty_cache()

            if len(sample_paths) >= max_samples:
                break

    # Stack arrays
    ae_latent_vecs = np.vstack(ae_latent_vecs)
    vae_latent_means = np.vstack(vae_latent_means)

    print(f"Extracted latent vectors: AE shape={ae_latent_vecs.shape}, VAE shape={vae_latent_means.shape}")

    # Create dataframe with sample info
    sample_df = pd.DataFrame({
        'file_path': sample_paths,
        'group': sample_labels
    })

    # Normalize paths for matching
    sample_df['file_path_norm'] = sample_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )
    metadata_df['file_path_norm'] = metadata_df['file_path'].apply(
        lambda x: os.path.basename(x.replace('\\', '/'))
    )

    # Extract patient IDs as a fallback matching strategy
    def extract_patient_id(path):
        path = path.replace('\\', '/')
        match = re.search(r'PPMI_(\d+)_', path)
        if match:
            return match.group(1)
        match = re.search(r'PPMI_Images_\w+/(\d+)/', path)
        if match:
            return match.group(1)
        return None

    sample_df['patient_id'] = sample_df['file_path'].apply(extract_patient_id)
    metadata_df['patient_id'] = metadata_df['file_path'].apply(extract_patient_id)

    # Try to match by filename first
    merged_df = pd.merge(sample_df, metadata_df, on='file_path_norm', how='inner', suffixes=('_sample', '_meta'))

    # If that doesn't work well, try matching by patient ID
    if len(merged_df) < 10:
        print("Filename matching failed, trying patient ID matching...")
        merged_df = pd.merge(sample_df, metadata_df, on='patient_id', how='inner', suffixes=('_sample', '_meta'))

    print(f"Successfully matched {len(merged_df)} samples with metadata")

    if len(merged_df) < 10:
        print("Error: Insufficient matches for analysis. Check file paths.")
        print("Sample patient IDs:", sample_df['patient_id'].dropna().unique()[:10])
        print("Metadata patient IDs:", metadata_df['patient_id'].dropna().unique()[:10])
        return None

    # Get indices of matched samples to extract latent vectors
    matched_indices = [sample_paths.index(path) for path in merged_df['file_path_sample']]
    ae_matched = ae_latent_vecs[matched_indices]
    vae_matched = vae_latent_means[matched_indices]

    print(f"Matched latent vectors: AE shape={ae_matched.shape}, VAE shape={vae_matched.shape}")

    # Analyze categorical metadata fields
    categorical_fields = ['PatientSex', 'StudyDescription', 'Manufacturer', 'ManufacturerModelName']

    # Results storage
    dimension_analysis = {
        'ae': {field: {} for field in categorical_fields},
        'vae': {field: {} for field in categorical_fields}
    }

    # Analyze each metadata field
    for field in categorical_fields:
        field_meta = field + '_meta' if field + '_meta' in merged_df.columns else field

        if field_meta not in merged_df.columns:
            print(f"Warning: Field '{field}' not found in metadata")
            continue

        print(f"\nAnalyzing field '{field}'...")

        # Check data type and handle properly
        print(f"Data type for {field_meta}: {merged_df[field_meta].dtype}")

        # Handle nulls and convert to string for consistent processing
        field_values = merged_df[field_meta].fillna('Unknown').astype(str).values

        # Now get unique values safely
        unique_values = np.unique(field_values)
        print(f"Unique values: {unique_values}")

        # Skip if less than 2 categories
        if len(unique_values) < 2:
            print(f"Skipping '{field}' - only one unique value found")
            continue

        # Count samples per category
        value_counts = pd.Series(field_values).value_counts()
        print(f"Counts per category: {dict(value_counts)}")

        # Skip categories with too few samples
        keep_values = value_counts[value_counts >= 5].index.tolist()
        if len(keep_values) < 2:
            print(f"Skipping '{field}' - insufficient samples per category")
            continue

        # Filter to keep only samples with sufficient category representation
        keep_mask = np.array([v in keep_values for v in field_values])
        if keep_mask.sum() < 10:
            print(f"Skipping '{field}' - insufficient samples after filtering")
            continue

        filtered_values = field_values[keep_mask]
        ae_filtered = ae_matched[keep_mask]
        vae_filtered = vae_matched[keep_mask]

        print(f"Analyzing with {len(filtered_values)} samples across {len(keep_values)} categories")

        # Calculate dimension scores
        ae_scores = np.zeros(ae_filtered.shape[1])
        vae_scores = np.zeros(vae_filtered.shape[1])
        ae_p_values = np.ones(ae_filtered.shape[1])
        vae_p_values = np.ones(vae_filtered.shape[1])

        # Convert categorical values to numeric for analysis
        value_map = {val: i for i, val in enumerate(keep_values)}
        y = np.array([value_map[val] for val in filtered_values])

        print(f"Starting F-statistic calculation for {ae_filtered.shape[1]} AE dimensions...")
        start_time = time.time()

        # Debug: Log processed dimensions
        processed_dims = 0
        success_dims = 0

        # DIMENSION SELECTION METHOD:
        # Using ANOVA F-statistic to measure how well each dimension separates different categories
        for dim in range(ae_filtered.shape[1]):
            processed_dims += 1
            try:
                # Group data by category for ANOVA
                groups = [ae_filtered[filtered_values == val, dim] for val in keep_values]

                # Verify we have enough data in each group
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    ae_scores[dim] = f_val
                    ae_p_values[dim] = p_val
                    success_dims += 1

                    # Debug: print some values periodically
                    if debug and dim % 50 == 0:
                        print(f"  AE Dim {dim}: F={f_val:.2f}, p={p_val:.4f}, group sizes: {[len(g) for g in groups]}")
                else:
                    if debug and dim % 50 == 0:
                        print(f"  AE Dim {dim}: Skipped - insufficient samples in groups: {[len(g) for g in groups]}")
                    ae_scores[dim] = 0
                    ae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing AE dimension {dim}: {e}")
                ae_scores[dim] = 0
                ae_p_values[dim] = 1.0

        print(f"Completed AE dimension analysis in {time.time() - start_time:.2f} seconds")
        print(f"Processed {processed_dims}/{ae_filtered.shape[1]} dimensions, {success_dims} with valid calculations")

        print(f"Starting F-statistic calculation for {vae_filtered.shape[1]} VAE dimensions...")
        start_time = time.time()

        # Reset counters for VAE
        processed_dims = 0
        success_dims = 0

        for dim in range(vae_filtered.shape[1]):
            processed_dims += 1
            try:
                groups = [vae_filtered[filtered_values == val, dim] for val in keep_values]
                if all(len(g) > 1 for g in groups):
                    f_val, p_val = stats.f_oneway(*groups)
                    vae_scores[dim] = f_val
                    vae_p_values[dim] = p_val
                    success_dims += 1

                    # Debug: print some values periodically
                    if debug and dim % 50 == 0:
                        print(f"  VAE Dim {dim}: F={f_val:.2f}, p={p_val:.4f}, group sizes: {[len(g) for g in groups]}")
                else:
                    if debug and dim % 50 == 0:
                        print(f"  VAE Dim {dim}: Skipped - insufficient samples in groups: {[len(g) for g in groups]}")
                    vae_scores[dim] = 0
                    vae_p_values[dim] = 1.0
            except Exception as e:
                print(f"Error analyzing VAE dimension {dim}: {e}")
                vae_scores[dim] = 0
                vae_p_values[dim] = 1.0

        print(f"Completed VAE dimension analysis in {time.time() - start_time:.2f} seconds")
        print(f"Processed {processed_dims}/{vae_filtered.shape[1]} dimensions, {success_dims} with valid calculations")

        # ADD DETAILED DEBUGGING OUTPUT
        print(f"\nF-statistic Calculation Results for {field}:")
        print(f"AE dimensions with p < 0.05: {np.sum(ae_p_values < 0.05)} out of {len(ae_p_values)}")
        print(f"VAE dimensions with p < 0.05: {np.sum(vae_p_values < 0.05)} out of {len(vae_p_values)}")
        print(f"Top 5 AE F-statistics: {sorted(ae_scores)[-5:]}")
        print(f"Top 5 VAE F-statistics: {sorted(vae_scores)[-5:]}")
        print(f"Mean AE F-statistic: {np.mean(ae_scores):.4f}")
        print(f"Mean VAE F-statistic: {np.mean(vae_scores):.4f}")

        # Plot histogram of F-statistics to see distribution
        plt.figure(figsize=(15, 6))
        plt.subplot(1, 2, 1)
        plt.hist(ae_scores, bins=30)
        plt.title(f'AE F-statistic Distribution for {field}')
        plt.xlabel('F-statistic')
        plt.ylabel('Count')
        plt.grid(alpha=0.3)

        plt.subplot(1, 2, 2)
        plt.hist(vae_scores, bins=30)
        plt.title(f'VAE F-statistic Distribution for {field}')
        plt.xlabel('F-statistic')
        plt.ylabel('Count')
        plt.grid(alpha=0.3)

        plt.tight_layout()
        plt.show()

        # Find top dimensions (highest F-statistic and p < 0.05)
        ae_signif_dims = np.where(ae_p_values < 0.05)[0]
        vae_signif_dims = np.where(vae_p_values < 0.05)[0]

        print(f"Found {len(ae_signif_dims)} significant AE dimensions")
        print(f"Found {len(vae_signif_dims)} significant VAE dimensions")

        if len(ae_signif_dims) > 0:
            ae_top_dims = ae_signif_dims[np.argsort(ae_scores[ae_signif_dims])[::-1][:10]]
        else:
            ae_top_dims = np.argsort(ae_scores)[::-1][:10]  # Just use highest F even if not significant

        if len(vae_signif_dims) > 0:
            vae_top_dims = vae_signif_dims[np.argsort(vae_scores[vae_signif_dims])[::-1][:10]]
        else:
            vae_top_dims = np.argsort(vae_scores)[::-1][:10]  # Just use highest F even if not significant

        print(f"\nTop 10 AE dimensions for {field}:")
        for i, dim in enumerate(ae_top_dims):
            print(f"  Dimension {dim}: F-statistic={ae_scores[dim]:.2f}, p-value={ae_p_values[dim]:.4f}")

        print(f"\nTop 10 VAE dimensions for {field}:")
        for i, dim in enumerate(vae_top_dims):
            print(f"  Dimension {dim}: F-statistic={vae_scores[dim]:.2f}, p-value={vae_p_values[dim]:.4f}")

        # Visualize top dimensions with separate plots for AE and VAE
        if len(ae_top_dims) > 0 or len(vae_top_dims) > 0:
            # Abbreviate labels if needed
            labels = []
            for val in keep_values:
                if len(val) > 20:  # If label is too long
                    shortened = val[:17] + "..."
                else:
                    shortened = val
                labels.append(shortened)

            # STANDARDIZED Y-AXIS RANGES
            # Calculate global min/max for all top AE dimensions to be plotted
            ae_data_for_plot = []
            for dim in ae_top_dims[:3]:
                for val in keep_values:
                    mask = filtered_values == val
                    ae_data_for_plot.extend(ae_filtered[mask, dim])

            # Calculate global min/max for all top VAE dimensions to be plotted
            vae_data_for_plot = []
            for dim in vae_top_dims[:3]:
                for val in keep_values:
                    mask = filtered_values == val
                    vae_data_for_plot.extend(vae_filtered[mask, dim])

            # Determine y-axis ranges with 10% padding
            if ae_data_for_plot:
                ae_min = np.min(ae_data_for_plot)
                ae_max = np.max(ae_data_for_plot)
                ae_range = ae_max - ae_min
                ae_y_min = ae_min - 0.1 * ae_range
                ae_y_max = ae_max + 0.1 * ae_range

            if vae_data_for_plot:
                vae_min = np.min(vae_data_for_plot)
                vae_max = np.max(vae_data_for_plot)
                vae_range = vae_max - vae_min
                vae_y_min = vae_min - 0.1 * vae_range
                vae_y_max = vae_max + 0.1 * vae_range

            # AE DIMENSIONS PLOT (if we have significant dimensions)
            if len(ae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"AE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top AE dimensions
                for i, dim in enumerate(ae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(ae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'AE Dimension {dim} (F={ae_scores[dim]:.2f}, p={ae_p_values[dim]:.4f})', fontsize=12)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)
                        plt.grid(axis='y', alpha=0.3)

                        # Set consistent y-axis limits
                        plt.ylim(ae_y_min, ae_y_max)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

            # VAE DIMENSIONS PLOT (if we have significant dimensions)
            if len(vae_top_dims) > 0:
                plt.figure(figsize=(20, 8))
                plt.suptitle(f"VAE Dimensions Correlated with {field}", fontsize=18)

                # Plot up to 3 top VAE dimensions
                for i, dim in enumerate(vae_top_dims[:3]):
                    if i < 3:  # Only plot first 3
                        plt.subplot(1, 3, i+1)

                        # Create boxplot with clear labels (no colors)
                        data = []
                        for val in keep_values:
                            mask = filtered_values == val
                            data.append(vae_filtered[mask, dim])

                        # Standard boxplot without colors
                        plt.boxplot(data)

                        plt.title(f'VAE Dimension {dim} (F={vae_scores[dim]:.2f}, p={vae_p_values[dim]:.4f})', fontsize=12)
                        plt.ylabel('Dimension Value', fontsize=12)

                        # Set x-ticks with increased spacing
                        plt.xticks(range(1, len(labels)+1), labels, rotation=90, fontsize=10)
                        plt.tick_params(axis='x', which='major', pad=15)
                        plt.grid(axis='y', alpha=0.3)

                        # Set consistent y-axis limits
                        plt.ylim(vae_y_min, vae_y_max)

                # Ensure there's plenty of space
                plt.tight_layout()
                plt.subplots_adjust(bottom=0.4, wspace=0.3)
                plt.show()

        # Store results
        dimension_analysis['ae'][field] = {
            'scores': ae_scores,
            'p_values': ae_p_values,
            'top_dims': ae_top_dims.tolist()
        }

        dimension_analysis['vae'][field] = {
            'scores': vae_scores,
            'p_values': vae_p_values,
            'top_dims': vae_top_dims.tolist()
        }

    return dimension_analysis

# Make sure to import time for the timing measurements
import time

# Load both models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the dimension analysis with debug information
print("\nAnalyzing which dimensions correlate with metadata...")
dimension_results = analyze_metadata_dimensions(
    ae_model, vae_model, val_loader,
    metadata_path="dicom_metadata.csv", max_samples=500,
    debug=True)  # Enable debug output

print("\nDimension analysis completed!")

"""## Group Separation"""

# Cell 25: VAE Latent Dimension Analysis for Patient Group Separation

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mutual_info_score
from scipy.stats import f_oneway
import scipy.stats as stats
from tqdm import tqdm
import gc

def analyze_vae_dimensions_for_group_separation(model, dataloader, max_samples=200):
    """
    Analyze how individual VAE latent dimensions separate between patient groups (PD, Control, SWEDD).

    This analysis focuses on:
    1. Which dimensions have highest KL divergence (most "active" dimensions)
    2. Which dimensions best separate between patient groups
    3. Visualizing the distribution of top dimensions across groups
    """
    device = next(model.parameters()).device
    model.eval()

    # Storage for latent vectors and metadata
    latent_means = []
    latent_logvars = []
    kl_per_dim = []
    labels = []
    paths = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting VAE latent vectors"):
            try:
                volumes = batch['volume'].to(device)
                batch_labels = batch['label']
                batch_paths = batch['path']

                # Extract latent vectors
                mu, log_var = model.encode(volumes)

                # Calculate KL divergence per dimension: 0.5 * (mu^2 + exp(log_var) - log_var - 1)
                kl_dims = 0.5 * (mu.pow(2) + log_var.exp() - log_var - 1)

                # Store results
                latent_means.append(mu.cpu().numpy())
                latent_logvars.append(log_var.cpu().numpy())
                kl_per_dim.append(kl_dims.cpu().numpy())
                labels.extend(batch_labels)
                paths.extend(batch_paths)

                # Memory cleanup
                del volumes, mu, log_var, kl_dims
                torch.cuda.empty_cache()

                if len(labels) >= max_samples:
                    break

            except Exception as e:
                print(f"Error processing batch: {str(e)}")
                continue

    # Stack arrays
    latent_means = np.vstack(latent_means)
    latent_logvars = np.vstack(latent_logvars)
    kl_per_dim = np.vstack(kl_per_dim)

    # Limit to max_samples if needed
    if max_samples and len(labels) > max_samples:
        latent_means = latent_means[:max_samples]
        latent_logvars = latent_logvars[:max_samples]
        kl_per_dim = kl_per_dim[:max_samples]
        labels = labels[:max_samples]
        paths = paths[:max_samples]

    # Get unique patient groups
    unique_groups = sorted(list(set(labels)))

    # Print overview
    print(f"Analyzing {len(labels)} samples across {len(unique_groups)} patient groups: {unique_groups}")
    group_counts = {group: labels.count(group) for group in unique_groups}
    print("Samples per group:", group_counts)

    # Calculate overall KL divergence per dimension
    mean_kl_per_dim = np.mean(kl_per_dim, axis=0)

    # Calculate separation metrics for each dimension
    # We'll use ANOVA F-statistic to measure how well each dimension separates groups
    f_stats = np.zeros(latent_means.shape[1])
    p_values = np.ones(latent_means.shape[1])
    mi_scores = np.zeros(latent_means.shape[1])  # Mutual information scores

    # Create a numeric encoding of labels for mutual information
    label_map = {label: i for i, label in enumerate(unique_groups)}
    numeric_labels = np.array([label_map[label] for label in labels])

    # Calculate separation metrics for each dimension
    for dim in range(latent_means.shape[1]):
        # Get dimension values for each group
        groups_data = [latent_means[np.array(labels) == group, dim] for group in unique_groups]

        # Calculate ANOVA F-statistic and p-value
        if all(len(g) > 1 for g in groups_data):
            f_val, p_val = f_oneway(*groups_data)
            f_stats[dim] = f_val
            p_values[dim] = p_val

        # Calculate mutual information
        try:
            # Discretize dimension values for MI calculation
            dim_values = latent_means[:, dim]
            bins = min(20, len(dim_values) // 10)  # Use fewer bins for smaller datasets
            discretized = np.digitize(dim_values, np.linspace(min(dim_values), max(dim_values), bins))
            mi_scores[dim] = mutual_info_score(discretized, numeric_labels)
        except Exception as e:
            print(f"Error calculating MI for dimension {dim}: {e}")
            mi_scores[dim] = 0

    # Find top dimensions by different metrics
    # 1. Top active dimensions (highest KL)
    top_kl_dims = np.argsort(mean_kl_per_dim)[::-1][:20]

    # 2. Top separating dimensions (highest F-statistic with p < 0.05)
    significant_dims = np.where(p_values < 0.05)[0]
    top_f_dims = significant_dims[np.argsort(f_stats[significant_dims])[::-1][:20]] if len(significant_dims) > 0 else np.argsort(f_stats)[::-1][:20]

    # 3. Top dimensions by mutual information
    top_mi_dims = np.argsort(mi_scores)[::-1][:20]

    # Create a composite score that combines these metrics
    # Normalize each metric to [0, 1] range and then average
    if np.max(mean_kl_per_dim) > np.min(mean_kl_per_dim):
        norm_kl = (mean_kl_per_dim - np.min(mean_kl_per_dim)) / (np.max(mean_kl_per_dim) - np.min(mean_kl_per_dim) + 1e-10)
    else:
        norm_kl = np.zeros_like(mean_kl_per_dim)

    if np.max(f_stats) > np.min(f_stats):
        norm_f = (f_stats - np.min(f_stats)) / (np.max(f_stats) - np.min(f_stats) + 1e-10)
    else:
        norm_f = np.zeros_like(f_stats)

    if np.max(mi_scores) > np.min(mi_scores):
        norm_mi = (mi_scores - np.min(mi_scores)) / (np.max(mi_scores) - np.min(mi_scores) + 1e-10)
    else:
        norm_mi = np.zeros_like(mi_scores)

    # Weight the score components based on significance (F-stat p-value)
    significance_weight = np.where(p_values < 0.05, 1.0, 0.1)
    composite_scores = (norm_kl + norm_f * significance_weight + norm_mi) / 3

    # Top dimensions by composite score
    top_composite_dims = np.argsort(composite_scores)[::-1][:20]

    # Print top dimensions by each metric
    print("\nTop 10 dimensions by average KL divergence (most active):")
    for i, dim in enumerate(top_kl_dims[:10]):
        print(f"  Dimension {dim}: KL={mean_kl_per_dim[dim]:.4f}")

    print("\nTop 10 dimensions by F-statistic (best group separation):")
    for i, dim in enumerate(top_f_dims[:10]):
        print(f"  Dimension {dim}: F={f_stats[dim]:.2f}, p={p_values[dim]:.6f}")

    print("\nTop 10 dimensions by mutual information:")
    for i, dim in enumerate(top_mi_dims[:10]):
        print(f"  Dimension {dim}: MI={mi_scores[dim]:.4f}")

    print("\nTop 10 dimensions by composite score:")
    for i, dim in enumerate(top_composite_dims[:10]):
        print(f"  Dimension {dim}: Score={composite_scores[dim]:.4f}, KL={mean_kl_per_dim[dim]:.4f}, F={f_stats[dim]:.2f}, p={p_values[dim]:.6f}")

    # Visualize top dimensions by different metrics
    print("\nVisualizing top dimensions by group separation...")

    # Create a custom palette for consistent colors
    palette = {'PD': 'red', 'Control': 'blue', 'SWEDD': 'green'}

    # Visualize top dimensions by F-statistic
    top_dims_to_plot = top_f_dims[:5]
    visualize_dimensions_by_group(latent_means, labels, top_dims_to_plot,
                                 group_counts, f_stats, p_values, palette,
                                 "Top Dimensions by F-statistic")

    # Visualize top dimensions by KL divergence
    visualize_dimensions_by_group(latent_means, labels, top_kl_dims[:5],
                                 group_counts, f_stats, p_values, palette,
                                 "Top Dimensions by KL Divergence")

    # Visualize top dimensions by composite score
    visualize_dimensions_by_group(latent_means, labels, top_composite_dims[:5],
                                 group_counts, f_stats, p_values, palette,
                                 "Top Dimensions by Composite Score")

    # Create a dimension score dataframe for further reference
    dimension_scores = pd.DataFrame({
        'dimension': np.arange(latent_means.shape[1]),
        'kl_divergence': mean_kl_per_dim,
        'f_statistic': f_stats,
        'p_value': p_values,
        'mutual_info': mi_scores,
        'composite_score': composite_scores,
        'significant': p_values < 0.05
    })

    # Sort by composite score
    dimension_scores = dimension_scores.sort_values('composite_score', ascending=False)

    # Create group separation visualization in 2D space using top 2 dimensions
    create_2d_separation_plot(latent_means, labels, top_f_dims[:2], palette,
                             "Group Separation Using Top 2 Dimensions (F-statistic)")

    # Create group separation visualization in 2D space using top 2 composite dimensions
    create_2d_separation_plot(latent_means, labels, top_composite_dims[:2], palette,
                             "Group Separation Using Top 2 Dimensions (Composite Score)")

    return {
        'latent_means': latent_means,
        'latent_logvars': latent_logvars,
        'kl_per_dim': kl_per_dim,
        'labels': labels,
        'paths': paths,
        'top_kl_dims': top_kl_dims,
        'top_f_dims': top_f_dims,
        'top_mi_dims': top_mi_dims,
        'top_composite_dims': top_composite_dims,
        'dimension_scores': dimension_scores,
        'f_stats': f_stats,
        'p_values': p_values,
        'mean_kl_per_dim': mean_kl_per_dim,
        'mi_scores': mi_scores
    }

def visualize_dimensions_by_group(latent_means, labels, dimensions,
                                 group_counts, f_stats, p_values,
                                 palette, title):
    """
    Visualize how specific dimensions distribute across patient groups.

    Parameters:
        latent_means: Numpy array of latent vectors (n_samples, n_dims)
        labels: List of group labels for each sample
        dimensions: List of dimensions to visualize
        group_counts: Dictionary with count of samples per group
        f_stats: F-statistics for each dimension
        p_values: p-values for each dimension
        palette: Color palette for groups
        title: Title for the plot
    """
    unique_groups = sorted(list(set(labels)))
    n_dims = len(dimensions)

    # Set up the figure
    fig, axes = plt.subplots(1, n_dims, figsize=(n_dims*5, 6))
    if n_dims == 1:
        axes = [axes]

    fig.suptitle(f"{title}", fontsize=16)

    # Create visualization for each dimension
    for i, dim in enumerate(dimensions):
        ax = axes[i]

        # Create a dataframe for this dimension
        dim_df = pd.DataFrame({
            'Value': latent_means[:, dim],
            'Group': labels
        })

        # Create violin plot with swarm plot overlay
        sns.violinplot(x='Group', y='Value', data=dim_df, palette=palette, ax=ax)

        # Add swarm plot if there aren't too many samples (to avoid clutter)
        if sum(group_counts.values()) < 100:
            sns.swarmplot(x='Group', y='Value', data=dim_df, color='black', alpha=0.5, ax=ax)

        # Add box plot for clearer visualization of the median and quartiles
        sns.boxplot(x='Group', y='Value', data=dim_df, width=0.2, palette=palette,
                   boxprops={'alpha': 0.5}, ax=ax)

        # Add stats in the title
        ax.set_title(f"Dimension {dim}\nF={f_stats[dim]:.2f}, p={p_values[dim]:.6f}", fontsize=12)
        ax.set_xlabel('')

        if i == 0:
            ax.set_ylabel('Dimension Value', fontsize=12)
        else:
            ax.set_ylabel('')

        # Add group counts to x-axis labels
        x_labels = [f"{group}\n(n={group_counts[group]})" for group in unique_groups]
        ax.set_xticklabels(x_labels)

        # Add grid for better readability
        ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.subplots_adjust(top=0.85)
    plt.show()

def create_2d_separation_plot(latent_means, labels, top_2_dims, palette, title):
    """
    Create a 2D scatter plot showing how the top 2 dimensions separate patient groups.

    Parameters:
        latent_means: Numpy array of latent vectors
        labels: List of group labels
        top_2_dims: List of the top 2 dimensions to plot
        palette: Color palette for groups
        title: Title for the plot
    """
    if len(top_2_dims) < 2:
        print("Need at least 2 dimensions for 2D plot")
        return

    # Create figure
    plt.figure(figsize=(10, 8))

    # Extract the two dimensions
    dim1, dim2 = top_2_dims[0], top_2_dims[1]

    # Create dataframe for plotting
    plot_df = pd.DataFrame({
        'Dimension 1': latent_means[:, dim1],
        'Dimension 2': latent_means[:, dim2],
        'Group': labels
    })

    # Create scatter plot
    sns.scatterplot(x='Dimension 1', y='Dimension 2', hue='Group',
                   data=plot_df, palette=palette, s=100, alpha=0.7)

    # Add group centroids
    for group in set(labels):
        group_data = plot_df[plot_df['Group'] == group]
        centroid_x = group_data['Dimension 1'].mean()
        centroid_y = group_data['Dimension 2'].mean()
        plt.scatter(centroid_x, centroid_y, s=200, color=palette[group],
                   marker='X', edgecolor='black', linewidth=2,
                   label=f"{group} centroid")

    # Add dimension indices to axis labels
    plt.xlabel(f"Dimension {dim1}", fontsize=12)
    plt.ylabel(f"Dimension {dim2}", fontsize=12)

    # Add title with dimension indices
    plt.title(f"{title}\nDimensions {dim1} and {dim2}", fontsize=14)

    # Add grid for better readability
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Calculate and display group separation metrics for these dimensions
    calculate_2d_separation_metrics(latent_means[:, [dim1, dim2]], labels,
                                   f"Dimensions {dim1} and {dim2}")

def calculate_2d_separation_metrics(points_2d, labels, title):
    """
    Calculate metrics that quantify how well the selected dimensions separate groups.

    Parameters:
        points_2d: Numpy array of 2D points
        labels: List of group labels
        title: Title for printed metrics
    """
    unique_groups = sorted(list(set(labels)))

    # Convert labels to numpy array
    labels = np.array(labels)

    # Calculate group centroids
    centroids = {}
    for group in unique_groups:
        group_points = points_2d[labels == group]
        centroids[group] = np.mean(group_points, axis=0)

    # Calculate distances between centroids
    print(f"\n{title} - Centroid distances between groups:")
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            dist = np.linalg.norm(centroids[group1] - centroids[group2])
            print(f"  {group1} vs {group2}: {dist:.4f}")

    # Calculate average distance of each sample to its own group centroid
    within_dists = {}
    for group in unique_groups:
        group_points = points_2d[labels == group]
        dists = np.linalg.norm(group_points - centroids[group], axis=1)
        within_dists[group] = np.mean(dists)

    print(f"\n{title} - Average within-group distances:")
    for group, dist in within_dists.items():
        print(f"  {group}: {dist:.4f}")

    # Calculate silhouette-like metric (ratio of between vs. within)
    between_dists = {}
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            between_dists[f"{group1}-{group2}"] = np.linalg.norm(centroids[group1] - centroids[group2])

    avg_within = np.mean(list(within_dists.values()))
    avg_between = np.mean(list(between_dists.values()))
    separation_ratio = avg_between / avg_within

    print(f"\n{title} - Separation quality:")
    print(f"  Average within-group distance: {avg_within:.4f}")
    print(f"  Average between-group distance: {avg_between:.4f}")
    print(f"  Separation ratio: {separation_ratio:.4f} (higher is better)")

# Load the trained VAE model from previous cells
print("Loading VAE model...")
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the full analysis
print("\nAnalyzing VAE dimensions for patient group separation...")
results = analyze_vae_dimensions_for_group_separation(vae_model, val_loader, max_samples=200)

# Analyze what top dimensions represent in brain space by visualizing them
print("\nVisualizing what top dimensions represent in brain space...")
top_dims_to_visualize = results['top_composite_dims'][:3]

for dim in top_dims_to_visualize:
    print(f"\nAnalyzing dimension {dim} in brain space:")
    visualize_vae_latent_dimension(vae_model, val_loader, dimension_idx=dim, alpha=5.0)

# Cell 26: AE vs VAE Performance Analysis with Top Discriminative Dimensions

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import f_oneway
from tqdm import tqdm
import gc
import matplotlib.patches as mpatches
from matplotlib.lines import Line2D
from mpl_toolkits.axes_grid1 import make_axes_locatable

def compare_ae_vae_performance(ae_model, vae_model, dataloader, max_samples=150):
    """
    Comprehensive comparison of AE and VAE performance focusing on:
    1. Reconstruction quality
    2. Top discriminative dimensions and their group separation ability
    """
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    # Storage for data
    original_samples = []
    reconstructions_ae = []
    reconstructions_vae = []
    latent_ae = []
    latent_vae_mu = []
    labels = []
    paths = []

    print("Extracting reconstructions and latent representations...")

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Processing samples"):
            volumes = batch['volume'].to(device)
            batch_labels = batch['label']
            batch_paths = batch['path']

            # Get AE outputs
            ae_latent = ae_model.encode(volumes)
            ae_recon = ae_model.decode(ae_latent)

            # Get VAE outputs
            vae_mu, vae_logvar = vae_model.encode(volumes)
            vae_recon, _, _ = vae_model(volumes)

            # Store data
            original_samples.append(volumes.cpu().numpy())
            reconstructions_ae.append(ae_recon.cpu().numpy())
            reconstructions_vae.append(vae_recon.cpu().numpy())
            latent_ae.append(ae_latent.cpu().numpy())
            latent_vae_mu.append(vae_mu.cpu().numpy())
            labels.extend(batch_labels)
            paths.extend(batch_paths)

            # Memory cleanup
            del volumes, ae_latent, ae_recon, vae_mu, vae_logvar, vae_recon
            torch.cuda.empty_cache()

            if len(labels) >= max_samples:
                break

    # Concatenate data
    original_samples = np.vstack(original_samples)[:max_samples]
    reconstructions_ae = np.vstack(reconstructions_ae)[:max_samples]
    reconstructions_vae = np.vstack(reconstructions_vae)[:max_samples]
    latent_ae = np.vstack(latent_ae)[:max_samples]
    latent_vae_mu = np.vstack(latent_vae_mu)[:max_samples]
    labels = labels[:max_samples]
    paths = paths[:max_samples]

    # Get unique groups
    unique_groups = sorted(list(set(labels)))
    print(f"Analyzing {len(labels)} samples across {len(unique_groups)} groups: {unique_groups}")

    # Create a color palette for groups
    palette = {'PD': '#E41A1C', 'Control': '#377EB8', 'SWEDD': '#4DAF4A'}
    if len(unique_groups) > len(palette):
        # Generate colors for any additional groups
        additional_colors = plt.cm.tab10(np.linspace(0, 1, len(unique_groups)))
        palette = {group: additional_colors[i] for i, group in enumerate(unique_groups)}

    # 1. Reconstruction quality comparison
    compare_reconstruction_quality(original_samples, reconstructions_ae, reconstructions_vae, labels, unique_groups)

    # 2. Find top discriminative dimensions for each model
    ae_dim_results = find_discriminative_dimensions(latent_ae, labels, unique_groups, "AE")
    vae_dim_results = find_discriminative_dimensions(latent_vae_mu, labels, unique_groups, "VAE")

    # 3. Compare top dimensions
    compare_top_dimensions(ae_dim_results, vae_dim_results)

    # 4. Visualize top dimensions for group separation
    visualize_top_dimensions(latent_ae, latent_vae_mu, labels, unique_groups,
                            ae_dim_results, vae_dim_results, palette)

    return {
        'original_samples': original_samples,
        'reconstructions_ae': reconstructions_ae,
        'reconstructions_vae': reconstructions_vae,
        'latent_ae': latent_ae,
        'latent_vae_mu': latent_vae_mu,
        'labels': labels,
        'paths': paths,
        'ae_dim_results': ae_dim_results,
        'vae_dim_results': vae_dim_results
    }

def compare_reconstruction_quality(originals, recon_ae, recon_vae, labels, unique_groups):
    """Visualize and compare reconstruction quality between AE and VAE."""
    print("\n1. Reconstruction Quality Comparison")

    # Calculate MSE for each sample
    mse_ae = np.mean(np.square(originals - recon_ae).reshape(originals.shape[0], -1), axis=1)
    mse_vae = np.mean(np.square(originals - recon_vae).reshape(originals.shape[0], -1), axis=1)

    # Per-group statistics
    mse_by_group = {}
    for group in unique_groups:
        group_mask = np.array(labels) == group
        group_mse_ae = mse_ae[group_mask]
        group_mse_vae = mse_vae[group_mask]

        mse_by_group[group] = {
            'AE': {
                'mean': np.mean(group_mse_ae),
                'std': np.std(group_mse_ae)
            },
            'VAE': {
                'mean': np.mean(group_mse_vae),
                'std': np.std(group_mse_vae)
            }
        }

    # Print statistics
    print("\nReconstruction Error by Group (MSE):")
    for group in unique_groups:
        ae_stats = mse_by_group[group]['AE']
        vae_stats = mse_by_group[group]['VAE']
        winner = "AE" if ae_stats['mean'] < vae_stats['mean'] else "VAE"

        print(f"  {group}:")
        print(f"    AE:  {ae_stats['mean']:.6f} ± {ae_stats['std']:.6f}")
        print(f"    VAE: {vae_stats['mean']:.6f} ± {vae_stats['std']:.6f}")
        print(f"    Best: {winner} by {abs(ae_stats['mean'] - vae_stats['mean']):.6f}")

    # Create comparison visualization
    plt.figure(figsize=(15, 6))

    # 1. Direct comparison scatter plot
    plt.subplot(1, 2, 1)
    plt.scatter(mse_ae, mse_vae, c=np.where(mse_ae < mse_vae, 'blue', 'red'),
               alpha=0.7, s=80, edgecolor='k', linewidth=0.5)

    # Add diagonal line
    max_err = max(np.max(mse_ae), np.max(mse_vae))
    plt.plot([0, max_err], [0, max_err], 'k--', alpha=0.5)

    # Add annotations
    plt.text(max_err*0.1, max_err*0.8, "VAE Better", color='red', fontsize=12, ha='center')
    plt.text(max_err*0.8, max_err*0.1, "AE Better", color='blue', fontsize=12, ha='center')

    # Better = Lower reconstruction error
    ae_win_count = np.sum(mse_ae < mse_vae)
    vae_win_count = np.sum(mse_vae < mse_ae)
    plt.title(f"AE vs VAE Reconstruction Error\nAE better: {ae_win_count}, VAE better: {vae_win_count}", fontsize=14)
    plt.xlabel("AE Error (MSE)", fontsize=12)
    plt.ylabel("VAE Error (MSE)", fontsize=12)
    plt.grid(alpha=0.3)

    # 2. Group-wise VAE improvement percentage
    plt.subplot(1, 2, 2)

    # Calculate relative improvement (positive = VAE better, negative = AE better)
    improvement = ((mse_ae - mse_vae) / mse_ae) * 100

    # Create dataframe for plotting
    imp_df = pd.DataFrame({
        'Improvement (%)': improvement,
        'Group': labels
    })

    # Create violin plot with box plot overlay
    sns.violinplot(x='Group', y='Improvement (%)', data=imp_df)
    sns.boxplot(x='Group', y='Improvement (%)', data=imp_df, width=0.1,
              boxprops={'facecolor': 'white'})

    # Add zero line
    plt.axhline(y=0, color='r', linestyle='--')

    # Customize plot
    plt.title("VAE Improvement over AE (%)", fontsize=14)
    plt.ylabel("Improvement (%)\nPositive = VAE better, Negative = AE better", fontsize=12)
    plt.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Visual comparison of actual reconstructions
    visualize_sample_reconstructions(originals, recon_ae, recon_vae, labels, unique_groups)

def visualize_sample_reconstructions(originals, recon_ae, recon_vae, labels, unique_groups):
    """Compare the visual quality of reconstructions for sample images from each group."""
    # Get one sample per group
    sample_indices = []
    for group in unique_groups:
        group_indices = [i for i, label in enumerate(labels) if label == group]
        if group_indices:
            # Pick middle sample to avoid potential outliers
            sample_indices.append(group_indices[len(group_indices)//2])

    if not sample_indices:
        return

    # Define anatomically relevant slices
    axial_slice = 32  # Axial view

    # Create figure for reconstructions
    fig = plt.figure(figsize=(12, 4 * len(sample_indices)))
    plt.suptitle("Visual Comparison of Reconstructions", fontsize=16)

    for i, idx in enumerate(sample_indices):
        # Get original and reconstructions
        orig = originals[idx].squeeze()
        ae_recon = recon_ae[idx].squeeze()
        vae_recon = recon_vae[idx].squeeze()
        group = labels[idx]

        # Original
        plt.subplot(len(sample_indices), 3, i*3 + 1)
        plt.imshow(orig[axial_slice], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Original - {group}", fontsize=12)
        plt.axis('off')

        # AE reconstruction
        plt.subplot(len(sample_indices), 3, i*3 + 2)
        plt.imshow(ae_recon[axial_slice], cmap='gray', vmin=0, vmax=3)
        plt.title("AE Reconstruction", fontsize=12)
        plt.axis('off')

        # VAE reconstruction
        plt.subplot(len(sample_indices), 3, i*3 + 3)
        plt.imshow(vae_recon[axial_slice], cmap='gray', vmin=0, vmax=3)
        plt.title("VAE Reconstruction", fontsize=12)
        plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

    # Create figure for error maps
    fig = plt.figure(figsize=(12, 4 * len(sample_indices)))
    plt.suptitle("Reconstruction Error Maps", fontsize=16)

    for i, idx in enumerate(sample_indices):
        # Get original and reconstructions
        orig = originals[idx].squeeze()
        ae_recon = recon_ae[idx].squeeze()
        vae_recon = recon_vae[idx].squeeze()
        group = labels[idx]

        # Calculate error maps
        ae_error = np.abs(orig - ae_recon)
        vae_error = np.abs(orig - vae_recon)

        # Set common color scale
        vmax = max(np.max(ae_error), np.max(vae_error))

        # Original
        plt.subplot(len(sample_indices), 3, i*3 + 1)
        plt.imshow(orig[axial_slice], cmap='gray', vmin=0, vmax=3)
        plt.title(f"Original - {group}", fontsize=12)
        plt.axis('off')

        # AE error
        plt.subplot(len(sample_indices), 3, i*3 + 2)
        plt.imshow(ae_error[axial_slice], cmap='hot', vmin=0, vmax=vmax)
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.title("AE Error", fontsize=12)
        plt.axis('off')

        # VAE error
        plt.subplot(len(sample_indices), 3, i*3 + 3)
        plt.imshow(vae_error[axial_slice], cmap='hot', vmin=0, vmax=vmax)
        plt.colorbar(fraction=0.046, pad=0.04)
        plt.title("VAE Error", fontsize=12)
        plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.show()

def find_discriminative_dimensions(latent_vectors, labels, unique_groups, model_name, top_n=10):
    """
    Find the most discriminative dimensions between patient groups.
    Uses F-statistic from one-way ANOVA to measure separation power.
    """
    print(f"\nFinding top discriminative dimensions for {model_name}...")

    # Convert labels to numpy array
    labels_array = np.array(labels)

    # Calculate F-statistic for each dimension
    f_values = []
    p_values = []

    for dim in range(latent_vectors.shape[1]):
        # Extract values for this dimension for each group
        groups_data = [latent_vectors[labels_array == group, dim] for group in unique_groups]

        try:
            # Run one-way ANOVA
            if all(len(g) > 1 for g in groups_data):
                f_stat, p_val = f_oneway(*groups_data)
                f_values.append(f_stat)
                p_values.append(p_val)
            else:
                f_values.append(0)
                p_values.append(1.0)
        except Exception as e:
            print(f"Error for dimension {dim}: {e}")
            f_values.append(0)
            p_values.append(1.0)

    # Convert to numpy arrays
    f_values = np.array(f_values)
    p_values = np.array(p_values)

    # Find top discriminative dimensions
    significant_dims = np.where(p_values < 0.05)[0]
    print(f"  Found {len(significant_dims)} significant dimensions (p < 0.05)")

    # Sort by F-statistic
    sorted_indices = np.argsort(f_values)[::-1]
    top_indices = sorted_indices[:top_n]

    # Get corresponding F and p values
    top_f_values = f_values[top_indices]
    top_p_values = p_values[top_indices]

    # Report top dimensions
    print("\nTop 5 discriminative dimensions:")
    for i in range(min(5, len(top_indices))):
        dim = top_indices[i]
        print(f"  Dimension {dim}: F = {top_f_values[i]:.2f}, p = {top_p_values[i]:.6f}")

    # Calculate group statistics for top dimensions
    group_stats = {}
    for dim in top_indices[:5]:  # Only store stats for top 5 dims to save memory
        dim_stats = {}
        for group in unique_groups:
            values = latent_vectors[labels_array == group, dim]
            dim_stats[group] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values)
            }
        group_stats[dim] = dim_stats

    return {
        'top_indices': top_indices,
        'top_f_values': top_f_values,
        'top_p_values': top_p_values,
        'all_f_values': f_values,
        'all_p_values': p_values,
        'group_stats': group_stats
    }

def compare_top_dimensions(ae_results, vae_results):
    """Compare statistical separation power of top dimensions for AE and VAE."""
    print("\n2. Top Dimensions Comparison")

    # Create a figure
    plt.figure(figsize=(14, 6))

    # 1. Top F-statistics comparison (left subplot)
    plt.subplot(1, 2, 1)

    # Get top 10 F-statistics for each model
    ae_f = ae_results['top_f_values'][:10]
    vae_f = vae_results['top_f_values'][:10]

    # Create index positions
    x = np.arange(len(ae_f))
    width = 0.35

    # Create bar chart
    plt.bar(x - width/2, ae_f, width, label='AE', color='#A1CAF1')
    plt.bar(x + width/2, vae_f, width, label='VAE', color='#F08080')

    # Add labels and customize plot
    plt.xlabel('Dimension Rank', fontsize=12)
    plt.ylabel('F-statistic', fontsize=12)
    plt.title('Top 10 Discriminative Dimensions by F-statistic', fontsize=14)
    plt.xticks(x, [f'{i+1}' for i in range(len(x))])
    plt.legend()
    plt.grid(axis='y', alpha=0.3)

    # 2. Significant dimensions count (right subplot)
    plt.subplot(1, 2, 2)

    # Count significant dimensions (p < 0.05)
    ae_sig_count = np.sum(ae_results['all_p_values'] < 0.05)
    vae_sig_count = np.sum(vae_results['all_p_values'] < 0.05)

    # Calculate percentages
    ae_perc = ae_sig_count / len(ae_results['all_p_values']) * 100
    vae_perc = vae_sig_count / len(vae_results['all_p_values']) * 100

    # Create bar chart
    models = ['AE', 'VAE']
    counts = [ae_sig_count, vae_sig_count]
    percentages = [ae_perc, vae_perc]

    bars = plt.bar(models, counts, color=['#A1CAF1', '#F08080'])

    # Add count labels
    for i, (bar, count, percentage) in enumerate(zip(bars, counts, percentages)):
        plt.text(bar.get_x() + bar.get_width()/2, count + 1,
               f"{count} ({percentage:.1f}%)", ha='center', fontsize=12)

    # Customize plot
    plt.xlabel('Model', fontsize=12)
    plt.ylabel('Number of Significant Dimensions (p < 0.05)', fontsize=12)
    plt.title('Dimensions with Significant Group Separation', fontsize=14)
    plt.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()

    # 3. Distribution of F-statistics (supplementary plot)
    plt.figure(figsize=(10, 5))

    # Get all F-values
    ae_all_f = ae_results['all_f_values']
    vae_all_f = vae_results['all_f_values']

    # Create histogram
    bins = np.linspace(0, max(max(ae_all_f), max(vae_all_f)), 30)
    plt.hist(ae_all_f, bins=bins, alpha=0.5, label='AE', color='#A1CAF1')
    plt.hist(vae_all_f, bins=bins, alpha=0.5, label='VAE', color='#F08080')

    # Customize plot
    plt.xlabel('F-statistic', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.title('Distribution of F-statistics (higher = better group separation)', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

def visualize_top_dimensions(latent_ae, latent_vae, labels, unique_groups,
                            ae_results, vae_results, palette):
    """
    Visualize how top dimensions separate patient groups in AE and VAE.
    Shows 2D plots of the 2 most discriminative dimensions with group centroids.
    """
    print("\n3. Top Dimensions Group Separation Visualization")

    # Convert labels to numpy array
    labels_array = np.array(labels)

    # A. First, visualize AE top 2 dimensions
    ae_top_dims = ae_results['top_indices'][:2]
    ae_top_f = ae_results['top_f_values'][:2]
    ae_top_p = ae_results['top_p_values'][:2]

    # B. Then, visualize VAE top 2 dimensions
    vae_top_dims = vae_results['top_indices'][:2]
    vae_top_f = vae_results['top_f_values'][:2]
    vae_top_p = vae_results['top_p_values'][:2]

    # Create a figure with AE and VAE side by side
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))

    # 1. AE Top 2 Dimensions Scatter Plot
    visualize_2d_separation(latent_ae, labels_array, unique_groups, ae_top_dims,
                           ae_top_f, ae_top_p, palette, ax1, "AE")

    # 2. VAE Top 2 Dimensions Scatter Plot
    visualize_2d_separation(latent_vae, labels_array, unique_groups, vae_top_dims,
                           vae_top_f, vae_top_p, palette, ax2, "VAE")

    plt.tight_layout()
    plt.show()

    # Additional visualization: Show distribution of each dimension by group
    visualize_top_dim_distributions(latent_ae, latent_vae, labels_array, unique_groups,
                                   ae_top_dims, vae_top_dims, palette)

def visualize_2d_separation(latent_vectors, labels, unique_groups, top_dims,
                           f_values, p_values, palette, ax, model_name):
    """
    Create a 2D scatter plot showing how the top 2 dimensions separate groups.
    Also shows centroids and calculates separation metrics.
    """
    # Extract the top 2 dimensions
    dim1, dim2 = top_dims

    # Create a dataframe for the plot
    plot_df = pd.DataFrame({
        'x': latent_vectors[:, dim1],
        'y': latent_vectors[:, dim2],
        'group': labels
    })

    # Calculate centroids for each group
    centroids = {}
    for group in unique_groups:
        group_data = plot_df[plot_df['group'] == group]
        centroids[group] = {
            'x': group_data['x'].mean(),
            'y': group_data['y'].mean()
        }

    # Plot each group's points
    for group in unique_groups:
        group_data = plot_df[plot_df['group'] == group]
        ax.scatter(group_data['x'], group_data['y'], label=group,
                  color=palette[group], s=80, alpha=0.7, edgecolor='w')

    # Plot centroids
    for group, coords in centroids.items():
        ax.scatter(coords['x'], coords['y'], s=200, color=palette[group],
                 marker='X', edgecolor='black', linewidth=2)

    # Calculate and plot the connecting lines between centroids
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            ax.plot([centroids[group1]['x'], centroids[group2]['x']],
                   [centroids[group1]['y'], centroids[group2]['y']],
                   'k--', alpha=0.5, linewidth=1)

            # Calculate and show distance
            dist = np.sqrt((centroids[group1]['x'] - centroids[group2]['x'])**2 +
                          (centroids[group1]['y'] - centroids[group2]['y'])**2)

            # Position the distance label at the midpoint of the line
            mid_x = (centroids[group1]['x'] + centroids[group2]['x']) / 2
            mid_y = (centroids[group1]['y'] + centroids[group2]['y']) / 2

            ax.text(mid_x, mid_y, f"{dist:.2f}",
                  backgroundcolor='white', ha='center', va='center', fontsize=10)

    # Customize plot
    ax.set_title(f"{model_name} Top Dimensions Separation\n(Dim {dim1}: F={f_values[0]:.2f}, p={p_values[0]:.6f},\nDim {dim2}: F={f_values[1]:.2f}, p={p_values[1]:.6f})",
               fontsize=14)
    ax.set_xlabel(f"Dimension {dim1}", fontsize=12)
    ax.set_ylabel(f"Dimension {dim2}", fontsize=12)
    ax.grid(alpha=0.3)

    # Create custom legend with both groups and centroids
    legend_elements = []

    # Group markers
    for group in unique_groups:
        legend_elements.append(
            mpatches.Patch(color=palette[group], label=group))

    # Centroid marker
    legend_elements.append(
        Line2D([0], [0], marker='X', color='w', markerfacecolor='gray',
              markersize=10, label='Centroids'))

    ax.legend(handles=legend_elements, loc='best')

    # Calculate separation quality metrics
    within_group_distances = []
    for group in unique_groups:
        group_mask = labels == group
        points = np.column_stack((latent_vectors[group_mask, dim1],
                                 latent_vectors[group_mask, dim2]))
        centroid = np.array([centroids[group]['x'], centroids[group]['y']])

        # Calculate distances from each point to its centroid
        distances = np.sqrt(np.sum((points - centroid)**2, axis=1))
        within_group_distances.extend(distances)

    # Calculate between-group distances (centroid to centroid)
    between_group_distances = []
    for i, group1 in enumerate(unique_groups):
        for group2 in unique_groups[i+1:]:
            dist = np.sqrt((centroids[group1]['x'] - centroids[group2]['x'])**2 +
                          (centroids[group1]['y'] - centroids[group2]['y'])**2)
            between_group_distances.append(dist)

    # Calculate average distances
    avg_within = np.mean(within_group_distances)
    avg_between = np.mean(between_group_distances)
    separation_ratio = avg_between / avg_within if avg_within > 0 else 0

    # Display metrics on the plot
    ax.text(0.05, 0.05,
           f"Avg within-group: {avg_within:.2f}\nAvg between-group: {avg_between:.2f}\nSeparation ratio: {separation_ratio:.2f}",
           transform=ax.transAxes,
           bbox=dict(facecolor='white', alpha=0.8))

    return {
        'centroids': centroids,
        'avg_within': avg_within,
        'avg_between': avg_between,
        'separation_ratio': separation_ratio
    }

def visualize_top_dim_distributions(latent_ae, latent_vae, labels, unique_groups,
                                   ae_top_dims, vae_top_dims, palette):
    """
    Visualize the distribution of values for top dimensions across patient groups.
    Shows violin plots for each group in each dimension.
    """
    # Convert to pandas format for easier plotting
    ae_dim1, ae_dim2 = ae_top_dims
    vae_dim1, vae_dim2 = vae_top_dims

    # Create dataframes for top dimensions
    ae_df = pd.DataFrame({
        f'AE Dim {ae_dim1}': latent_ae[:, ae_dim1],
        f'AE Dim {ae_dim2}': latent_ae[:, ae_dim2],
        'Group': labels
    })

    vae_df = pd.DataFrame({
        f'VAE Dim {vae_dim1}': latent_vae[:, vae_dim1],
        f'VAE Dim {vae_dim2}': latent_vae[:, vae_dim2],
        'Group': labels
    })

    # Create figure for top dimension distributions
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. AE Dimension 1
    ax = axes[0, 0]
    sns.violinplot(x='Group', y=f'AE Dim {ae_dim1}', data=ae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'AE Dim {ae_dim1}', data=ae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"AE Dimension {ae_dim1} Distribution", fontsize=14)
    ax.grid(axis='y', alpha=0.3)

    # 2. AE Dimension 2
    ax = axes[0, 1]
    sns.violinplot(x='Group', y=f'AE Dim {ae_dim2}', data=ae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'AE Dim {ae_dim2}', data=ae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"AE Dimension {ae_dim2} Distribution", fontsize=14)
    ax.grid(axis='y', alpha=0.3)

    # 3. VAE Dimension 1
    ax = axes[1, 0]
    sns.violinplot(x='Group', y=f'VAE Dim {vae_dim1}', data=vae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'VAE Dim {vae_dim1}', data=vae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"VAE Dimension {vae_dim1} Distribution", fontsize=14)
    ax.grid(axis='y', alpha=0.3)

    # 4. VAE Dimension 2
    ax = axes[1, 1]
    sns.violinplot(x='Group', y=f'VAE Dim {vae_dim2}', data=vae_df, palette=palette, ax=ax)
    sns.boxplot(x='Group', y=f'VAE Dim {vae_dim2}', data=vae_df, width=0.2, color='white', ax=ax)
    ax.set_title(f"VAE Dimension {vae_dim2} Distribution", fontsize=14)
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.suptitle("Distribution of Top Discriminative Dimensions by Patient Group", fontsize=16)
    plt.subplots_adjust(top=0.93)
    plt.show()

    # Create additional plot showing top 3-5 dimensions as heatmap of means
    visualize_dimension_group_means(latent_ae, latent_vae, labels, unique_groups,
                                   ae_top_dims[:5], vae_top_dims[:5], palette)

def visualize_dimension_group_means(latent_ae, latent_vae, labels, unique_groups,
                                   ae_top_dims, vae_top_dims, palette):
    """
    Create a heatmap visualization showing how the top dimensions
    differ in mean values across patient groups for both models.
    """
    # Calculate group means for top AE dimensions
    ae_means = np.zeros((len(unique_groups), len(ae_top_dims)))
    for i, group in enumerate(unique_groups):
        group_mask = labels == group
        for j, dim in enumerate(ae_top_dims):
            ae_means[i, j] = np.mean(latent_ae[group_mask, dim])

    # Calculate group means for top VAE dimensions
    vae_means = np.zeros((len(unique_groups), len(vae_top_dims)))
    for i, group in enumerate(unique_groups):
        group_mask = labels == group
        for j, dim in enumerate(vae_top_dims):
            vae_means[i, j] = np.mean(latent_vae[group_mask, dim])

    # Create a figure for the heatmaps
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))

    # 1. AE heatmap
    im1 = ax1.imshow(ae_means, cmap='coolwarm', aspect='auto')

    # Add axis labels
    ax1.set_yticks(np.arange(len(unique_groups)))
    ax1.set_yticklabels(unique_groups)
    ax1.set_xticks(np.arange(len(ae_top_dims)))
    ax1.set_xticklabels([f'Dim {dim}' for dim in ae_top_dims])

    # Add colorbar
    divider = make_axes_locatable(ax1)
    cax1 = divider.append_axes("right", size="5%", pad=0.1)
    plt.colorbar(im1, cax=cax1)

    # Add title
    ax1.set_title("AE Top Dimensions - Mean Values by Group", fontsize=14)

    # Add value annotations
    for i in range(len(unique_groups)):
        for j in range(len(ae_top_dims)):
            ax1.text(j, i, f"{ae_means[i, j]:.2f}",
                    ha="center", va="center", color="black" if abs(ae_means[i, j]) < 1 else "white")

    # 2. VAE heatmap
    im2 = ax2.imshow(vae_means, cmap='coolwarm', aspect='auto')

    # Add axis labels
    ax2.set_yticks(np.arange(len(unique_groups)))
    ax2.set_yticklabels(unique_groups)
    ax2.set_xticks(np.arange(len(vae_top_dims)))
    ax2.set_xticklabels([f'Dim {dim}' for dim in vae_top_dims])

    # Add colorbar
    divider = make_axes_locatable(ax2)
    cax2 = divider.append_axes("right", size="5%", pad=0.1)
    plt.colorbar(im2, cax=cax2)

    # Add title
    ax2.set_title("VAE Top Dimensions - Mean Values by Group", fontsize=14)

    # Add value annotations
    for i in range(len(unique_groups)):
        for j in range(len(vae_top_dims)):
            ax2.text(j, i, f"{vae_means[i, j]:.2f}",
                    ha="center", va="center", color="black" if abs(vae_means[i, j]) < 1 else "white")

    plt.tight_layout()
    plt.show()

# Load the trained models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Run the comparison analysis with focus on discriminative dimensions
results = compare_ae_vae_performance(ae_model, vae_model, val_loader, max_samples=150)

"""## Identifiability of the same Patient, is it possible?"""

# Cell 27: Identifying Patients with Multiple Exams
import os
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
from datetime import datetime
import torch
from tqdm import tqdm
import gc

def extract_patient_info(file_path):
    """
    Extract patient ID and exam date from file path.
    Returns a tuple (patient_id, exam_date, group)
    """
    # Normalize path
    file_path = file_path.replace('\\', '/')

    # Extract patient group (PD, Control, SWEDD)
    if 'PPMI_Images_PD' in file_path:
        patient_group = 'PD'
    elif 'PPMI_Images_Cont' in file_path:
        patient_group = 'Control'
    elif 'PPMI_Images_SWEDD' in file_path:
        patient_group = 'SWEDD'
    else:
        patient_group = 'Unknown'

    # Extract patient ID - should be a folder after the group folder
    patient_id_match = re.search(r'PPMI_Images_\w+/(\d+)/', file_path)
    if not patient_id_match:
        patient_id_match = re.search(r'PPMI_(\d+)_', file_path)

    patient_id = patient_id_match.group(1) if patient_id_match else None

    # Extract exam date - typically found in a format like "2011-01-20_16_28_47.0"
    date_match = re.search(r'(\d{4}-\d{2}-\d{2})_\d{2}_\d{2}_\d{2}', file_path)
    if date_match:
        exam_date = date_match.group(1)
    else:
        # Try another common format
        date_match = re.search(r'(\d{8})', file_path)
        if date_match:
            date_str = date_match.group(1)
            # Format YYYYMMDD
            exam_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        else:
            exam_date = None

    return patient_id, exam_date, patient_group

def identify_longitudinal_patients(dataloader, min_exams=3, max_patients=10):
    """
    Identify patients with multiple exams and select a subset for analysis.
    Prioritizes patients with the MOST exams in each group.

    Parameters:
        dataloader: DataLoader containing DATSCAN images
        min_exams: Minimum number of exams required to consider a patient for analysis
        max_patients: Maximum number of patients to include in the analysis

    Returns:
        Dictionary with patient info and DataFrame of longitudinal patients
    """
    print("Identifying patients with multiple exams...")

    # Dictionary to store patient info
    patient_exams = defaultdict(lambda: defaultdict(list))

    # Extract patient info from all file paths in the dataloader
    for batch in tqdm(dataloader, desc="Processing files"):
        paths = batch['path']
        labels = batch['label']

        for path, label in zip(paths, labels):
            patient_id, exam_date, patient_group = extract_patient_info(path)

            if patient_id and exam_date:
                # Store the path along with the exam date
                patient_exams[patient_id][exam_date].append({
                    'path': path,
                    'group': label if label else patient_group
                })

    # Count number of exams per patient
    exam_counts = {patient_id: len(exams) for patient_id, exams in patient_exams.items()}

    # Create a DataFrame for analysis
    patient_info = []
    for patient_id, exam_dates in patient_exams.items():
        # Get the patient group (should be the same for all exams)
        patient_group = next(iter(next(iter(exam_dates.values()))))['group']
        num_exams = len(exam_dates)

        # Get the first and last exam dates
        exam_date_list = list(exam_dates.keys())
        first_exam = min(exam_date_list) if exam_date_list else None
        last_exam = max(exam_date_list) if exam_date_list else None

        # Calculate the time span in days if possible
        time_span = None
        if first_exam and last_exam:
            try:
                first_date = datetime.strptime(first_exam, "%Y-%m-%d")
                last_date = datetime.strptime(last_exam, "%Y-%m-%d")
                time_span = (last_date - first_date).days
            except ValueError:
                pass

        patient_info.append({
            'patient_id': patient_id,
            'group': patient_group,
            'num_exams': num_exams,
            'first_exam': first_exam,
            'last_exam': last_exam,
            'time_span_days': time_span
        })

    patient_df = pd.DataFrame(patient_info)

    # Sort by number of exams in descending order
    patient_df = patient_df.sort_values(by='num_exams', ascending=False)

    print(f"Found {len(patient_df)} unique patients.")
    print(f"Patients with {min_exams}+ exams: {len(patient_df[patient_df['num_exams'] >= min_exams])}")

    # Distribution of exams per patient
    plt.figure(figsize=(10, 6))
    sns.histplot(data=patient_df, x='num_exams', hue='group', discrete=True, multiple='stack')
    plt.title('Distribution of Exams per Patient')
    plt.xlabel('Number of Exams')
    plt.ylabel('Number of Patients')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # Filter for patients with multiple exams (at least min_exams)
    longitudinal_df = patient_df[patient_df['num_exams'] >= min_exams].copy()

    # Show the top patients from each group
    print("\nTop patients with most exams by group:")
    for group in sorted(longitudinal_df['group'].unique()):
        group_patients = longitudinal_df[longitudinal_df['group'] == group].sort_values(by='num_exams', ascending=False)
        print(f"\n{group} group:")
        if len(group_patients) > 0:
            print(group_patients[['patient_id', 'num_exams', 'time_span_days']].head(5).to_string(index=False))
        else:
            print("No patients with sufficient exams.")

    # Time span distribution for longitudinal patients
    plt.figure(figsize=(10, 6))
    sns.histplot(data=longitudinal_df, x='time_span_days', hue='group', bins=20, multiple='stack')
    plt.title('Time Span of Exams for Longitudinal Patients')
    plt.xlabel('Time Span (days)')
    plt.ylabel('Number of Patients')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # GUARANTEED GROUP REPRESENTATION STRATEGY
    # Allocate slots for each group to ensure representation
    selected_patients = []
    all_groups = patient_df['group'].unique()
    slots_per_group = max(1, max_patients // len(all_groups))
    remaining_slots = max_patients - (slots_per_group * len(all_groups))

    print(f"\nAllocating {slots_per_group} slots per group with {remaining_slots} remaining slots")

    # First, try to fill with patients meeting minimum exam criteria
    for group in all_groups:
        group_patients = longitudinal_df[longitudinal_df['group'] == group]

        # If we don't have enough patients with min_exams, fall back to patients with fewer exams
        if len(group_patients) < slots_per_group:
            # Get all patients from this group
            all_group_patients = patient_df[patient_df['group'] == group].sort_values(by='num_exams', ascending=False)

            # Take top patients even if they don't meet min_exams
            fallback_count = slots_per_group - len(group_patients)
            fallback_patients = all_group_patients[~all_group_patients['patient_id'].isin(group_patients['patient_id'])].head(fallback_count)

            # Add to the group patients
            group_patients = pd.concat([group_patients, fallback_patients])

            print(f"Added {len(fallback_patients)} patients from {group} group with fewer than {min_exams} exams")

        # Select top patients from this group
        selected_from_group = group_patients.head(slots_per_group)
        selected_patients.append(selected_from_group)

        print(f"Selected {len(selected_from_group)} patients from {group} group")

    # Combine selected patients and sort by number of exams
    selected_df = pd.concat(selected_patients).sort_values(by=['num_exams', 'time_span_days'], ascending=[False, False])

    # Allocate remaining slots to patients with the most exams
    if remaining_slots > 0:
        # Get eligible patients not already selected
        remaining_patients = longitudinal_df[~longitudinal_df['patient_id'].isin(selected_df['patient_id'])]

        # If we have eligible patients, add them
        if len(remaining_patients) > 0:
            additional = remaining_patients.head(remaining_slots)
            selected_df = pd.concat([selected_df, additional])
            print(f"Added {len(additional)} additional patients with the most exams")

    # Final sort by exam count
    selected_df = selected_df.sort_values(by='num_exams', ascending=False)

    print("\nSelected patients for analysis:")
    print(selected_df[['patient_id', 'group', 'num_exams', 'time_span_days']].reset_index(drop=True))

    # Verify we have representation from all groups
    selected_groups = selected_df['group'].unique()
    if len(selected_groups) == len(all_groups):
        print("\n✅ All patient groups are represented in the selection")
    else:
        missing_groups = set(all_groups) - set(selected_groups)
        print(f"\n⚠️ Missing representation from groups: {missing_groups}")

    return {
        'patient_exams': patient_exams,
        'patient_df': patient_df,
        'longitudinal_df': longitudinal_df,
        'selected_patients': selected_df
    }, selected_df

# Run the function to identify longitudinal patients
# We're now GUARANTEEING representation from all groups
patient_data, selected_patients = identify_longitudinal_patients(val_loader, min_exams=2, max_patients=10)

# Cell 27: Extracting and Analyzing Latent Representations for Longitudinal Patients
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.manifold import TSNE
from tqdm import tqdm
import time
import gc

def extract_patient_latent_representations(patient_exams, selected_patients, ae_model, vae_model, dataloader):
    """
    Extract latent representations for all exams of selected patients.

    Parameters:
        patient_exams: Dictionary with patient exam info
        selected_patients: DataFrame of patients selected for analysis
        ae_model: Trained autoencoder model
        vae_model: Trained VAE model
        dataloader: DataLoader containing all images

    Returns:
        Dictionary with latent representations for each patient and exam
    """
    print("Extracting latent representations for longitudinal patients...")

    # Set models to evaluation mode
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    # Create a set of selected patient IDs for faster lookup
    selected_patient_ids = set(selected_patients['patient_id'])

    # Dictionary to store latent representations
    patient_latent_reps = {
        'ae': defaultdict(lambda: defaultdict(list)),
        'vae': defaultdict(lambda: defaultdict(list))
    }

    # Process all images in the dataloader
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume']
            paths = batch['path']

            # Check if any image in this batch belongs to our selected patients
            batch_has_selected = False
            for path in paths:
                patient_id, _, _ = extract_patient_info(path)
                if patient_id in selected_patient_ids:
                    batch_has_selected = True
                    break

            # Skip batch if it doesn't contain any of our selected patients
            if not batch_has_selected:
                continue

            # Process the batch
            volumes = volumes.to(device)

            # Get latent vectors
            ae_latent = ae_model.encode(volumes)
            vae_mu, _ = vae_model.encode(volumes)

            # Store latent vectors for selected patients
            for i, path in enumerate(paths):
                patient_id, exam_date, _ = extract_patient_info(path)

                if patient_id in selected_patient_ids and exam_date:
                    patient_latent_reps['ae'][patient_id][exam_date].append(ae_latent[i].cpu().numpy())
                    patient_latent_reps['vae'][patient_id][exam_date].append(vae_mu[i].cpu().numpy())

            # Memory cleanup
            del volumes, ae_latent, vae_mu
            torch.cuda.empty_cache()

    # Average latent vectors for each exam (in case there are multiple images per exam)
    for model_type in ['ae', 'vae']:
        for patient_id in patient_latent_reps[model_type]:
            for exam_date in patient_latent_reps[model_type][patient_id]:
                vectors = patient_latent_reps[model_type][patient_id][exam_date]
                if vectors:
                    # Average the vectors
                    avg_vector = np.mean(vectors, axis=0)
                    patient_latent_reps[model_type][patient_id][exam_date] = avg_vector

    # Convert to a more accessible format for analysis
    latent_data = []

    for model_type in ['ae', 'vae']:
        for patient_id in patient_latent_reps[model_type]:
            for exam_date, latent_vector in patient_latent_reps[model_type][patient_id].items():
                # Get patient group from selected_patients
                patient_group = selected_patients[selected_patients['patient_id'] == patient_id]['group'].iloc[0]

                latent_data.append({
                    'patient_id': patient_id,
                    'group': patient_group,
                    'exam_date': exam_date,
                    'model_type': model_type,
                    'latent_vector': latent_vector
                })

    latent_df = pd.DataFrame(latent_data)

    print(f"Extracted latent representations for {len(latent_df)} exams across {len(selected_patient_ids)} patients.")

    return latent_df

def analyze_patient_latent_consistency(latent_df):
    """
    Analyze the consistency of latent representations across exams for the same patient.

    Parameters:
        latent_df: DataFrame with latent representations for each patient and exam

    Returns:
        Dictionary with analysis results
    """
    print("\nAnalyzing consistency of latent representations...")

    # Calculate intra-patient and inter-patient similarity
    results = {
        'ae': {'intra_sim': [], 'inter_sim': [], 'stable_dims': []},
        'vae': {'intra_sim': [], 'inter_sim': [], 'stable_dims': []}
    }

    # Calculate pairwise similarities for each model type
    for model_type in ['ae', 'vae']:
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Initialize arrays for dimension-wise analysis
        latent_dim = len(model_data.iloc[0]['latent_vector'])
        dim_stability = np.zeros(latent_dim)
        dim_inter_variation = np.zeros(latent_dim)

        # Group by patient
        patient_groups = model_data.groupby('patient_id')

        # Calculate intra-patient similarities
        for patient_id, patient_df in patient_groups:
            patient_vectors = np.array(patient_df['latent_vector'].tolist())

            # Calculate pairwise similarities within patient
            if len(patient_vectors) > 1:
                # Cosine similarity between all pairs of exams
                sim_matrix = cosine_similarity(patient_vectors)

                # Average similarity (excluding self-similarity along diagonal)
                intra_sim = (sim_matrix.sum() - len(patient_vectors)) / (len(patient_vectors) * (len(patient_vectors) - 1))
                results[model_type]['intra_sim'].append(intra_sim)

                # Analyze dimension-wise stability
                for dim in range(latent_dim):
                    dim_values = patient_vectors[:, dim]
                    dim_stability[dim] += np.std(dim_values)

        # Normalize dimension stability by number of patients
        dim_stability /= len(patient_groups)

        # Find the most stable dimensions (lowest standard deviation across exams)
        stable_dims = np.argsort(dim_stability)[:20]  # Top 20 most stable dimensions
        results[model_type]['stable_dims'] = stable_dims.tolist()

        # Calculate inter-patient similarities
        patient_avg_vectors = {}

        # Get average vector for each patient
        for patient_id, patient_df in patient_groups:
            patient_vectors = np.array(patient_df['latent_vector'].tolist())
            patient_avg_vectors[patient_id] = np.mean(patient_vectors, axis=0)

        # Calculate pairwise similarities between different patients
        patient_ids = list(patient_avg_vectors.keys())
        for i in range(len(patient_ids)):
            for j in range(i+1, len(patient_ids)):
                vec1 = patient_avg_vectors[patient_ids[i]]
                vec2 = patient_avg_vectors[patient_ids[j]]

                # Cosine similarity between patients
                sim = cosine_similarity([vec1], [vec2])[0, 0]
                results[model_type]['inter_sim'].append(sim)

                # Calculate dimension-wise variation between patients
                for dim in range(latent_dim):
                    dim_inter_variation[dim] += abs(vec1[dim] - vec2[dim])

        # Normalize inter-patient variation by number of pairs
        if len(patient_ids) > 1:
            num_pairs = len(patient_ids) * (len(patient_ids) - 1) / 2
            dim_inter_variation /= num_pairs

        # Find most discriminative dimensions (highest variation between patients)
        discrim_dims = np.argsort(dim_inter_variation)[::-1][:20]  # Top 20 most discriminative dimensions
        results[model_type]['discrim_dims'] = discrim_dims.tolist()

    # Plot intra vs inter patient similarity distributions
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    sns.kdeplot(results['ae']['intra_sim'], label='Intra-patient', shade=True)
    sns.kdeplot(results['ae']['inter_sim'], label='Inter-patient', shade=True)
    plt.title('AE: Intra vs. Inter-Patient Similarity')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Density')
    plt.grid(alpha=0.3)
    plt.legend()

    plt.subplot(1, 2, 2)
    sns.kdeplot(results['vae']['intra_sim'], label='Intra-patient', shade=True)
    sns.kdeplot(results['vae']['inter_sim'], label='Inter-patient', shade=True)
    plt.title('VAE: Intra vs. Inter-Patient Similarity')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Density')
    plt.grid(alpha=0.3)
    plt.legend()

    plt.tight_layout()
    plt.show()

    # Create summary statistics table
    summary_stats = []
    for model_type in ['ae', 'vae']:
        intra_mean = np.mean(results[model_type]['intra_sim'])
        intra_std = np.std(results[model_type]['intra_sim'])
        inter_mean = np.mean(results[model_type]['inter_sim'])
        inter_std = np.std(results[model_type]['inter_sim'])

        # Separation ratio (higher is better)
        separation_ratio = intra_mean / inter_mean if inter_mean > 0 else float('inf')

        summary_stats.append({
            'Model': model_type.upper(),
            'Intra-Patient Similarity': f"{intra_mean:.4f} ± {intra_std:.4f}",
            'Inter-Patient Similarity': f"{inter_mean:.4f} ± {inter_std:.4f}",
            'Separation Ratio': f"{separation_ratio:.4f}"
        })

    summary_df = pd.DataFrame(summary_stats)
    print("\nSummary Statistics:")
    print(summary_df)

    # Print most stable dimensions
    for model_type in ['ae', 'vae']:
        print(f"\n{model_type.upper()} - Top 10 most stable dimensions:")
        for dim in results[model_type]['stable_dims'][:10]:
            print(f"  Dimension {dim}")

        print(f"\n{model_type.upper()} - Top 10 most discriminative dimensions:")
        for dim in results[model_type]['discrim_dims'][:10]:
            print(f"  Dimension {dim}")

    return results

# Load AE and VAE models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Extract latent representations for longitudinal patients
latent_df = extract_patient_latent_representations(
    patient_data['patient_exams'],
    selected_patients,
    ae_model,
    vae_model,
    val_loader
)

# Analyze consistency of latent representations
consistency_results = analyze_patient_latent_consistency(latent_df)

# Cell 28: Visualizing Patient Identity in Latent Space
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import LeaveOneOut
import itertools
from matplotlib.colors import ListedColormap

def visualize_patient_latent_evolution(latent_df, stable_dims):
    """
    Visualize how the latent representations of patients evolve over time,
    focusing on the most stable dimensions identified.

    Parameters:
        latent_df: DataFrame with latent representations
        stable_dims: Dictionary with stable dimensions for AE and VAE
    """
    print("Visualizing patient latent space evolution...")

    # Create a figure for both models
    for model_type in ['ae', 'vae']:
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Get top stable dimensions
        top_dims = stable_dims[model_type]['stable_dims'][:2]
        top_discrim_dims = stable_dims[model_type]['discrim_dims'][:2]

        # Create plots
        fig, axes = plt.subplots(1, 2, figsize=(18, 8))
        plt.suptitle(f'{model_type.upper()}: Patient Evolution in Latent Space', fontsize=16)

        # Plot using stable dimensions
        ax = axes[0]
        visualize_dimensions(model_data, top_dims, ax, f'Most Stable Dimensions ({top_dims[0]}, {top_dims[1]})')

        # Plot using discriminative dimensions
        ax = axes[1]
        visualize_dimensions(model_data, top_discrim_dims, ax, f'Most Discriminative Dimensions ({top_discrim_dims[0]}, {top_discrim_dims[1]})')

        plt.tight_layout()
        plt.subplots_adjust(top=0.9)
        plt.show()

    # Create dimension evolution plots for each patient
    for model_type in ['ae', 'vae']:
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Get top stable & discriminative dimensions
        top_stable = stable_dims[model_type]['stable_dims'][:5]
        top_discrim = stable_dims[model_type]['discrim_dims'][:5]

        # For each patient, visualize how these dimensions evolve over time
        for patient_id, patient_df in model_data.groupby('patient_id'):
            # Skip if there are fewer than 3 exams
            if len(patient_df) < 3:
                continue

            # Sort by exam date
            patient_df = patient_df.sort_values('exam_date')

            # Get patient group
            patient_group = patient_df['group'].iloc[0]

            # Convert exam dates to numerical indices for x-axis
            exam_dates = patient_df['exam_date'].tolist()

            # Plot evolution of top dimensions
            fig, axes = plt.subplots(2, 1, figsize=(12, 10))
            plt.suptitle(f'{model_type.upper()}: Patient {patient_id} ({patient_group}) - Dimension Evolution', fontsize=16)

            # Stable dimensions
            ax = axes[0]
            for i, dim in enumerate(top_stable):
                dim_values = [vec[dim] for vec in patient_df['latent_vector']]
                ax.plot(range(len(exam_dates)), dim_values, 'o-', label=f'Dim {dim}')

            ax.set_title('Most Stable Dimensions')
            ax.set_xlabel('Exam Index')
            ax.set_ylabel('Dimension Value')
            ax.set_xticks(range(len(exam_dates)))
            ax.set_xticklabels(exam_dates, rotation=45)
            ax.grid(alpha=0.3)
            ax.legend()

            # Discriminative dimensions
            ax = axes[1]
            for i, dim in enumerate(top_discrim):
                dim_values = [vec[dim] for vec in patient_df['latent_vector']]
                ax.plot(range(len(exam_dates)), dim_values, 'o-', label=f'Dim {dim}')

            ax.set_title('Most Discriminative Dimensions')
            ax.set_xlabel('Exam Index')
            ax.set_ylabel('Dimension Value')
            ax.set_xticks(range(len(exam_dates)))
            ax.set_xticklabels(exam_dates, rotation=45)
            ax.grid(alpha=0.3)
            ax.legend()

            plt.tight_layout()
            plt.subplots_adjust(top=0.9)
            plt.show()

def visualize_dimensions(data, dimensions, ax, title):
    """Helper function to visualize patient trajectories in two dimensions"""
    # Create a colormap with one color per patient
    patient_ids = data['patient_id'].unique()
    colors = plt.cm.tab20(np.linspace(0, 1, len(patient_ids)))
    patient_colors = {pid: colors[i] for i, pid in enumerate(patient_ids)}

    # Plot each patient's trajectory
    for patient_id, patient_df in data.groupby('patient_id'):
        # Sort by exam date
        patient_df = patient_df.sort_values('exam_date')

        # Get group for marker shape
        group = patient_df['group'].iloc[0]
        marker = 'o' if group == 'PD' else ('s' if group == 'Control' else '^')

        # Extract dimension values
        x_values = [vec[dimensions[0]] for vec in patient_df['latent_vector']]
        y_values = [vec[dimensions[1]] for vec in patient_df['latent_vector']]

        # Plot trajectory with connecting lines
        ax.plot(x_values, y_values, '-', color=patient_colors[patient_id], alpha=0.5)

        # Plot individual points with patient labels
        for i, (x, y, date) in enumerate(zip(x_values, y_values, patient_df['exam_date'])):
            # Larger and darker marker for first and last exam
            if i == 0 or i == len(x_values) - 1:
                ax.scatter(x, y, s=100, color=patient_colors[patient_id], marker=marker,
                          edgecolor='black', linewidth=1, alpha=1.0, zorder=3)
                # Add date label for first and last
                date_label = date.split('-')[0] + ('-' + date.split('-')[1] if '-' in date else '')
                ax.annotate(date_label, (x, y), xytext=(5, 5), textcoords='offset points',
                           fontsize=8, bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.7))
            else:
                ax.scatter(x, y, s=60, color=patient_colors[patient_id], marker=marker,
                          edgecolor='black', linewidth=0.5, alpha=0.7, zorder=2)

    # Add legend for patients
    legend_elements = []
    for patient_id in patient_ids:
        patient_data = data[data['patient_id'] == patient_id]
        group = patient_data['group'].iloc[0]
        marker = 'o' if group == 'PD' else ('s' if group == 'Control' else '^')
        legend_elements.append(plt.Line2D([0], [0], marker=marker, color='w', markerfacecolor=patient_colors[patient_id],
                                         markersize=10, label=f"{patient_id} ({group})"))

    ax.legend(handles=legend_elements, loc='best', fontsize=8)
    ax.set_title(title)
    ax.grid(alpha=0.3)

def evaluate_patient_identification(latent_df, stable_dims):
    """
    Evaluate whether patients can be identified from their latent representations
    using leave-one-exam-out cross-validation.

    Parameters:
        latent_df: DataFrame with latent representations
        stable_dims: Dictionary with stable dimensions for AE and VAE
    """
    print("\nEvaluating patient identification from latent space...")

    # Results for each model
    identification_results = {}

    for model_type in ['ae', 'vae']:
        print(f"\nEvaluating {model_type.upper()}...")
        model_data = latent_df[latent_df['model_type'] == model_type]

        # Get different dimension sets to evaluate
        dim_sets = {
            'all_dims': None,  # Use all dimensions
            'stable_dims': stable_dims[model_type]['stable_dims'][:20],
            'discrim_dims': stable_dims[model_type]['discrim_dims'][:20]
        }

        # Store results for this model
        results = {}

        # Evaluate each dimension set
        for dim_set_name, dims in dim_sets.items():
            print(f"\n  Using {dim_set_name}...")

            # Prepare data for cross-validation
            X_all = []
            y_all = []

            for _, row in model_data.iterrows():
                latent_vector = row['latent_vector']

                # Select only the specified dimensions if applicable
                if dims is not None:
                    latent_vector = latent_vector[dims]

                X_all.append(latent_vector)
                y_all.append(row['patient_id'])

            X_all = np.array(X_all)
            y_all = np.array(y_all)

            # Leave-one-exam-out cross-validation
            loo = LeaveOneOut()
            predictions = []
            actual = []

            for train_index, test_index in tqdm(loo.split(X_all), total=len(X_all), desc="LOO Cross-validation"):
                X_train, X_test = X_all[train_index], X_all[test_index]
                y_train, y_test = y_all[train_index], y_all[test_index]

                # Train a simple KNN classifier
                knn = KNeighborsClassifier(n_neighbors=1)
                knn.fit(X_train, y_train)

                # Predict
                pred = knn.predict(X_test)

                predictions.extend(pred)
                actual.extend(y_test)

            # Calculate accuracy
            accuracy = np.mean(np.array(predictions) == np.array(actual))

            print(f"  Accuracy: {accuracy:.4f}")

            # Store results
            results[dim_set_name] = {
                'accuracy': accuracy
            }

        identification_results[model_type] = results

    return identification_results

# Visualize patient latent space evolution
visualize_patient_latent_evolution(latent_df, consistency_results)

# Evaluate patient identification from latent space
identification_results = evaluate_patient_identification(latent_df, consistency_results)

# Final summary
print("\nFinal Insights:")
print("1. Most stable dimensions (consistent within patients):")
for model_type in ['ae', 'vae']:
    print(f"   - {model_type.upper()}: {', '.join(map(str, consistency_results[model_type]['stable_dims'][:5]))}")

print("\n2. Most discriminative dimensions (varying between patients):")
for model_type in ['ae', 'vae']:
    print(f"   - {model_type.upper()}: {', '.join(map(str, consistency_results[model_type]['discrim_dims'][:5]))}")

print("\n3. Patient identification accuracy:")
for model_type in ['ae', 'vae']:
    for dim_set in identification_results[model_type]:
        accuracy = identification_results[model_type][dim_set]['accuracy']
        print(f"   - {model_type.upper()} using {dim_set}: {accuracy:.4f}")