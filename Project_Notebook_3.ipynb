{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.9.0)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.12)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Tuple, Optional, Dict\n",
    "import time\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pydicom\n",
    "from skimage import transform, filters, morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: GPU Setup and Environment Configuration\n",
    "def setup_environment(seed: int = 42) -> Dict[str, Union[torch.device, bool]]:\n",
    "    \"\"\"\n",
    "    Configure the GPU environment and set random seeds for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        dict: Environment configuration including device and GPU availability\n",
    "    \"\"\"\n",
    "    # Set random seeds\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Configure environment\n",
    "    env_config = {\n",
    "        'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "        'gpu_available': torch.cuda.is_available(),\n",
    "        'amp_enabled': True,  # Enable Automatic Mixed Precision\n",
    "    }\n",
    "    \n",
    "    if env_config['gpu_available']:\n",
    "        # Configure CUDA for optimal performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        \n",
    "        # Print GPU information\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"WARNING: GPU not available. Using CPU.\")\n",
    "    \n",
    "    return env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 Ti\n",
      "Memory Available: 12.88 GB\n",
      "Initial GPU Memory: 0.00 GB allocated, 0.00 GB cached\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Memory Management Utilities\n",
    "class MemoryTracker:\n",
    "    \"\"\"Utility class to track and manage GPU memory usage.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_gpu_memory_usage() -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Get current GPU memory usage.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (allocated memory in GB, cached memory in GB)\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated() / 1e9\n",
    "            cached = torch.cuda.memory_reserved() / 1e9\n",
    "            return allocated, cached\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def clear_gpu_memory():\n",
    "        \"\"\"Clear unused GPU memory and run garbage collection.\"\"\"\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    @staticmethod\n",
    "    def log_memory_usage(prefix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Log current GPU memory usage.\n",
    "        \n",
    "        Args:\n",
    "            prefix (str): Optional prefix for the log message\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            allocated, cached = MemoryTracker.get_gpu_memory_usage()\n",
    "            print(f\"{prefix}GPU Memory: {allocated:.2f} GB allocated, {cached:.2f} GB cached\")\n",
    "\n",
    "# Initialize environment\n",
    "env_config = setup_environment()\n",
    "memory_tracker = MemoryTracker()\n",
    "\n",
    "# Display initial memory usage\n",
    "memory_tracker.log_memory_usage(\"Initial \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: File Collection and Validation\n",
    "class DataCollector:\n",
    "    \"\"\"Handles collecting and validating DICOM files from the PPMI dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_path: Union[str, Path]):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.excluded_files: List[Path] = []\n",
    "        self.valid_files: List[Dict] = []\n",
    "        \n",
    "    def _is_valid_file(self, file_path: Path) -> bool:\n",
    "        \"\"\"\n",
    "        Check if file is valid (not containing 'br_raw').\n",
    "        \n",
    "        Args:\n",
    "            file_path (Path): Path to check\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if file is valid, False otherwise\n",
    "        \"\"\"\n",
    "        return (file_path.suffix.lower() == '.dcm' and \n",
    "                'br_raw' not in str(file_path).lower())\n",
    "    \n",
    "    def _get_group_from_path(self, file_path: Path) -> str:\n",
    "        \"\"\"Extract group (PD, SWEDD, Control) from file path.\"\"\"\n",
    "        path_str = str(file_path)\n",
    "        if 'PPMI_Images_PD' in path_str:\n",
    "            return 'PD'\n",
    "        elif 'PPMI_Images_SWEDD' in path_str:\n",
    "            return 'SWEDD'\n",
    "        elif 'PPMI_Images_Cont' in path_str:\n",
    "            return 'Control'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    \n",
    "    def collect_files(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Recursively collect all valid DICOM files.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing file information\n",
    "        \"\"\"\n",
    "        print(f\"Starting file collection from: {self.base_path}\")\n",
    "        \n",
    "        # First, check if the path exists\n",
    "        if not self.base_path.exists():\n",
    "            raise FileNotFoundError(f\"Path does not exist: {self.base_path}\")\n",
    "        \n",
    "        print(\"Building file list... (updating every 1000 files found)\")\n",
    "        \n",
    "        # Use a more efficient way to collect files with progress updates\n",
    "        all_files = []\n",
    "        files_found = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for root, _, files in os.walk(str(self.base_path)):\n",
    "            dcm_files = [Path(root) / f for f in files if f.endswith('.dcm')]\n",
    "            all_files.extend(dcm_files)\n",
    "            \n",
    "            files_found += len(dcm_files)\n",
    "            if files_found % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"\\rFound {files_found} DICOM files... ({elapsed:.1f} seconds elapsed)\", \n",
    "                      end=\"\", flush=True)\n",
    "        \n",
    "        total_files = len(all_files)\n",
    "        print(f\"\\nCompleted file discovery: {total_files} DICOM files found in {time.time() - start_time:.1f} seconds\")\n",
    "        \n",
    "        if total_files == 0:\n",
    "            raise ValueError(f\"No DICOM files found in {self.base_path}\")\n",
    "            \n",
    "        print(f\"\\nFound {total_files} DICOM files. Processing...\")\n",
    "        \n",
    "        # Process files with progress bar\n",
    "        for file_path in tqdm(all_files, \n",
    "                            desc=\"Processing files\",\n",
    "                            ncols=80,\n",
    "                            unit='files'):\n",
    "            if self._is_valid_file(file_path):\n",
    "                self.valid_files.append({\n",
    "                    'path': str(file_path),\n",
    "                    'group': self._get_group_from_path(file_path),\n",
    "                    'patient_id': file_path.parents[3].name\n",
    "                })\n",
    "            else:\n",
    "                self.excluded_files.append(file_path)\n",
    "            \n",
    "            # Show interim progress every 1000 files\n",
    "            if len(self.valid_files) % 1000 == 0:\n",
    "                print(f\"\\nInterim progress:\")\n",
    "                print(f\"Processed {len(self.valid_files) + len(self.excluded_files)}/{total_files} files\")\n",
    "                print(f\"Valid: {len(self.valid_files)}, Excluded: {len(self.excluded_files)}\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(self.valid_files)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCollection Summary:\")\n",
    "        print(f\"Valid files: {len(self.valid_files)}\")\n",
    "        print(f\"Excluded files: {len(self.excluded_files)}\")\n",
    "        print(\"\\nGroup distribution:\")\n",
    "        print(df['group'].value_counts())\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: DICOM Processing and Preprocessing\n",
    "class DICOMProcessor:\n",
    "    \"\"\"Handles DICOM loading and preprocessing.\"\"\"\n",
    "    \n",
    "    def __init__(self, target_shape: Tuple[int, int, int] = (128, 128, 128)):\n",
    "        self.target_shape = target_shape\n",
    "        self.memory_tracker = MemoryTracker()\n",
    "    \n",
    "    def load_dicom(self, file_path: Union[str, Path], to_gpu: bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Load and preprocess DICOM file.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to DICOM file\n",
    "            to_gpu: Whether to move tensor to GPU immediately after preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Preprocessed image tensor\n",
    "        \"\"\"\n",
    "        # Load DICOM\n",
    "        dcm = pydicom.dcmread(str(file_path))\n",
    "        \n",
    "        # Extract pixel array and convert to float32\n",
    "        img = dcm.pixel_array.astype(np.float32)\n",
    "        \n",
    "        # Apply rescaling\n",
    "        if hasattr(dcm, 'RescaleSlope') and hasattr(dcm, 'RescaleIntercept'):\n",
    "            img = img * float(dcm.RescaleSlope) + float(dcm.RescaleIntercept)\n",
    "        \n",
    "        # Preprocess\n",
    "        img = self._preprocess_volume(img)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        tensor = torch.from_numpy(img).unsqueeze(0)  # Add channel dimension\n",
    "        \n",
    "        # Move to GPU if requested\n",
    "        if to_gpu and torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "            self.memory_tracker.log_memory_usage(\"After GPU transfer: \")\n",
    "        \n",
    "        return tensor\n",
    "    \n",
    "    def _preprocess_volume(self, volume: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply preprocessing steps to volume.\n",
    "        \n",
    "        Args:\n",
    "            volume: Input volume array\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Preprocessed volume\n",
    "        \"\"\"\n",
    "        # Intensity normalization\n",
    "        volume = np.clip(volume, 0, None)  # Remove negative values\n",
    "        if volume.max() > 0:\n",
    "            volume = (volume - volume.min()) / (volume.max() - volume.min())\n",
    "        \n",
    "        # Brain masking using Otsu thresholding\n",
    "        threshold = filters.threshold_otsu(volume)\n",
    "        mask = volume > threshold\n",
    "        mask = morphology.binary_closing(mask)\n",
    "        volume = volume * mask\n",
    "        \n",
    "        # Resize to target shape\n",
    "        if volume.shape != self.target_shape:\n",
    "            # Calculate padding/cropping\n",
    "            pad_width = [(max((t - s) // 2, 0), max((t - s + 1) // 2, 0))\n",
    "                        for t, s in zip(self.target_shape, volume.shape)]\n",
    "            crop_width = [(max((s - t) // 2, 0), max((s - t + 1) // 2, 0))\n",
    "                         for t, s in zip(self.target_shape, volume.shape)]\n",
    "            \n",
    "            # Apply padding if needed\n",
    "            if any(p[0] > 0 or p[1] > 0 for p in pad_width):\n",
    "                volume = np.pad(volume, pad_width, mode='constant')\n",
    "            \n",
    "            # Apply cropping if needed\n",
    "            if any(c[0] > 0 or c[1] > 0 for c in crop_width):\n",
    "                slices = tuple(slice(c[0], s - c[1]) for c, s in zip(crop_width, volume.shape))\n",
    "                volume = volume[slices]\n",
    "        \n",
    "        return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: PyTorch Dataset Implementation\n",
    "class DATSCANDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for DATSCAN images.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame, processor: DICOMProcessor, \n",
    "                 to_gpu: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "        \n",
    "        Args:\n",
    "            data_df: DataFrame containing file paths and labels\n",
    "            processor: DICOM processor instance\n",
    "            to_gpu: Whether to move tensors to GPU immediately\n",
    "        \"\"\"\n",
    "        self.data_df = data_df\n",
    "        self.processor = processor\n",
    "        self.to_gpu = to_gpu\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        \"\"\"Get preprocessed image tensor.\"\"\"\n",
    "        file_path = self.data_df.iloc[idx]['path']\n",
    "        return self.processor.load_dicom(file_path, self.to_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file collection from: Images\n",
      "Building file list... (updating every 1000 files found)\n",
      "Found 7000 DICOM files... (128.7 seconds elapsed)\n",
      "Completed file discovery: 7754 DICOM files found in 211.3 seconds\n",
      "\n",
      "Found 7754 DICOM files. Processing...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m processor \u001b[38;5;241m=\u001b[39m DICOMProcessor()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Collect files\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data_df \u001b[38;5;241m=\u001b[39m \u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create dataset\u001b[39;00m\n\u001b[1;32m     11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DATSCANDataset(data_df, processor, to_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[13], line 74\u001b[0m, in \u001b[0;36mDataCollector.collect_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DICOM files. Processing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Process files with progress bar\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                    \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_valid_file(file_path):\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_files\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(file_path),\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_group_from_path(file_path),\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m: file_path\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     83\u001b[0m         })\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py:233\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    232\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize collector and processor\n",
    "    collector = DataCollector(base_path=\"Images\")\n",
    "    processor = DICOMProcessor()\n",
    "    \n",
    "    # Collect files\n",
    "    data_df = collector.collect_files()\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = DATSCANDataset(data_df, processor, to_gpu=True)\n",
    "    \n",
    "    # Create dataloader with optimized settings\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=2,  # Start with small batch size, adjust based on GPU memory\n",
    "        num_workers=6,  # Optimized for 8-core CPU\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
