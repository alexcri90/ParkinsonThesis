# -*- coding: utf-8 -*-
"""Project_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zkbb1EDlzyb3Th4K0IOr--4MKPeUN-z5

# Setup
"""

# Cell 1: Install dependencies
# Uncomment and run the following command if dependencies are not already installed.
# %pip install scikit-learn scikit-image SimpleITK nibabel nilearn albumentations seaborn pandas numpy matplotlib tqdm pydicom scipy
# %pip install umap-learn

# CUDA verification
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
    print(f"CUDA device capability: {torch.cuda.get_device_capability(0)}")

# Cell 2: Import statements and environment setup
import torch

def configure_gpu():
    """
    Configures GPU settings:
    - Detects CUDA device
    - Enables CUDNN benchmarking for improved performance on NVIDIA 4070Ti
    """
    if torch.cuda.is_available():
        device = torch.device("cuda")
        # Enable CUDNN benchmark for optimized convolution algorithm selection
        torch.backends.cudnn.benchmark = True
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
    else:
        raise EnvironmentError("CUDA-compatible GPU not found. Please check your GPU configuration.")

def print_gpu_memory_stats():
    """
    Prints current GPU memory usage for monitoring.
    """
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024 ** 2)
        reserved = torch.cuda.memory_reserved() / (1024 ** 2)
        print(f"GPU Memory Allocated: {allocated:.2f} MB")
        print(f"GPU Memory Reserved: {reserved:.2f} MB")
    else:
        print("CUDA not available.")

# Configure GPU on startup
configure_gpu()
print_gpu_memory_stats()

import warnings
warnings.filterwarnings('ignore')

# Cell 3: GPU Setup and Memory Management
import os
import logging
import warnings
import pandas as pd

# Configure logging for quality assurance (logs will be written to data_ingestion.log)
logging.basicConfig(level=logging.INFO, filename="data_ingestion.log", filemode="w",
                    format="%(asctime)s - %(levelname)s - %(message)s")

def collect_files(base_dir):
    """
    Recursively collects DICOM files only from the expected folders:
    - PPMI_Images_PD: Label "PD"
    - PPMI_Images_SWEDD: Label "SWEDD"
    - PPMI_Images_Cont: Label "Control"

    Excludes any file containing "br_raw" in its path and logs all skipped folders.

    :param base_dir: Base directory containing the Images folder.
    :return: (included_files, excluded_files)
             included_files: list of tuples (full_path, label)
             excluded_files: list of file paths that were excluded.
    """
    included_files = []
    excluded_files = []

    # Define the expected folders and corresponding labels
    expected_folders = {
        "PPMI_Images_PD": "PD",
        "PPMI_Images_SWEDD": "SWEDD",
        "PPMI_Images_Cont": "Control"
    }

    # Iterate over immediate subdirectories in base_dir
    for folder in os.listdir(base_dir):
        folder_path = os.path.join(base_dir, folder)
        if os.path.isdir(folder_path) and folder in expected_folders:
            logging.info(f"Processing folder: {folder_path}")
            # Recursively traverse the expected folder
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    if file.endswith(".dcm"):
                        full_path = os.path.join(root, file)
                        # Exclude any file with "br_raw" in its full path
                        if "br_raw" in full_path:
                            excluded_files.append(full_path)
                            logging.info(f"Excluding raw file: {full_path}")
                        else:
                            included_files.append((full_path, expected_folders[folder]))
        else:
            logging.info(f"Skipping folder: {folder_path}")

    return included_files, excluded_files

def generate_dataframe(included_files):
    """
    Creates a DataFrame from the list of validated file paths.

    :param included_files: List of tuples (file_path, label)
    :return: DataFrame with columns 'file_path' and 'label'
    """
    df = pd.DataFrame(included_files, columns=["file_path", "label"])
    return df

def save_qa_report(total_files, included_count, excluded_count, output_path="data_ingestion_QA_report.csv"):
    """
    Generates and saves a QA report of the file collection process.

    :param total_files: Total number of DICOM files encountered.
    :param included_count: Count of files included after filtering.
    :param excluded_count: Count of files excluded.
    :param output_path: File path for the QA report CSV.
    """
    exclusion_ratio = excluded_count / total_files if total_files > 0 else 0
    qa_report = {
        "total_files": total_files,
        "included_files": included_count,
        "excluded_files": excluded_count,
        "exclusion_ratio": exclusion_ratio,
    }
    qa_df = pd.DataFrame([qa_report])
    qa_df.to_csv(output_path, index=False)
    logging.info("QA report saved to %s", output_path)

    if exclusion_ratio > 0.5:
        warnings.warn(f"High proportion of raw files excluded: {exclusion_ratio:.2%}")

"""## Data Ingestion"""

# !pip install pydicom
# !pip install nibabel

# Cell 4: Data Ingestion Pipeline
import pydicom
import numpy as np

def load_dicom(file_path):
    """
    Loads and processes a DICOM file:
    - Reads the file using pydicom.
    - Converts the pixel array to float32.
    - Applies RescaleSlope and RescaleIntercept if available.

    :param file_path: Path to the DICOM file.
    :return: Tuple (processed_pixel_array, dicom_metadata)
    """
    try:
        ds = pydicom.dcmread(file_path)
    except Exception as e:
        raise IOError(f"Error reading DICOM file {file_path}: {e}")

    # Extract pixel array and convert to float32
    pixel_array = ds.pixel_array.astype(np.float32)

    # Apply rescaling if attributes are present
    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):
        slope = ds.RescaleSlope
        intercept = ds.RescaleIntercept
        pixel_array = pixel_array * slope + intercept

    return pixel_array, ds

# Cell 5: Execute Data Ingestion Pipeline
# Define the base directory containing the "Images" folder (adjust if necessary)
base_dir = "Images"

# Collect files from only the expected subdirectories
included_files, excluded_files = collect_files(base_dir)

# Create a DataFrame for the validated file paths and their labels
df = generate_dataframe(included_files)

# Final validation: Ensure that no "br_raw" files are included
if df["file_path"].str.contains("br_raw").any():
    raise ValueError("Validation failed: 'br_raw' files detected in the final dataset!")

# Save the validated file paths to CSV for reproducibility
df.to_csv("validated_file_paths.csv", index=False)
print("Validated file paths saved to validated_file_paths.csv")

# Generate and save the QA report
total_files = len(included_files) + len(excluded_files)
save_qa_report(total_files, len(included_files), len(excluded_files))
print("QA report generated and saved as data_ingestion_QA_report.csv")

"""## Data Visualization"""

# Cell 6: Visualize One Axial, Coronal, and Sagittal Slice for a Random Patient per Group

import pandas as pd
import random
import matplotlib.pyplot as plt
import numpy as np
import nibabel as nib

# Read the validated file paths CSV generated earlier
df = pd.read_csv("validated_file_paths.csv")

# Function to extract the three orthogonal slices from a 3D volume
def extract_slices(volume):
    """
    Given a 3D volume, returns one axial, one coronal, and one sagittal slice.
    Assumes volume shape is (depth, height, width).
    """
    d, h, w = volume.shape
    axial = volume[32, :, :]         # Axial: slice along depth
    coronal = volume[:, 50, :]        # Coronal: slice along height
    sagittal = volume[:, :, 55]       # Sagittal: slice along width
    return axial, coronal, sagittal

# List of groups and their expected labels
groups = {"PD": "PD", "SWEDD": "SWEDD", "Control": "Control"}
maskH = nib.load('rmask_ICV.nii')
mask = maskH.get_fdata()>0.5
mask = np.transpose(mask,[2, 1, 0])
mask = np.flip(mask,axis=1)
# Create a figure with one row per group and three columns for the views
fig, axes = plt.subplots(nrows=len(groups), ncols=3, figsize=(12, 4 * len(groups)))
fig.suptitle("Axial, Coronal, and Sagittal Slices for a Random Patient per Group", fontsize=16)

for i, (group_key, group_label) in enumerate(groups.items()):
    # Filter DataFrame for the current group
    group_df = df[df["label"] == group_label]
    if group_df.empty:
        print(f"No data found for group {group_label}")
        continue

    # Select a random file from the group
    random_file = group_df.sample(1)["file_path"].values[0]
    print(f"Loading file for group {group_label}: {random_file}")

    # Load the DICOM volume using the previously defined load_dicom() function
    volume, _ = load_dicom(random_file)

    # Verify the volume is 3D (if not, skip or raise an error)
    if volume.ndim != 3:
        raise ValueError(f"Expected 3D volume, got shape {volume.shape} for file: {random_file}")

    axial, coronal, sagittal = extract_slices(volume)

    # Plot Axial slice
    ax = axes[i, 0]
    ax.imshow(axial, cmap="gray")
    ax.set_title(f"{group_label} - Axial")
    ax.axis("off")

    # Plot Coronal slice
    ax = axes[i, 1]
    ax.imshow(coronal, cmap="gray")
    ax.set_title(f"{group_label} - Coronal")
    ax.axis("off")

    # Plot Sagittal slice
    ax = axes[i, 2]
    ax.imshow(sagittal, cmap="gray")
    ax.set_title(f"{group_label} - Sagittal")
    ax.axis("off")

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""## Data Preprocessing

### Intensity Normalization and Volume Preprocessing

### Brain Masking
"""

#!pip install scikit-image

# Cell 7: Data Preprocessing – Brain Masking

import numpy as np
import matplotlib.pyplot as plt
from skimage.filters import threshold_otsu
from skimage.morphology import binary_closing, ball

def resize_volume(volume, target_shape=(64, 128, 128)):
    """
    Resizes the volume to the target shape using zero-padding or center cropping.

    Args:
        volume: Input 3D volume as numpy array with shape (d, h, w)
        target_shape: Desired output shape as tuple (d_new, h_new, w_new)

    Returns:
        Resized volume with shape target_shape
    """
    def get_pad_amounts(current_size, target_size):
        """Helper to calculate padding amounts"""
        if current_size >= target_size:
            return 0, 0
        diff = target_size - current_size
        pad_before = diff // 2
        pad_after = diff - pad_before
        return pad_before, pad_after

    current_shape = volume.shape
    resized = volume.copy()

    # Calculate padding/cropping for each dimension
    pads = [get_pad_amounts(current_shape[i], target_shape[i]) for i in range(3)]

    # Apply padding if needed
    if any(sum(p) > 0 for p in pads):
        resized = np.pad(
            resized,
            pad_width=pads,
            mode="constant",
            constant_values=0
        )

    # Apply cropping if needed
    for i in range(3):
        if current_shape[i] > target_shape[i]:
            # Calculate slicing indices
            start = (current_shape[i] - target_shape[i]) // 2
            end = start + target_shape[i]
            # Apply slice
            if i == 0:
                resized = resized[start:end, :, :]
            elif i == 1:
                resized = resized[:, start:end, :]
            else:
                resized = resized[:, :, start:end]

    return resized

def process_volume(volume, target_shape=(64, 128, 128)):
    """
    Process a 3D volume by:
    1. Normalizing intensity (truncating negatives and min-max scaling)
    2. Resizing to target_shape
    3. Generating a brain mask via Otsu thresholding and morphological closing

    Args:
        volume: Input 3D volume
        target_shape: Desired output shape (depth, height, width)

    Returns:
        norm_vol: Normalized and resized volume
        mask: Brain mask
        masked_vol: Masked volume
    """
    # 1. Intensity normalization
    # volume = np.clip(volume, a_min=0, a_max=None)
    # vmin, vmax = volume.min(), volume.max()
    # if vmax > vmin:
    #     norm_vol = (volume - vmin) / (vmax - vmin)
    # else:
    #     norm_vol = volume - vmin


    # 2. Resize the normalized volume
    norm_vol = resize_volume(volume-volume.min(), target_shape=target_shape)
    mask = np.zeros((64,128,128),dtype=bool)
    mask[20:40,82:103,43:82]=1
    norm_vol /= np.mean(norm_vol[mask])

    # 3. Compute brain mask
    thresh = threshold_otsu(norm_vol)
    mask = norm_vol > thresh
    mask = binary_closing(mask, footprint=ball(2))
    masked_vol = norm_vol * mask

    return norm_vol, mask, masked_vol

# Demonstration: Load one sample DICOM file (using the first file in your validated DataFrame)
sample_file = df.iloc[0]["file_path"]
original_volume, _ = load_dicom(sample_file)
original_volume = original_volume[9:73,:,:]

# Process the volume with our new function
norm_vol, mask, masked_vol = process_volume(original_volume, target_shape=(64,128,128))

print(original_volume.shape)
print(norm_vol.shape)

# Extract an axial (middle) slice from both the normalized volume and the masked volume
axial_norm = norm_vol[norm_vol.shape[0]//2, :, :]
axial_masked = masked_vol[masked_vol.shape[0]//2, :, :]

# Plot side-by-side for comparison
fig, axes = plt.subplots(1, 2, figsize=(12, 6))
axes[0].imshow(axial_norm, cmap="gray")
axes[0].set_title("Normalized Axial Slice")
axes[0].axis("off")

axes[1].imshow(axial_masked, cmap="gray")
axes[1].set_title("Masked Axial Slice")
axes[1].axis("off")

plt.tight_layout()
plt.show()

# Cell 8: Data Preprocessing – Visualization (heatmap)
plt.imshow(norm_vol[32,:,:])
plt.colorbar()

"""## Dataloader Creation (with Shape Validation)"""

# !pip install ipywidgets

# Cell 9: Dataset Implementation with GPU Memory Management
import torch
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import gc
import numpy as np
import os
import psutil
import time
from sklearn.model_selection import train_test_split

def print_memory_stats():
    """Print memory usage statistics"""
    if torch.cuda.is_available():
        print("\nGPU Memory Usage:")
        print(f"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        print(f"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")
    print(f"CPU Memory Usage: {psutil.Process().memory_info().rss / 1024**2:.2f} MB")

class OnDemandDataset(Dataset):
    """
    Memory-efficient dataset that loads volumes on demand rather than all at once
    """
    def __init__(self, dataframe, transform=None):
        self.df = dataframe
        self.transform = transform

        # Load mask once
        try:
            maskH = nib.load('rmask_ICV.nii')
            self.mask = maskH.get_fdata() > 0.5
            self.mask = np.transpose(self.mask, [2, 1, 0])
            self.mask = np.flip(self.mask, axis=1)
            print("✅ Brain mask loaded successfully")
        except Exception as e:
            print(f"⚠️ Warning: Could not load brain mask: {e}")
            print("⚠️ Creating a dummy mask instead")
            self.mask = np.ones((128, 128, 128), dtype=bool)

        # Verify all paths exist
        missing_files = []
        for idx, row in dataframe.iterrows():
            if not os.path.exists(row["file_path"]):
                missing_files.append(row["file_path"])

        if missing_files:
            print(f"⚠️ Warning: {len(missing_files)} files not found!")
            print(f"First few missing files: {missing_files[:3]}")
        else:
            print(f"✅ All {len(dataframe)} file paths are valid")

    def __len__(self):
        """Return the total number of samples in the dataset"""
        return len(self.df)

    def __getitem__(self, idx):
        """Load a single volume on demand"""
        try:
            # Get file path
            file_path = self.df.iloc[idx]["file_path"]

            # Load and process volume
            volume, _ = load_dicom(file_path)

            # Apply mask
            volume -= volume.min()
            volume = volume * self.mask

            # Apply processing
            norm_vol, _, _ = process_volume(volume[9:73, :, :], target_shape=(64, 128, 128))

            # Convert to tensor
            volume_tensor = torch.from_numpy(np.expand_dims(norm_vol, axis=0)).float()

            return {
                "volume": volume_tensor,
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }
        except Exception as e:
            print(f"Error processing file {self.df.iloc[idx]['file_path']}: {e}")
            # Return a zero tensor as fallback
            return {
                "volume": torch.zeros((1, 64, 128, 128), dtype=torch.float32),
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }

class BatchLoadDataset(Dataset):
    """
    Memory-efficient dataset that processes data in small batches
    and caches the processed results
    """
    def __init__(self, dataframe, batch_size=32, transform=None):
        self.df = dataframe
        self.transform = transform
        self.data_cache = {}  # Cache for processed data

        # Load mask once
        try:
            maskH = nib.load('rmask_ICV.nii')
            self.mask = maskH.get_fdata() > 0.5
            self.mask = np.transpose(self.mask, [2, 1, 0])
            self.mask = np.flip(self.mask, axis=1)
            print("✅ Brain mask loaded successfully")
        except Exception as e:
            print(f"⚠️ Warning: Could not load brain mask: {e}")
            print("⚠️ Creating a dummy mask instead")
            self.mask = np.ones((128, 128, 128), dtype=bool)

        # Pre-process data in batches to avoid memory issues
        total_batches = (len(dataframe) + batch_size - 1) // batch_size
        print(f"Pre-processing {len(dataframe)} samples in {total_batches} batches...")

        for batch_idx in tqdm(range(total_batches)):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(dataframe))

            for idx in range(start_idx, end_idx):
                try:
                    file_path = dataframe.iloc[idx]["file_path"]

                    # Load DICOM
                    volume, _ = load_dicom(file_path)
                    volume -= volume.min()
                    volume = volume * self.mask

                    # Process volume
                    norm_vol, _, _ = process_volume(volume[9:73, :, :], target_shape=(64, 128, 128))

                    # Store in cache (using index as key)
                    self.data_cache[idx] = norm_vol

                except Exception as e:
                    print(f"Error processing file {dataframe.iloc[idx]['file_path']}: {e}")
                    self.data_cache[idx] = np.zeros((64, 128, 128), dtype=np.float32)

            # Force garbage collection after each batch
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # Print memory stats every few batches
            if batch_idx % 5 == 0:
                print_memory_stats()

        print("✅ Data pre-processing complete")

    def __len__(self):
        """Return the total number of samples in the dataset"""
        return len(self.df)

    def __getitem__(self, idx):
        """Get a cached pre-processed volume"""
        try:
            # Get the pre-processed volume from cache
            norm_vol = self.data_cache[idx]

            # Convert to tensor
            volume_tensor = torch.from_numpy(np.expand_dims(norm_vol, axis=0)).float()

            return {
                "volume": volume_tensor,
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }
        except Exception as e:
            print(f"Error retrieving item {idx}: {e}")
            # Return a zero tensor as fallback
            return {
                "volume": torch.zeros((1, 64, 128, 128), dtype=torch.float32),
                "label": self.df.iloc[idx]["label"],
                "path": self.df.iloc[idx]["file_path"]
            }

def create_dataloaders(df, batch_size=4, train_split=0.8, on_demand=True):
    """Create train and validation dataloaders with stratified split"""
    # Stratified split to maintain group distributions
    train_df, val_df = train_test_split(
        df,
        test_size=1-train_split,
        stratify=df['label'],
        random_state=42
    )

    print("\nTraining set distribution:")
    print(train_df['label'].value_counts())
    print("\nValidation set distribution:")
    print(val_df['label'].value_counts())

    # Create datasets with appropriate strategy
    if on_demand:
        print("Using on-demand data loading strategy (lighter on memory but slower)")
        train_dataset = OnDemandDataset(train_df)
        val_dataset = OnDemandDataset(val_df)
    else:
        print("Using batch pre-processing strategy (faster but more memory intensive)")
        train_dataset = BatchLoadDataset(train_df)
        val_dataset = BatchLoadDataset(val_df)

    # Create dataloaders with optimized settings
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,  # Reduced from 6 to prevent hanging
        pin_memory=True,
        persistent_workers=False  # Changed from True to avoid memory issues
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,  # Reduced from 6 to prevent hanging
        pin_memory=True,
        persistent_workers=False  # Changed from True to avoid memory issues
    )

    return train_loader, val_loader

# Test the dataloader with a small batch
if __name__ == "__main__":
    print("Testing dataloader with small batch...")
    start_time = time.time()

    # Create dataloaders with a smaller batch size for testing
    train_loader, val_loader = create_dataloaders(df, batch_size=2, on_demand=True)

    # Try to load a single batch
    print("Fetching a single batch...")
    for batch in train_loader:
        print(f"Batch loaded successfully!")
        print(f"Batch shape: {batch['volume'].shape}")
        print(f"Labels: {batch['label']}")
        break

    print(f"Dataloader test completed in {time.time() - start_time:.2f} seconds")
    print_memory_stats()

"""# SBR Study with Latent Representations"""

# Cell 29: Loading and Preprocessing SBR Data
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import re

# Load the SBR data
sbr_file = "DaTScan_SBR_Analysis_17Dec2024.csv"
sbr_df = pd.read_csv(sbr_file)

# Display basic information
print(f"Loaded SBR data with {len(sbr_df)} rows and {len(sbr_df.columns)} columns")
print("\nColumn names:")
print(sbr_df.columns.tolist())

# Check data types and nulls
print("\nData types:")
print(sbr_df.dtypes)
print("\nNull values:")
print(sbr_df.isnull().sum())

# Filter out records not analyzed
sbr_filtered = sbr_df[sbr_df['DATSCAN_ANALYZED'] == 'Yes'].copy()
print(f"\nFiltered to {len(sbr_filtered)} records with DATSCAN_ANALYZED = 'Yes'")

# Convert dates to standardized format
def standardize_date(date_str):
    if pd.isna(date_str) or date_str == "":
        return None

    # Try different formats
    try:
        # Format: MM/YYYY
        if '/' in date_str and len(date_str.split('/')) == 2:
            month, year = date_str.split('/')
            # Convert to YYYY-MM format
            return f"{year}-{month.zfill(2)}"
        # Format: MM/DD/YYYY
        elif '/' in date_str and len(date_str.split('/')) == 3:
            month, day, year = date_str.split('/')
            # Convert to YYYY-MM-DD format
            return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        else:
            return date_str
    except:
        return date_str

# Apply date standardization
sbr_filtered['DATSCAN_DATE_STD'] = sbr_filtered['DATSCAN_DATE'].apply(standardize_date)

# Parse EVENT_ID to extract date information (some are in MM/YYYY format)
def parse_event_id_date(event_id):
    if pd.isna(event_id) or event_id == "":
        return None

    # Check if event_id contains date info (e.g., "U01", "BL", "03/2013")
    if '/' in event_id:
        return standardize_date(event_id)
    else:
        return None

sbr_filtered['EVENT_DATE_STD'] = sbr_filtered['EVENT_ID'].apply(parse_event_id_date)

# Use EVENT_DATE when DATSCAN_DATE is missing
sbr_filtered['SCAN_DATE'] = sbr_filtered['DATSCAN_DATE_STD'].fillna(sbr_filtered['EVENT_DATE_STD'])

# Convert SBR measurements to numeric
sbr_columns = [
    'DATSCAN_CAUDATE_R', 'DATSCAN_CAUDATE_L',
    'DATSCAN_PUTAMEN_R', 'DATSCAN_PUTAMEN_L',
    'DATSCAN_PUTAMEN_R_ANT', 'DATSCAN_PUTAMEN_L_ANT'
]

for col in sbr_columns:
    sbr_filtered[col] = pd.to_numeric(sbr_filtered[col], errors='coerce')

# Add convenient aggregate measures
sbr_filtered['MEAN_CAUDATE'] = sbr_filtered[['DATSCAN_CAUDATE_R', 'DATSCAN_CAUDATE_L']].mean(axis=1)
sbr_filtered['MEAN_PUTAMEN'] = sbr_filtered[['DATSCAN_PUTAMEN_R', 'DATSCAN_PUTAMEN_L']].mean(axis=1)
sbr_filtered['MEAN_PUTAMEN_ANT'] = sbr_filtered[['DATSCAN_PUTAMEN_R_ANT', 'DATSCAN_PUTAMEN_L_ANT']].mean(axis=1)
sbr_filtered['MEAN_TOTAL'] = sbr_filtered[sbr_columns].mean(axis=1)

# Verify SBR statistics by column
print("\nSBR Statistics:")
print(sbr_filtered[sbr_columns + ['MEAN_CAUDATE', 'MEAN_PUTAMEN', 'MEAN_PUTAMEN_ANT', 'MEAN_TOTAL']].describe())

# Visualize SBR distributions
plt.figure(figsize=(15, 6))
sns.boxplot(data=sbr_filtered[sbr_columns])
plt.title('Distribution of SBR Values by Region')
plt.ylabel('SBR Value')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Save the filtered data for use in subsequent cells
sbr_clean = sbr_filtered[['PATNO', 'EVENT_ID', 'SCAN_DATE'] + sbr_columns +
                         ['MEAN_CAUDATE', 'MEAN_PUTAMEN', 'MEAN_PUTAMEN_ANT', 'MEAN_TOTAL']]
print("\nCleaned SBR data:")
print(sbr_clean.head())

# Check for duplicates
duplicates = sbr_clean[sbr_clean.duplicated(subset=['PATNO', 'SCAN_DATE'], keep=False)]
if not duplicates.empty:
    print(f"\nWarning: Found {len(duplicates)} duplicate entries for the same patient and date")
    print(duplicates)

# Cell 30: Matching SBR Data with Latent Representations
import os
import re
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import gc

# Function to extract patient ID and date from file path
def extract_patient_info_from_path(file_path):
    """
    Extract patient ID and exam date from file path.
    Returns a tuple (patient_id, exam_date)
    """
    # Normalize path
    file_path = file_path.replace('\\', '/')

    # Extract patient ID - should be a folder after the group folder
    patient_id_match = re.search(r'PPMI_Images_\w+/(\d+)/', file_path)
    if not patient_id_match:
        patient_id_match = re.search(r'PPMI_(\d+)_', file_path)

    patient_id = patient_id_match.group(1) if patient_id_match else None

    # Extract exam date - typically found in a format like "2011-01-20_16_28_47.0"
    date_match = re.search(r'(\d{4}-\d{2}-\d{2})_\d{2}_\d{2}_\d{2}', file_path)
    if date_match:
        exam_date = date_match.group(1)
    else:
        # Try another common format
        date_match = re.search(r'(\d{8})', file_path)
        if date_match:
            date_str = date_match.group(1)
            # Format YYYYMMDD
            exam_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        else:
            exam_date = None

    return patient_id, exam_date

# Function to match dates between SBR data and image data
def match_dates(image_date, sbr_dates):
    """
    Find the closest matching date in sbr_dates for the given image_date.
    Returns the matching date or None if no match is found.
    """
    if image_date is None or not sbr_dates:
        return None

    # Extract year and month from image date
    try:
        image_year_month = "-".join(image_date.split("-")[:2])
    except:
        return None

    # Look for exact matches first (YYYY-MM or YYYY-MM-DD)
    exact_matches = [d for d in sbr_dates if d and d.startswith(image_year_month)]
    if exact_matches:
        return exact_matches[0]

    # If no exact match, look for same year
    try:
        image_year = image_date.split("-")[0]
        year_matches = [d for d in sbr_dates if d and d.startswith(image_year)]
        if year_matches:
            return year_matches[0]
    except:
        pass

    return None

# Function to extract latent vectors from the models for a batch of images
def extract_latent_vectors(ae_model, vae_model, dataloader, max_samples=None):
    """
    Extract latent vectors from both models for all images in the dataloader.
    Also extracts patient ID and date information for matching with SBR data.
    """
    device = next(ae_model.parameters()).device
    ae_model.eval()
    vae_model.eval()

    # Storage for results
    results = []
    sample_count = 0

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting latent vectors"):
            volumes = batch['volume'].to(device)
            paths = batch['path']
            labels = batch['label']

            # Extract latent vectors
            ae_latent = ae_model.encode(volumes)
            vae_mu, vae_logvar = vae_model.encode(volumes)

            # Process each sample in the batch
            for i in range(len(volumes)):
                path = paths[i]
                label = labels[i]

                # Extract patient information
                patient_id, exam_date = extract_patient_info_from_path(path)

                if patient_id and exam_date:
                    # Store results
                    results.append({
                        'path': path,
                        'patient_id': patient_id,
                        'exam_date': exam_date,
                        'group': label,
                        'ae_latent': ae_latent[i].cpu().numpy(),
                        'vae_mu': vae_mu[i].cpu().numpy(),
                        'vae_logvar': vae_logvar[i].cpu().numpy()
                    })

                    sample_count += 1
                    if max_samples and sample_count >= max_samples:
                        break

            # Memory cleanup
            del volumes, ae_latent, vae_mu, vae_logvar
            torch.cuda.empty_cache()

            if max_samples and sample_count >= max_samples:
                break

    return results

# Load the previously trained models
print("Loading trained models...")
ae_model, _ = load_trained_model('checkpoints', 'autoencoder_v1', latent_dim=256)
vae_model, _ = load_trained_vae('checkpoints', 'vae_model_v2', latent_dim=256)

# Extract latent vectors for all images
print("\nExtracting latent vectors for entire dataset...")
latent_results = extract_latent_vectors(ae_model, vae_model, val_loader, max_samples=None)
print(f"Extracted latent vectors for {len(latent_results)} images")

# Convert to DataFrame for easier processing
latent_df = pd.DataFrame([{
    'path': r['path'],
    'patient_id': r['patient_id'],
    'exam_date': r['exam_date'],
    'group': r['group'],
    'ae_latent': r['ae_latent'],
    'vae_mu': r['vae_mu'],
    'vae_logvar': r['vae_logvar']
} for r in latent_results])

print("\nLatent vector DataFrame:")
print(f"Shape: {latent_df.shape}")
print(latent_df[['patient_id', 'exam_date', 'group']].head())

# Create a lookup dictionary for SBR data by patient ID
sbr_by_patient = {}
for _, row in sbr_clean.iterrows():
    patient_id = str(row['PATNO'])
    if patient_id not in sbr_by_patient:
        sbr_by_patient[patient_id] = []

    sbr_by_patient[patient_id].append({
        'scan_date': row['SCAN_DATE'],
        'caudate_r': row['DATSCAN_CAUDATE_R'],
        'caudate_l': row['DATSCAN_CAUDATE_L'],
        'putamen_r': row['DATSCAN_PUTAMEN_R'],
        'putamen_l': row['DATSCAN_PUTAMEN_L'],
        'putamen_r_ant': row['DATSCAN_PUTAMEN_R_ANT'],
        'putamen_l_ant': row['DATSCAN_PUTAMEN_L_ANT'],
        'mean_caudate': row['MEAN_CAUDATE'],
        'mean_putamen': row['MEAN_PUTAMEN'],
        'mean_putamen_ant': row['MEAN_PUTAMEN_ANT'],
        'mean_total': row['MEAN_TOTAL']
    })

# Match latent vectors with SBR data
matched_data = []

for _, row in tqdm(latent_df.iterrows(), total=len(latent_df), desc="Matching with SBR data"):
    patient_id = row['patient_id']
    exam_date = row['exam_date']

    # Check if patient exists in SBR data
    if patient_id in sbr_by_patient:
        # Get all SBR records for this patient
        sbr_records = sbr_by_patient[patient_id]
        sbr_dates = [record['scan_date'] for record in sbr_records]

        # Find the matching SBR record
        matching_date = match_dates(exam_date, sbr_dates)

        if matching_date:
            # Get the matching SBR record
            matching_record = next((r for r in sbr_records if r['scan_date'] == matching_date), None)

            if matching_record:
                # Combine latent vector with SBR data
                matched_entry = {
                    'path': row['path'],
                    'patient_id': patient_id,
                    'exam_date': exam_date,
                    'sbr_date': matching_date,
                    'group': row['group'],
                    'ae_latent': row['ae_latent'],
                    'vae_mu': row['vae_mu'],
                    'vae_logvar': row['vae_logvar']
                }

                # Add all SBR metrics
                matched_entry.update(matching_record)
                matched_data.append(matched_entry)

# Convert to DataFrame
matched_df = pd.DataFrame(matched_data)
print(f"\nMatched {len(matched_df)} images with SBR data")

# Verify the matched data
if not matched_df.empty:
    print("\nMatched data sample:")
    print(matched_df[['patient_id', 'exam_date', 'sbr_date', 'group', 'mean_total']].head())

    # Check distribution of matched data by group
    print("\nDistribution by group:")
    print(matched_df['group'].value_counts())

    # Visualize SBR values by group
    plt.figure(figsize=(12, 6))
    sns.boxplot(x='group', y='mean_total', data=matched_df)
    plt.title('Mean SBR by Patient Group')
    plt.xlabel('Patient Group')
    plt.ylabel('Mean SBR')
    plt.grid(alpha=0.3)
    plt.show()
else:
    print("Warning: No matches found between image data and SBR data!")

# Save matched data for use in subsequent cells
matched_df.to_pickle('latent_sbr_matched_data.pkl')
print("\nSaved matched data to 'latent_sbr_matched_data.pkl'")

# Cell 31: Analyzing Correlations Between Latent Dimensions and SBR Metrics
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import gc

# Load the matched data
try:
    matched_df = pd.read_pickle('latent_sbr_matched_data.pkl')
    print(f"Loaded matched data with {len(matched_df)} entries")
except:
    print("Error loading matched data! Please run the previous cell first.")
    raise ValueError("Missing matched data file")

# Define SBR metrics to analyze
sbr_metrics = [
    'caudate_r', 'caudate_l',
    'putamen_r', 'putamen_l',
    'putamen_r_ant', 'putamen_l_ant',
    'mean_caudate', 'mean_putamen', 'mean_putamen_ant', 'mean_total'
]

# Function to compute correlations between latent dimensions and SBR metrics
def compute_correlations(latent_type, metric_names):
    """
    Compute correlations between each latent dimension and SBR metrics.

    Parameters:
        latent_type: 'ae_latent' or 'vae_mu'
        metric_names: List of SBR metrics to analyze

    Returns:
        DataFrame with correlation values
    """
    print(f"Computing correlations for {latent_type}...")

    # Get the number of dimensions in the latent space
    first_latent = matched_df.iloc[0][latent_type]
    n_dims = len(first_latent)

    # Initialize correlation matrix
    corr_matrix = np.zeros((n_dims, len(metric_names)))
    p_values = np.zeros((n_dims, len(metric_names)))

    # Extract all latent vectors as a numpy array
    latent_vecs = np.array([row[latent_type] for _, row in matched_df.iterrows()])

    # Compute correlation for each dimension and SBR metric
    for dim in tqdm(range(n_dims), desc=f"Analyzing {n_dims} dimensions"):
        dim_values = latent_vecs[:, dim]

        for j, metric in enumerate(metric_names):
            # Extract SBR metric values
            sbr_values = matched_df[metric].values

            # Remove NaNs
            valid_mask = ~np.isnan(sbr_values)
            dim_valid = dim_values[valid_mask]
            sbr_valid = sbr_values[valid_mask]

            if len(dim_valid) > 5:  # Require at least 5 valid samples
                # Compute Pearson correlation
                corr, p_val = np.corrcoef(dim_valid, sbr_valid)[0, 1], None
                if np.isnan(corr):
                    corr = 0
                corr_matrix[dim, j] = corr

    # Create DataFrame for results
    corr_df = pd.DataFrame(corr_matrix, columns=metric_names)

    return corr_df

# Compute correlations for both AE and VAE
ae_corr_df = compute_correlations('ae_latent', sbr_metrics)
vae_corr_df = compute_correlations('vae_mu', sbr_metrics)

# Function to identify and visualize top correlated dimensions
def visualize_top_correlations(corr_df, latent_type, n_top=10):
    """
    Find and visualize the dimensions with highest absolute correlation.

    Parameters:
        corr_df: DataFrame with correlation values
        latent_type: 'ae_latent' or 'vae_mu'
        n_top: Number of top dimensions to show
    """
    # Calculate the absolute correlation across all SBR metrics
    corr_df['mean_abs_corr'] = corr_df.abs().mean(axis=1)

    # Sort by mean absolute correlation
    top_dims = corr_df.sort_values('mean_abs_corr', ascending=False).index[:n_top]

    print(f"\nTop {n_top} {latent_type} dimensions by correlation with SBR:")
    for i, dim in enumerate(top_dims):
        print(f"  Dimension {dim}: Mean Abs. Corr = {corr_df.loc[dim, 'mean_abs_corr']:.4f}")

    # Visualize correlations for top dimensions
    plt.figure(figsize=(15, 10))

    # Extract correlation values for the top dimensions
    top_corr = corr_df.loc[top_dims, sbr_metrics]

    # Create the heatmap
    sns.heatmap(top_corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0,
                fmt='.2f', linewidths=.5)
    plt.title(f'Top {n_top} {latent_type.split("_")[0].upper()} Dimensions: Correlation with SBR Metrics', fontsize=16)
    plt.xlabel('SBR Metrics', fontsize=12)
    plt.ylabel('Latent Dimensions', fontsize=12)
    plt.tight_layout()
    plt.show()

    return top_dims, corr_df

# Visualize top correlated dimensions for both models
print("\nAnalyzing Autoencoder (AE) dimensions:")
ae_top_dims, ae_corr_with_mean = visualize_top_correlations(ae_corr_df, 'ae_latent')

print("\nAnalyzing Variational Autoencoder (VAE) dimensions:")
vae_top_dims, vae_corr_with_mean = visualize_top_correlations(vae_corr_df, 'vae_mu')

# Find dimensions with strong correlations for specific SBR metrics
def analyze_metric_specific_dimensions(corr_df, latent_type):
    """
    Identify dimensions that are specifically correlated with individual SBR metrics.
    """
    print(f"\nTop dimensions in {latent_type.split('_')[0].upper()} for specific SBR metrics:")

    for metric in sbr_metrics:
        # Sort dimensions by absolute correlation for this metric
        abs_corr = corr_df[metric].abs()
        top_dims = abs_corr.sort_values(ascending=False).index[:3]

        print(f"\n  {metric}:")
        for dim in top_dims:
            corr_val = corr_df.loc[dim, metric]
            print(f"    Dimension {dim}: Corr = {corr_val:.4f}")

# Analyze metric-specific dimensions
analyze_metric_specific_dimensions(ae_corr_df, 'ae_latent')
analyze_metric_specific_dimensions(vae_corr_df, 'vae_mu')

# Distribution of correlation strengths
plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
abs_corrs = ae_corr_df[sbr_metrics].abs().values.flatten()
plt.hist(abs_corrs, bins=30, alpha=0.7)
plt.axvline(x=0.5, color='r', linestyle='--', label='Strong Correlation Threshold')
plt.title('AE: Distribution of Absolute Correlation Strengths')
plt.xlabel('Absolute Correlation')
plt.ylabel('Count')
plt.grid(alpha=0.3)
plt.legend()

plt.subplot(1, 2, 2)
abs_corrs = vae_corr_df[sbr_metrics].abs().values.flatten()
plt.hist(abs_corrs, bins=30, alpha=0.7)
plt.axvline(x=0.5, color='r', linestyle='--', label='Strong Correlation Threshold')
plt.title('VAE: Distribution of Absolute Correlation Strengths')
plt.xlabel('Absolute Correlation')
plt.ylabel('Count')
plt.grid(alpha=0.3)
plt.legend()

plt.tight_layout()
plt.show()

# Compare the distributions between AE and VAE
plt.figure(figsize=(10, 6))
plt.hist(ae_corr_with_mean['mean_abs_corr'], bins=30, alpha=0.5, label='AE')
plt.hist(vae_corr_with_mean['mean_abs_corr'], bins=30, alpha=0.5, label='VAE')
plt.title('Comparison of Correlation Strengths: AE vs VAE')
plt.xlabel('Mean Absolute Correlation')
plt.ylabel('Count of Dimensions')
plt.grid(alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

# Save results for use in subsequent cells
results = {
    'ae_corr_df': ae_corr_df,
    'vae_corr_df': vae_corr_df,
    'ae_top_dims': ae_top_dims,
    'vae_top_dims': vae_top_dims,
    'sbr_metrics': sbr_metrics
}

import pickle
with open('sbr_correlation_results.pkl', 'wb') as f:
    pickle.dump(results, f)

print("\nSaved correlation results to 'sbr_correlation_results.pkl'")

# Cell 32: Visualizing Top Dimensions and SBR Relationships
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import pickle

# Load the matched data
try:
    matched_df = pd.read_pickle('latent_sbr_matched_data.pkl')
    print(f"Loaded matched data with {len(matched_df)} entries")
except:
    print("Error loading matched data! Please run the previous cells first.")
    raise ValueError("Missing matched data file")

# Load correlation results
try:
    with open('sbr_correlation_results.pkl', 'rb') as f:
        corr_results = pickle.load(f)

    ae_corr_df = corr_results['ae_corr_df']
    vae_corr_df = corr_results['vae_corr_df']
    ae_top_dims = corr_results['ae_top_dims']
    vae_top_dims = corr_results['vae_top_dims']
    sbr_metrics = corr_results['sbr_metrics']

    print("Loaded correlation results successfully")
except:
    print("Error loading correlation results! Please run the previous cell first.")
    raise ValueError("Missing correlation results file")

# Extract all latent vectors as numpy arrays
ae_latent_vecs = np.array([row['ae_latent'] for _, row in matched_df.iterrows()])
vae_latent_vecs = np.array([row['vae_mu'] for _, row in matched_df.iterrows()])

# Function to create scatter plots for top dimensions vs SBR metrics
def visualize_dimension_vs_sbr(latent_vecs, top_dims, sbr_metric, model_type):
    """
    Create scatter plots showing the relationship between top latent dimensions and a specific SBR metric.

    Parameters:
        latent_vecs: numpy array of latent vectors
        top_dims: list of top dimension indices
        sbr_metric: SBR metric to analyze
        model_type: 'AE' or 'VAE'
    """
    # Get SBR values
    sbr_values = matched_df[sbr_metric].values

    # Create figure for scatter plots
    num_plots = min(6, len(top_dims))
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.flatten()

    # Create scatter plots for top dimensions
    for i in range(num_plots):
        dim = top_dims[i]
        ax = axes[i]

        # Extract dimension values and remove NaNs
        dim_values = latent_vecs[:, dim]
        valid_mask = ~np.isnan(sbr_values)

        # Create scatter plot
        scatter = ax.scatter(dim_values[valid_mask], sbr_values[valid_mask],
                             alpha=0.7, c=matched_df.loc[valid_mask, 'mean_total'],
                             cmap='viridis', s=50)

        # Calculate correlation
        valid_dim = dim_values[valid_mask]
        valid_sbr = sbr_values[valid_mask]
        corr = np.corrcoef(valid_dim, valid_sbr)[0, 1]

        # Add title and labels
        ax.set_title(f'Dimension {dim}: Correlation = {corr:.4f}', fontsize=12)
        ax.set_xlabel(f'Dimension {dim} Value', fontsize=10)
        ax.set_ylabel(sbr_metric, fontsize=10)
        ax.grid(alpha=0.3)

        # Add best fit line
        if len(valid_dim) > 1:
            m, b = np.polyfit(valid_dim, valid_sbr, 1)
            ax.plot(valid_dim, m*valid_dim + b, 'r--', alpha=0.7)

    # Add colorbar
    cbar_ax = fig.add_axes([0.95, 0.15, 0.02, 0.7])
    cbar = fig.colorbar(scatter, cax=cbar_ax)
    cbar.set_label('Mean Total SBR', fontsize=12)

    # Set overall title
    plt.suptitle(f'{model_type} Top Dimensions vs {sbr_metric}', fontsize=16)
    plt.tight_layout(rect=[0, 0, 0.95, 0.95])
    plt.subplots_adjust(top=0.9)
    plt.show()

# Visualize top dimensions for key SBR metrics
for metric in ['mean_total', 'mean_caudate', 'mean_putamen']:
    print(f"\nVisualizing {metric} relationships:")

    print("\nAutoencoder (AE) dimensions:")
    visualize_dimension_vs_sbr(ae_latent_vecs, ae_top_dims, metric, 'AE')

    print("\nVariational Autoencoder (VAE) dimensions:")
    visualize_dimension_vs_sbr(vae_latent_vecs, vae_top_dims, metric, 'VAE')

# Function to visualize SBR values in latent space using dimensionality reduction
def visualize_latent_space_by_sbr(latent_vecs, model_type, sbr_metric='mean_total'):
    """
    Visualize the latent space colored by SBR values using PCA and t-SNE.

    Parameters:
        latent_vecs: numpy array of latent vectors
        model_type: 'AE' or 'VAE'
        sbr_metric: SBR metric to use for coloring
    """
    # Get SBR values and remove NaNs
    sbr_values = matched_df[sbr_metric].values
    valid_mask = ~np.isnan(sbr_values)

    filtered_vecs = latent_vecs[valid_mask]
    filtered_sbr = sbr_values[valid_mask]

    # Create figure for both PCA and t-SNE
    fig, axes = plt.subplots(1, 2, figsize=(18, 8))

    # PCA
    print(f"Performing PCA on {model_type} latent space...")
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(filtered_vecs)

    scatter = axes[0].scatter(pca_result[:, 0], pca_result[:, 1],
                              c=filtered_sbr, cmap='viridis',
                              alpha=0.7, s=70, edgecolors='w', linewidths=0.5)

    axes[0].set_title(f'{model_type} Latent Space (PCA)', fontsize=14)
    axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)
    axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)
    axes[0].grid(alpha=0.3)

    # t-SNE
    print(f"Performing t-SNE on {model_type} latent space...")
    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(filtered_vecs)-1))
    tsne_result = tsne.fit_transform(filtered_vecs)

    scatter = axes[1].scatter(tsne_result[:, 0], tsne_result[:, 1],
                              c=filtered_sbr, cmap='viridis',
                              alpha=0.7, s=70, edgecolors='w', linewidths=0.5)

    axes[1].set_title(f'{model_type} Latent Space (t-SNE)', fontsize=14)
    axes[1].set_xlabel('t-SNE Component 1', fontsize=12)
    axes[1].set_ylabel('t-SNE Component 2', fontsize=12)
    axes[1].grid(alpha=0.3)

    # Add colorbar
    cbar_ax = fig.add_axes([0.95, 0.15, 0.02, 0.7])
    cbar = fig.colorbar(scatter, cax=cbar_ax)
    cbar.set_label(sbr_metric, fontsize=12)

    # Set overall title
    plt.suptitle(f'{model_type} Latent Space Colored by {sbr_metric}', fontsize=16)
    plt.tight_layout(rect=[0, 0, 0.95, 0.95])
    plt.subplots_adjust(top=0.9)
    plt.show()

# Visualize latent spaces colored by SBR values
print("\nVisualizing latent spaces colored by mean total SBR:")
visualize_latent_space_by_sbr(ae_latent_vecs, 'AE')
visualize_latent_space_by_sbr(vae_latent_vecs, 'VAE')

# Group-level analysis: Show mean dimension values by SBR ranges
def analyze_dimensions_by_sbr_ranges(latent_vecs, top_dims, model_type, sbr_metric='mean_total'):
    """
    Analyze how latent dimension values change across different SBR ranges.

    Parameters:
        latent_vecs: numpy array of latent vectors
        top_dims: list of top dimension indices
        model_type: 'AE' or 'VAE'
        sbr_metric: SBR metric to analyze
    """
    # Get SBR values and remove NaNs
    sbr_values = matched_df[sbr_metric].values
    valid_mask = ~np.isnan(sbr_values)

    # Create SBR ranges for grouping
    sbr_min, sbr_max = np.min(sbr_values[valid_mask]), np.max(sbr_values[valid_mask])
    sbr_range = sbr_max - sbr_min

    # Create bins (5 equal bins)
    bins = np.linspace(sbr_min, sbr_max, 6)
    bin_labels = [f"{bins[i]:.2f}-{bins[i+1]:.2f}" for i in range(5)]

    # Assign each sample to a bin
    binned_data = pd.DataFrame({
        'sbr': sbr_values[valid_mask],
        'bin': pd.cut(sbr_values[valid_mask], bins=bins, labels=bin_labels, include_lowest=True)
    })

    # Add latent dimension values for top dimensions
    for i, dim in enumerate(top_dims[:6]):
        binned_data[f'dim_{dim}'] = latent_vecs[valid_mask, dim]

    # Create the plot
    fig, ax = plt.subplots(figsize=(14, 8))

    # Reshape data for boxplot
    plot_data = []
    dim_names = []

    for i, dim in enumerate(top_dims[:6]):
        for bin_label in bin_labels:
            bin_values = binned_data.loc[binned_data['bin'] == bin_label, f'dim_{dim}']
            plot_data.append(bin_values)
            dim_names.append(f"Dim {dim}\n{bin_label}")

    # Create a custom colormap that transitions from red to blue
    bin_colors = plt.cm.coolwarm(np.linspace(0, 1, len(bin_labels)))
    colors = []
    for i in range(len(top_dims[:6])):
        colors.extend(bin_colors)

    # Create boxplot
    boxplot = ax.boxplot(plot_data, patch_artist=True, showfliers=False)

    # Apply colors
    for patch, color in zip(boxplot['boxes'], colors):
        patch.set_facecolor(color)

    # Add labels and title
    ax.set_xticklabels(dim_names, rotation=90)
    ax.set_ylabel('Dimension Value', fontsize=12)
    ax.set_title(f'{model_type} Top Dimensions by {sbr_metric} Ranges', fontsize=16)
    ax.grid(alpha=0.3)

    # Add legend
    import matplotlib.patches as mpatches
    legend_patches = [mpatches.Patch(color=bin_colors[i], label=bin_labels[i])
                     for i in range(len(bin_labels))]
    ax.legend(handles=legend_patches, title='SBR Ranges', loc='best')

    plt.tight_layout()
    plt.show()

# Analyze dimensions by SBR ranges
print("\nAnalyzing dimensions by SBR ranges:")
analyze_dimensions_by_sbr_ranges(ae_latent_vecs, ae_top_dims, 'AE')
analyze_dimensions_by_sbr_ranges(vae_latent_vecs, vae_top_dims, 'VAE')

# Create a more targeted visualization of individual dimensions vs group and SBR
def visualize_top_dims_by_group_and_sbr(latent_vecs, top_dims, model_type):
    """
    Create scatter plots showing how top dimensions relate to both group and SBR.
    """
    # Use just the top 2 dimensions for simplicity
    dim1, dim2 = top_dims[:2]

    # Extract dimension values
    x_values = latent_vecs[:, dim1]
    y_values = latent_vecs[:, dim2]

    # Get groups and SBR values
    groups = matched_df['group'].values
    sbr_values = matched_df['mean_total'].values
    valid_mask = ~np.isnan(sbr_values)

    # Create scatter plot
    plt.figure(figsize=(12, 10))

    # Define colors by group
    group_colors = {'PD': 'red', 'Control': 'blue', 'SWEDD': 'green'}
    default_color = 'gray'

    # Create scatter with group colors and sizes based on SBR
    for group in np.unique(groups):
        group_mask = (groups == group) & valid_mask
        plt.scatter(
            x_values[group_mask],
            y_values[group_mask],
            c=[group_colors.get(group, default_color)],
            s=sbr_values[group_mask] * 20,  # Size proportional to SBR value
            alpha=0.7,
            label=group,
            edgecolors='white',
            linewidths=0.5
        )

    # Add labels and title
    plt.xlabel(f'Dimension {dim1}', fontsize=12)
    plt.ylabel(f'Dimension {dim2}', fontsize=12)
    plt.title(f'{model_type} Top Dimensions by Group and SBR', fontsize=16)
    plt.grid(alpha=0.3)
    plt.legend(title='Patient Group')

    # Add a size reference for SBR values
    from matplotlib.lines import Line2D
    sbr_handles = [
        Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',
               markersize=np.sqrt(sbr * 20), label=f'SBR {sbr:.1f}')
        for sbr in [1.0, 2.0, 3.0]
    ]
    plt.legend(handles=sbr_handles, title='SBR Value', loc='upper right')

    plt.tight_layout()
    plt.show()

# Visualize top dimensions by group and SBR
print("\nVisualizing top dimensions by group and SBR:")
visualize_top_dims_by_group_and_sbr(ae_latent_vecs, ae_top_dims, 'AE')
visualize_top_dims_by_group_and_sbr(vae_latent_vecs, vae_top_dims, 'VAE')

# Cell 33: Building Regression Models to Predict SBR from Latent Space
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, f_regression
import pickle

# Set random seed for reproducibility
np.random.seed(42)

# Load the matched data
try:
    matched_df = pd.read_pickle('latent_sbr_matched_data.pkl')
    print(f"Loaded matched data with {len(matched_df)} entries")
except:
    print("Error loading matched data! Please run the previous cells first.")
    raise ValueError("Missing matched data file")

# Load correlation results
try:
    with open('sbr_correlation_results.pkl', 'rb') as f:
        corr_results = pickle.load(f)

    ae_corr_df = corr_results['ae_corr_df']
    vae_corr_df = corr_results['vae_corr_df']
    ae_top_dims = corr_results['ae_top_dims']
    vae_top_dims = corr_results['vae_top_dims']
    sbr_metrics = corr_results['sbr_metrics']

    print("Loaded correlation results successfully")
except:
    print("Error loading correlation results! Please run the previous cells first.")
    raise ValueError("Missing correlation results file")

# Function to prepare data for regression
def prepare_regression_data(latent_vecs, sbr_metric, top_dims=None, n_dims=50):
    """
    Prepare data for regression analysis.

    Parameters:
        latent_vecs: numpy array of latent vectors
        sbr_metric: SBR metric to predict
        top_dims: optional list of top dimensions to use (if None, use top n_dims by correlation)
        n_dims: number of top dimensions to use if top_dims is None

    Returns:
        X, y for regression, with nulls removed
    """
    # Get SBR values
    y = matched_df[sbr_metric].values

    # Remove nulls
    valid_mask = ~np.isnan(y)
    X_full = latent_vecs[valid_mask]
    y = y[valid_mask]

    # Use only top dimensions if specified
    if top_dims is not None:
        X = X_full[:, top_dims]
    elif n_dims > 0 and n_dims < X_full.shape[1]:
        # Select top n_dims by correlation
        corr_values = np.array([np.corrcoef(X_full[:, i], y)[0, 1] if len(np.unique(X_full[:, i])) > 1 else 0
                               for i in range(X_full.shape[1])])
        abs_corr = np.abs(corr_values)
        top_by_corr = np.argsort(abs_corr)[::-1][:n_dims]
        X = X_full[:, top_by_corr]
    else:
        X = X_full

    return X, y

# Function to evaluate regression models
def evaluate_regression_models(X, y, model_type, sbr_metric):
    """
    Evaluate multiple regression models using cross-validation.

    Parameters:
        X: feature matrix
        y: target values
        model_type: 'AE' or 'VAE'
        sbr_metric: SBR metric being predicted

    Returns:
        DataFrame with model performance
    """
    # Split data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42
    )

    # Define models to evaluate
    models = {
        'Linear Regression': LinearRegression(),
        'Ridge Regression': Ridge(alpha=1.0),
        'Lasso Regression': Lasso(alpha=0.1),
        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),
        'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.1),
        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5)
    }

    # Standardize features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Evaluate each model
    results = []

    for name, model in models.items():
        print(f"Evaluating {name}...")

        # Train model
        model.fit(X_train_scaled, y_train)

        # Make predictions
        y_pred_train = model.predict(X_train_scaled)
        y_pred_test = model.predict(X_test_scaled)

        # Calculate metrics
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)

        # Store results
        results.append({
            'Model': name,
            'Train RMSE': train_rmse,
            'Test RMSE': test_rmse,
            'Train MAE': train_mae,
            'Test MAE': test_mae,
            'Train R²': train_r2,
            'Test R²': test_r2
        })

        # Visualize predictions vs actual for this model
        if test_r2 > 0.5:  # Only visualize models with decent performance
            plt.figure(figsize=(10, 8))

            # Training set
            plt.subplot(2, 2, 1)
            plt.scatter(y_train, y_pred_train, alpha=0.7)
            plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], 'r--')
            plt.title(f'Training Set: {name}')
            plt.xlabel('Actual SBR')
            plt.ylabel('Predicted SBR')

            # Test set
            plt.subplot(2, 2, 2)
            plt.scatter(y_test, y_pred_test, alpha=0.7)
            plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
            plt.title(f'Test Set: {name}')
            plt.xlabel('Actual SBR')
            plt.ylabel('Predicted SBR')

            # Residuals - Training set
            plt.subplot(2, 2, 3)
            residuals_train = y_train - y_pred_train
            plt.scatter(y_pred_train, residuals_train, alpha=0.7)
            plt.axhline(y=0, color='r', linestyle='--')
            plt.title('Training Residuals')
            plt.xlabel('Predicted SBR')
            plt.ylabel('Residual')

            # Residuals - Test set
            plt.subplot(2, 2, 4)
            residuals_test = y_test - y_pred_test
            plt.scatter(y_pred_test, residuals_test, alpha=0.7)
            plt.axhline(y=0, color='r', linestyle='--')
            plt.title('Test Residuals')
            plt.xlabel('Predicted SBR')
            plt.ylabel('Residual')

            plt.suptitle(f"{model_type}: {name} - Predicting {sbr_metric}", fontsize=16)
            plt.tight_layout()
            plt.subplots_adjust(top=0.9)
            plt.show()

    # Create DataFrame with results
    results_df = pd.DataFrame(results)

    # Display results sorted by test R²
    results_sorted = results_df.sort_values('Test R²', ascending=False)
    print(f"\n{model_type} Model Performance for {sbr_metric}:")
    print(results_sorted)

    return results_sorted, X_train_scaled, X_test_scaled, y_train, y_test

# Extract latent vectors
ae_latent_vecs = np.array([row['ae_latent'] for _, row in matched_df.iterrows()])
vae_latent_vecs = np.array([row['vae_mu'] for _, row in matched_df.iterrows()])

# Analyze feature importance for the best performing model
def analyze_feature_importance(model, X_train, feature_indices=None):
    """
    Analyze and visualize feature importance for a trained model.

    Parameters:
        model: trained model with feature_importances_ attribute
        X_train: training data
        feature_indices: original indices of the features used
    """
    if not hasattr(model, 'feature_importances_'):
        print("Model does not provide feature importance information")
        return

    # Get feature importances
    importances = model.feature_importances_

    # Create a DataFrame for importances
    if feature_indices is not None:
        features = [f'Dim {idx}' for idx in feature_indices]
    else:
        features = [f'Feature {i}' for i in range(len(importances))]

    importance_df = pd.DataFrame({
        'Feature': features,
        'Importance': importances
    })

    # Sort by importance
    importance_df = importance_df.sort_values('Importance', ascending=False).head(15)

    # Plot feature importances
    plt.figure(figsize=(12, 8))
    sns.barplot(data=importance_df, x='Importance', y='Feature')
    plt.title('Feature Importance', fontsize=14)
    plt.xlabel('Importance', fontsize=12)
    plt.ylabel('Feature', fontsize=12)
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    plt.show()

    return importance_df

# Function to find optimal number of dimensions
def find_optimal_dimensions(latent_vecs, sbr_metric, model_type, max_dims=100, step=5):
    """
    Find the optimal number of dimensions for predicting a SBR metric.

    Parameters:
        latent_vecs: numpy array of latent vectors
        sbr_metric: SBR metric to predict
        model_type: 'AE' or 'VAE'
        max_dims: maximum number of dimensions to try
        step: step size for testing different numbers of dimensions
    """
    # Get SBR values
    y = matched_df[sbr_metric].values

    # Remove nulls
    valid_mask = ~np.isnan(y)
    X_full = latent_vecs[valid_mask]
    y = y[valid_mask]

    # Calculate correlations with target
    corr_values = np.array([np.corrcoef(X_full[:, i], y)[0, 1] if len(np.unique(X_full[:, i])) > 1 else 0
                           for i in range(X_full.shape[1])])
    abs_corr = np.abs(corr_values)

    # Sort features by absolute correlation
    sorted_indices = np.argsort(abs_corr)[::-1]

    # Test different numbers of dimensions
    dim_counts = list(range(5, max_dims + 1, step))
    cv_scores = []

    # Create the model
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('model', Ridge(alpha=1.0))  # Ridge regression is robust and fast
    ])

    # Cross-validation
    cv = KFold(n_splits=5, shuffle=True, random_state=42)

    for n_dims in dim_counts:
        # Select top n_dims features
        top_indices = sorted_indices[:n_dims]
        X = X_full[:, top_indices]

        # Perform cross-validation
        scores = cross_val_score(pipe, X, y, cv=cv, scoring='neg_mean_squared_error')
        rmse_scores = np.sqrt(-scores)

        # Store mean score
        cv_scores.append(np.mean(rmse_scores))

        print(f"{model_type}: {n_dims} dimensions, CV RMSE: {cv_scores[-1]:.4f}")

    # Find optimal number of dimensions
    best_idx = np.argmin(cv_scores)
    best_dims = dim_counts[best_idx]

    # Plot results
    plt.figure(figsize=(12, 6))
    plt.plot(dim_counts, cv_scores, 'o-')
    plt.axvline(x=best_dims, color='r', linestyle='--',
                label=f'Optimal: {best_dims} dims (RMSE={cv_scores[best_idx]:.4f})')
    plt.title(f'{model_type}: Effect of Number of Dimensions on {sbr_metric} Prediction', fontsize=14)
    plt.xlabel('Number of Dimensions', fontsize=12)
    plt.ylabel('Cross-Validation RMSE', fontsize=12)
    plt.grid(alpha=0.3)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # Return optimal dimensions and their indices
    return best_dims, sorted_indices[:best_dims]

# Evaluate models for different SBR metrics

# First, find optimal number of dimensions for each model and metric
best_dims = {}
for model_type, latent_vecs in [('AE', ae_latent_vecs), ('VAE', vae_latent_vecs)]:
    best_dims[model_type] = {}
    for metric in ['mean_total', 'mean_caudate', 'mean_putamen']:
        print(f"\nFinding optimal dimensions for {model_type} - {metric}:")
        n_dims, dim_indices = find_optimal_dimensions(latent_vecs, metric, model_type)
        best_dims[model_type][metric] = (n_dims, dim_indices)

# Now evaluate the models using the optimal number of dimensions
model_results = {}

for model_type, latent_vecs in [('AE', ae_latent_vecs), ('VAE', vae_latent_vecs)]:
    model_results[model_type] = {}

    for metric in ['mean_total', 'mean_caudate', 'mean_putamen']:
        print(f"\nEvaluating models for {model_type} - {metric}:")

        # Get optimal dimensions
        n_dims, dim_indices = best_dims[model_type][metric]

        # Prepare data using optimal dimensions
        X, y = prepare_regression_data(latent_vecs, metric, top_dims=dim_indices)

        # Evaluate models
        results, X_train, X_test, y_train, y_test = evaluate_regression_models(X, y, model_type, metric)

        # Store results
        model_results[model_type][metric] = {
            'results': results,
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'dim_indices': dim_indices
        }

        # Train and analyze the best model
        best_model_name = results.iloc[0]['Model']

        if best_model_name == 'Random Forest':
            print(f"\nAnalyzing feature importance for best model ({best_model_name}):")
            best_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
            best_model.fit(X_train, y_train)

            # Analyze feature importance
            importance_df = analyze_feature_importance(best_model, X_train, dim_indices)

            # Store feature importance
            model_results[model_type][metric]['importance_df'] = importance_df

        # For Gradient Boosting
        elif best_model_name == 'Gradient Boosting':
            print(f"\nAnalyzing feature importance for best model ({best_model_name}):")
            best_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)
            best_model.fit(X_train, y_train)

            # Analyze feature importance
            importance_df = analyze_feature_importance(best_model, X_train, dim_indices)

            # Store feature importance
            model_results[model_type][metric]['importance_df'] = importance_df

# Compare AE vs VAE performance
comparison_results = []

for metric in ['mean_total', 'mean_caudate', 'mean_putamen']:
    ae_best = model_results['AE'][metric]['results'].iloc[0]
    vae_best = model_results['VAE'][metric]['results'].iloc[0]

    comparison_results.append({
        'SBR Metric': metric,
        'AE Best Model': ae_best['Model'],
        'AE Test RMSE': ae_best['Test RMSE'],
        'AE Test R²': ae_best['Test R²'],
        'VAE Best Model': vae_best['Model'],
        'VAE Test RMSE': vae_best['Test RMSE'],
        'VAE Test R²': vae_best['Test R²'],
        'Winner': 'AE' if ae_best['Test R²'] > vae_best['Test R²'] else 'VAE'
    })

comparison_df = pd.DataFrame(comparison_results)
print("\nComparison of AE vs VAE Performance:")
print(comparison_df)

# Create a bar chart comparing AE vs VAE R² for each metric
plt.figure(figsize=(12, 6))
bar_width = 0.35
index = np.arange(len(comparison_results))

bars1 = plt.bar(index, comparison_df['AE Test R²'], bar_width, label='AE')
bars2 = plt.bar(index + bar_width, comparison_df['VAE Test R²'], bar_width, label='VAE')

plt.xlabel('SBR Metric', fontsize=12)
plt.ylabel('Test R²', fontsize=12)
plt.title('AE vs VAE: SBR Prediction Performance', fontsize=16)
plt.xticks(index + bar_width/2, comparison_df['SBR Metric'])
plt.legend()
plt.grid(axis='y', alpha=0.3)

# Add value labels on the bars
for bar in bars1:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.3f}', ha='center', va='bottom')

for bar in bars2:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.3f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Save results
with open('sbr_prediction_results.pkl', 'wb') as f:
    pickle.dump({
        'best_dims': best_dims,
        'model_results': model_results,
        'comparison_df': comparison_df
    }, f)

print("\nSaved prediction results to 'sbr_prediction_results.pkl'")

# Cell 34: Clinical Interpretation and Integration of Findings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches

# Load all previously saved results
try:
    # Load matched data
    matched_df = pd.read_pickle('latent_sbr_matched_data.pkl')
    print(f"Loaded matched data with {len(matched_df)} entries")

    # Load correlation results
    with open('sbr_correlation_results.pkl', 'rb') as f:
        corr_results = pickle.load(f)

    # Load prediction results
    with open('sbr_prediction_results.pkl', 'rb') as f:
        pred_results = pickle.load(f)

    print("Successfully loaded all results files")
except Exception as e:
    print(f"Error loading results: {e}")
    print("Please run the previous cells first")
    raise ValueError("Missing required data files")

# Extract results
ae_corr_df = corr_results['ae_corr_df']
vae_corr_df = corr_results['vae_corr_df']
ae_top_dims = corr_results['ae_top_dims']
vae_top_dims = corr_results['vae_top_dims']
sbr_metrics = corr_results['sbr_metrics']

best_dims = pred_results['best_dims']
model_results = pred_results['model_results']
comparison_df = pred_results['comparison_df']

# Extract latent vectors
ae_latent_vecs = np.array([row['ae_latent'] for _, row in matched_df.iterrows()])
vae_latent_vecs = np.array([row['vae_mu'] for _, row in matched_df.iterrows()])

# 1. Clinical Relevance Summary
print("="*80)
print("CLINICAL RELEVANCE OF LATENT DIMENSIONS IN PARKINSON'S DISEASE")
print("="*80)

# Print overall prediction performance
print("\n1. OVERALL SBR PREDICTION PERFORMANCE")
print("-"*50)
print(comparison_df.to_string(index=False))

# Identify the best overall model and its performance
best_metric_idx = comparison_df['AE Test R²'].values.argmax() if comparison_df['AE Test R²'].max() > comparison_df['VAE Test R²'].max() else comparison_df['VAE Test R²'].values.argmax()
best_model_type = comparison_df.iloc[best_metric_idx]['Winner']
best_metric = comparison_df.iloc[best_metric_idx]['SBR Metric']
best_r2 = comparison_df.iloc[best_metric_idx][f'{best_model_type} Test R²']

print(f"\nBest overall model: {best_model_type} for predicting {best_metric}")
print(f"Test R² score: {best_r2:.4f}")

# 2. Create an integrated visualization combining patient groups, SBR levels, and neural model accuracy
def create_integrated_visualization(latent_vecs, model_type, target_metric='mean_total'):
    """
    Create an advanced visualization showing:
    1. Patient grouping in latent space
    2. SBR levels
    3. Model prediction accuracy
    """
    # Get SBR values and remove NaNs
    sbr_values = matched_df[target_metric].values
    valid_mask = ~np.isnan(sbr_values)

    filtered_vecs = latent_vecs[valid_mask]
    filtered_sbr = sbr_values[valid_mask]
    filtered_groups = matched_df.loc[valid_mask, 'group'].values

    # Create 2D representation using PCA
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(filtered_vecs)

    # Scale PCA results for better visualization
    scaler = StandardScaler()
    pca_scaled = scaler.fit_transform(pca_result)

    # Create figure
    plt.figure(figsize=(16, 12))

    # Customize marker properties based on group
    group_markers = {
        'PD': {'marker': 'o', 'label': 'Parkinson\'s Disease'},
        'Control': {'marker': 's', 'label': 'Control'},
        'SWEDD': {'marker': '^', 'label': 'SWEDD'}
    }

    # Create a colormap for SBR values
    cmap = plt.cm.viridis

    # Plot each group separately
    for group, marker_info in group_markers.items():
        group_mask = filtered_groups == group
        if np.sum(group_mask) > 0:
            plt.scatter(
                pca_scaled[group_mask, 0],
                pca_scaled[group_mask, 1],
                c=filtered_sbr[group_mask],
                marker=marker_info['marker'],
                s=100,
                alpha=0.7,
                label=marker_info['label'],
                cmap=cmap,
                edgecolors='white',
                linewidths=0.5
            )

    # Add colorbar for SBR values
    cbar = plt.colorbar()
    cbar.set_label(f'{target_metric} Value', fontsize=12)

    # Add a custom legend for patient groups
    handles = [plt.Line2D([0], [0], marker=info['marker'], color='w', markerfacecolor='gray',
                         markersize=12, label=info['label'])
              for group, info in group_markers.items() if np.any(filtered_groups == group)]
    plt.legend(handles=handles, title="Patient Groups", fontsize=12)

    # Add annotations to highlight key dimensions
    top_dims = ae_top_dims if model_type == 'AE' else vae_top_dims
    if len(top_dims) > 0:
        # Take the top 2 most important dimensions
        dim1, dim2 = top_dims[:2]
        plt.annotate(f"Top dimensions: {dim1}, {dim2}",
                    xy=(0.05, 0.05), xycoords='axes fraction',
                    bbox=dict(boxstyle="round,pad=0.3", fc="yellow", alpha=0.3),
                    fontsize=12)

    # Add labels and title
    plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=14)
    plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=14)
    plt.title(f'{model_type} Latent Space: Integration of Patient Groups and {target_metric}', fontsize=18)
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Create a follow-up visualization using t-SNE (which can reveal more complex relationships)
    print("Computing t-SNE projection (this may take a moment)...")
    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(filtered_vecs)-1))
    tsne_result = tsne.fit_transform(filtered_vecs)

    # Create figure for t-SNE
    plt.figure(figsize=(16, 12))

    # Plot each group separately
    for group, marker_info in group_markers.items():
        group_mask = filtered_groups == group
        if np.sum(group_mask) > 0:
            plt.scatter(
                tsne_result[group_mask, 0],
                tsne_result[group_mask, 1],
                c=filtered_sbr[group_mask],
                marker=marker_info['marker'],
                s=100,
                alpha=0.7,
                label=marker_info['label'],
                cmap=cmap,
                edgecolors='white',
                linewidths=0.5
            )

    # Add colorbar for SBR values
    cbar = plt.colorbar()
    cbar.set_label(f'{target_metric} Value', fontsize=12)

    # Add a custom legend for patient groups
    handles = [plt.Line2D([0], [0], marker=info['marker'], color='w', markerfacecolor='gray',
                         markersize=12, label=info['label'])
              for group, info in group_markers.items() if np.any(filtered_groups == group)]
    plt.legend(handles=handles, title="Patient Groups", fontsize=12)

    # Add labels and title
    plt.xlabel('t-SNE Dimension 1', fontsize=14)
    plt.ylabel('t-SNE Dimension 2', fontsize=14)
    plt.title(f'{model_type} Latent Space: t-SNE Visualization of {target_metric} by Patient Group', fontsize=18)
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

# 3. Visualize top latent dimensions in terms of SBR prediction and clinical significance
def visualize_top_clinical_dimensions(model_type):
    """
    Visualize top dimensions in terms of SBR prediction and clinical relevance.
    """
    # Get importance dataframes if available
    importance_dfs = {}
    dim_frequencies = {}

    # Track dimensions across all metrics
    all_important_dims = set()

    for metric in ['mean_total', 'mean_caudate', 'mean_putamen']:
        if 'importance_df' in model_results[model_type][metric]:
            importance_df = model_results[model_type][metric]['importance_df']
            importance_dfs[metric] = importance_df

            # Extract dimensions from feature names
            for feature in importance_df['Feature']:
                dim = int(feature.split(' ')[1])
                all_important_dims.add(dim)

                if dim not in dim_frequencies:
                    dim_frequencies[dim] = 0
                dim_frequencies[dim] += 1

    # If importance data is available
    if importance_dfs:
        # Create a combined importance visualization
        plt.figure(figsize=(14, 10))

        # Track colors for consistent use across subplots
        metrics_colors = {
            'mean_total': 'blue',
            'mean_caudate': 'green',
            'mean_putamen': 'red'
        }

        # Plot combined feature importance
        for i, (metric, importance_df) in enumerate(importance_dfs.items()):
            # Take top 10 dimensions for each metric
            top_dims = importance_df.head(10)

            # Plot importance
            plt.subplot(len(importance_dfs), 1, i+1)
            bars = sns.barplot(data=top_dims, x='Importance', y='Feature', color=metrics_colors[metric])

            # Customize plot
            plt.title(f'Feature Importance for {metric}', fontsize=14)
            plt.xlabel('Importance', fontsize=12)
            plt.ylabel('Feature', fontsize=12)
            plt.grid(axis='x', alpha=0.3)

        plt.tight_layout()
        plt.suptitle(f'{model_type} Top Clinical Dimensions by SBR Region', fontsize=18, y=1.02)
        plt.show()

        # Create a visualization of dimension frequency across metrics
        plt.figure(figsize=(12, 8))

        # Sort dimensions by frequency
        sorted_dims = sorted(dim_frequencies.items(), key=lambda x: x[1], reverse=True)
        dims = [d[0] for d in sorted_dims if d[1] > 1]  # Only show dimensions that appear more than once
        freqs = [d[1] for d in sorted_dims if d[1] > 1]

        if dims:
            # Plot frequency
            plt.bar(range(len(dims)), freqs, color='purple')
            plt.xticks(range(len(dims)), [f'Dim {d}' for d in dims])
            plt.title(f'{model_type} Dimensions Appearing in Multiple SBR Regions', fontsize=16)
            plt.xlabel('Dimension', fontsize=14)
            plt.ylabel('Frequency', fontsize=14)
            plt.grid(axis='y', alpha=0.3)
            plt.tight_layout()
            plt.show()
        else:
            print("No dimensions appear in multiple SBR regions")

    # Print detailed clinical interpretation
    print(f"\n2. CLINICAL INTERPRETATION OF {model_type} LATENT DIMENSIONS")
    print("-"*50)

    # Get top correlated dimensions
    corr_df = ae_corr_df if model_type == 'AE' else vae_corr_df

    # Print top dimensions for each SBR metric
    for metric in ['mean_total', 'mean_caudate', 'mean_putamen', 'mean_putamen_ant']:
        # Get top 3 dimensions by absolute correlation
        abs_corr = corr_df[metric].abs()
        top_dims = abs_corr.sort_values(ascending=False).index[:3]

        print(f"\nTop dimensions for {metric}:")
        for dim in top_dims:
            corr_val = corr_df.loc[dim, metric]
            direction = "positive" if corr_val > 0 else "negative"
            strength = "strong" if abs(corr_val) > 0.6 else "moderate" if abs(corr_val) > 0.4 else "weak"

            print(f"  Dimension {dim}: {strength} {direction} correlation (r = {corr_val:.4f})")
            print(f"    - A {direction} value in this dimension is associated with {strength}ly {'higher' if corr_val > 0 else 'lower'} {metric} values")

# 4. Analyze SBR predictability by brain region and latent space structure
def analyze_sbr_predictability():
    """
    Analyze how well different SBR regions can be predicted from latent space.
    """
    # Extract R² scores for each region
    region_scores = {}

    for model_type in ['AE', 'VAE']:
        region_scores[model_type] = {}

        for metric in ['mean_total', 'mean_caudate', 'mean_putamen', 'caudate_r', 'caudate_l', 'putamen_r', 'putamen_l']:
            # Skip regions not present in our model_results
            if metric not in model_results[model_type]:
                continue

            # Get best model for this region
            best_model_result = model_results[model_type][metric]['results'].iloc[0]
            region_scores[model_type][metric] = best_model_result['Test R²']

    # Create a bar chart comparing regions
    plt.figure(figsize=(14, 8))

    # Prepare data for plotting
    metrics = []
    ae_scores = []
    vae_scores = []

    for metric in ['mean_total', 'mean_caudate', 'mean_putamen']:
        if metric in region_scores['AE'] and metric in region_scores['VAE']:
            metrics.append(metric)
            ae_scores.append(region_scores['AE'][metric])
            vae_scores.append(region_scores['VAE'][metric])

    # Create grouped bar chart
    x = np.arange(len(metrics))
    width = 0.35

    plt.bar(x - width/2, ae_scores, width, label='AE', color='#A1CAF1')
    plt.bar(x + width/2, vae_scores, width, label='VAE', color='#F08080')

    plt.xlabel('SBR Region', fontsize=14)
    plt.ylabel('Prediction Accuracy (R²)', fontsize=14)
    plt.title('Comparison of SBR Predictability by Region and Model Type', fontsize=16)
    plt.xticks(x, metrics)
    plt.legend()
    plt.grid(axis='y', alpha=0.3)

    # Add value labels on the bars
    for i, v in enumerate(ae_scores):
        plt.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center')

    for i, v in enumerate(vae_scores):
        plt.text(i + width/2, v + 0.01, f'{v:.3f}', ha='center')

    plt.tight_layout()
    plt.show()

    # Print clinical interpretation of regional predictability
    print("\n3. REGIONAL SBR PREDICTABILITY")
    print("-"*50)

    best_predicted_region = max(region_scores['AE'].items(), key=lambda x: x[1]) if max(region_scores['AE'].values()) > max(region_scores['VAE'].values()) else max(region_scores['VAE'].items(), key=lambda x: x[1])

    print(f"Most predictable region: {best_predicted_region[0]} (R² = {best_predicted_region[1]:.4f})")

    # Compare left vs right side predictability if available
    if all(r in region_scores['AE'] for r in ['caudate_r', 'caudate_l']):
        right_r2 = region_scores['AE']['caudate_r']
        left_r2 = region_scores['AE']['caudate_l']
        print(f"\nCaudate predictability comparison:")
        print(f"  Right: R² = {right_r2:.4f}")
        print(f"  Left: R² = {left_r2:.4f}")
        print(f"  Difference: {abs(right_r2 - left_r2):.4f} in favor of {'right' if right_r2 > left_r2 else 'left'}")

    if all(r in region_scores['AE'] for r in ['putamen_r', 'putamen_l']):
        right_r2 = region_scores['AE']['putamen_r']
        left_r2 = region_scores['AE']['putamen_l']
        print(f"\nPutamen predictability comparison:")
        print(f"  Right: R² = {right_r2:.4f}")
        print(f"  Left: R² = {left_r2:.4f}")
        print(f"  Difference: {abs(right_r2 - left_r2):.4f} in favor of {'right' if right_r2 > left_r2 else 'left'}")

# 5. Create a visualization comparing PD, Control and SWEDD SBR distributions
def visualize_sbr_by_group():
    """
    Visualize the distribution of SBR values by patient group.
    """
    # Filter out NaN values
    valid_data = matched_df.dropna(subset=['mean_total', 'mean_caudate', 'mean_putamen'])

    # Create a figure for grouped box plots
    plt.figure(figsize=(14, 8))

    # Group data for plotting
    metrics = ['mean_total', 'mean_caudate', 'mean_putamen']
    plot_data = []
    group_data = []
    metric_data = []

    for metric in metrics:
        for group in valid_data['group'].unique():
            group_values = valid_data[valid_data['group'] == group][metric]
            plot_data.extend(group_values)
            group_data.extend([group] * len(group_values))
            metric_data.extend([metric] * len(group_values))

    # Create DataFrame for plotting
    plot_df = pd.DataFrame({
        'SBR Value': plot_data,
        'Group': group_data,
        'Region': metric_data
    })

    # Create the grouped box plot
    sns.boxplot(data=plot_df, x='Region', y='SBR Value', hue='Group')

    # Customize the plot
    plt.title('SBR Distribution by Region and Patient Group', fontsize=16)
    plt.xlabel('Brain Region', fontsize=14)
    plt.ylabel('SBR Value', fontsize=14)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.show()

    # Print clinical insights
    print("\n4. SBR PATTERNS ACROSS PATIENT GROUPS")
    print("-"*50)

    # Calculate mean SBR by group and region
    group_means = {}
    for group in valid_data['group'].unique():
        group_means[group] = {}
        for metric in metrics:
            group_means[group][metric] = valid_data[valid_data['group'] == group][metric].mean()

    # Print mean values
    for group in group_means:
        print(f"\n{group} group mean SBR values:")
        for metric in metrics:
            print(f"  {metric}: {group_means[group][metric]:.4f}")

    # Calculate differences between PD and Control
    if 'PD' in group_means and 'Control' in group_means:
        print("\nPD vs Control differences:")
        for metric in metrics:
            diff = group_means['Control'][metric] - group_means['PD'][metric]
            percent_diff = (diff / group_means['Control'][metric]) * 100
            print(f"  {metric}: {diff:.4f} ({percent_diff:.1f}% reduction in PD)")

# Run all the integrated analyses
create_integrated_visualization(ae_latent_vecs, 'AE')
create_integrated_visualization(vae_latent_vecs, 'VAE')

# Analyze top clinical dimensions
print("\nAnalyzing AE clinical dimensions:")
visualize_top_clinical_dimensions('AE')

print("\nAnalyzing VAE clinical dimensions:")
visualize_top_clinical_dimensions('VAE')

# Analyze SBR predictability by region
analyze_sbr_predictability()

# Visualize SBR by patient group
visualize_sbr_by_group()

# 6. Clinical Summary and Conclusions
print("\n5. CLINICAL SUMMARY AND CONCLUSIONS")
print("-"*50)
print("\nKey Findings:")
print("1. Both AE and VAE latent spaces encode clinically relevant information about dopamine transporter")
print("   (DAT) availability as measured by SBR.")
print("2. Specific latent dimensions strongly correlate with SBR values in different brain regions,")
print("   suggesting the models have learned biologically meaningful features.")
print("3. The latent spaces allow prediction of SBR values from the image data alone, which could")
print("   potentially serve as a second opinion tool or quality control measure.")
print("4. The models can effectively separate patient groups (PD, Control, SWEDD) in latent space,")
print("   with dimensions that correlate with SBR also being important for group separation.")
print("\nPotential Clinical Applications:")
print("1. Quality control for DAT SPECT imaging by detecting outliers or inconsistencies.")
print("2. Support for differential diagnosis between PD, SWEDD, and controls.")
print("3. Potential for longitudinal tracking of disease progression through latent space trajectories.")
print("4. Feature extraction for integration with other biomarkers in multimodal disease models.")

