# -*- coding: utf-8 -*-
"""Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vL8M7iPwPUJBgfi7ODZRbbo_nE86xJkG
"""

# Commented out IPython magic to ensure Python compatibility.
# Cell 0: Installations
#%pip install scikit-learn scikit-image
#%pip install SimpleITK
# %pip install nibabel nilearn scipy scikit-image

# Cell 1: Import necessary libraries
import os
import pandas as pd

# Cell 2: Define the base directory and categories
# Assuming the notebook and Images folder are in the same directory
base_dir = 'Images'
categories = ['PPMI_Images_PD', 'PPMI_Images_SWEDD', 'PPMI_Images_Cont']

# Cell 3: Collect DICOM file paths for each category
data = []

for category in categories:
    category_path = os.path.join(base_dir, category)
    for patient_id in os.listdir(category_path):
        patient_path = os.path.join(category_path, patient_id)
        reconstructed_path = os.path.join(patient_path, 'Reconstructed_DaTSCAN')
        if os.path.exists(reconstructed_path):
            for exam_date in os.listdir(reconstructed_path):
                exam_date_path = os.path.join(reconstructed_path, exam_date)
                for exam_id in os.listdir(exam_date_path):
                    exam_id_path = os.path.join(exam_date_path, exam_id)
                    for root, dirs, files in os.walk(exam_id_path):
                        for file in files:
                            if file.endswith('.dcm'):
                                file_path = os.path.join(root, file)
                                data.append({
                                    'category': category,
                                    'patient_id': patient_id,
                                    'file_path': file_path
                                })

# Cell 4: Create a DataFrame to organize the data
df = pd.DataFrame(data)
df['label'] = df['category'].map({
    'PPMI_Images_PD': 'PD',
    'PPMI_Images_SWEDD': 'SWEDD',
    'PPMI_Images_Cont': 'Control'
})
df = df[['patient_id', 'file_path', 'label']]
df.head()

# Cell 5: Summary statistics
print('Number of images per category:')
print(df['label'].value_counts())

# Cell 6: Save DataFrame to CSV (optional)
df.to_csv('dicom_file_paths.csv', index=False)

# Cell 7: Import additional libraries for image processing
import numpy as np
import pydicom
import matplotlib.pyplot as plt
from tqdm import tqdm  # For progress bars

# Cell 8: Function to load and preprocess DICOM images
def load_dicom_image(file_path, target_shape=None):
    """
    Load a DICOM file and return the image data as a NumPy array.
    Optionally resizes the image to the target_shape.
    """
    ds = pydicom.dcmread(file_path)
    img = ds.pixel_array.astype(np.float32)

    # Apply rescale slope and intercept if present
    if 'RescaleSlope' in ds:
        img *= float(ds.RescaleSlope)
    if 'RescaleIntercept' in ds:
        img += float(ds.RescaleIntercept)

    # Normalize the image intensities
    img = (img - np.min(img)) / (np.max(img) - np.min(img))

    # Resize image if target_shape is specified
    if target_shape and img.shape != target_shape:
        from skimage.transform import resize
        img = resize(img, target_shape, mode='reflect', anti_aliasing=True)

    return img

# Cell 9: Initialize dictionaries to store sums and counts for each group
mean_sums = {'PD': None, 'SWEDD': None, 'Control': None}
counts = {'PD': 0, 'SWEDD': 0, 'Control': 0}
shapes = {'PD': None, 'SWEDD': None, 'Control': None}

# Cell 10: Compute mean images for each group
# We'll iterate over the DataFrame 'df' created earlier

# Map labels to group names
group_labels = {'PD': 'PD', 'SWEDD': 'SWEDD', 'Control': 'Control'}

# Iterate over each group
for label in group_labels.values():
    group_df = df[df['label'] == label]
    print(f"Processing group: {label}")

    # Initialize progress bar
    for idx, row in tqdm(group_df.iterrows(), total=group_df.shape[0]):
        file_path = row['file_path']
        try:
            # Load the image
            if counts[label] == 0:
                # For the first image, get the shape
                img = load_dicom_image(file_path)
                shapes[label] = img.shape
                mean_sums[label] = np.zeros(shapes[label], dtype=np.float32)
            else:
                # For subsequent images, resize if necessary
                img = load_dicom_image(file_path, target_shape=shapes[label])

            # Accumulate the sum
            mean_sums[label] += img
            counts[label] += 1
        except Exception as e:
            print(f"Error processing {file_path}: {e}")
            continue

    # Compute the mean
    mean_sums[label] /= counts[label]

# Cell 11 (Updated): Visualize the mean images for each group with corrected orientation
import numpy as np
import matplotlib.pyplot as plt

def plot_mean_views(mean_img, title_prefix):
    """
    Plots the axial, coronal, and sagittal views of the mean image with corrected orientation.
    Each image is rotated counterclockwise by 90 degrees.
    """
    # Swap axes if necessary to match anatomical planes
    # This rearranges the data from (Z, Y, X) to (X, Y, Z)
    mean_img = np.swapaxes(mean_img, 0, 2)

    # Compute the middle slices
    axial_slice = mean_img[:, :, mean_img.shape[2] // 2]
    coronal_slice = mean_img[:, mean_img.shape[1] // 2, :]
    sagittal_slice = mean_img[mean_img.shape[0] // 2, :, :]

    # Adjust the orientation of slices
    # First, flip slices to correct the orientation
    axial_slice = np.flipud(axial_slice)
    coronal_slice = np.flipud(coronal_slice)
    sagittal_slice = np.flipud(sagittal_slice)

    # Then, rotate each slice counterclockwise by 90 degrees
    axial_slice = np.rot90(axial_slice, k=1)
    coronal_slice = np.rot90(coronal_slice, k=1)
    sagittal_slice = np.rot90(sagittal_slice, k=1)

    # Plotting
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    plt.suptitle(f"{title_prefix} Mean Views")

    axes[0].imshow(axial_slice, cmap='gray', origin='upper')
    axes[0].set_title('Axial View')
    axes[0].axis('off')

    axes[1].imshow(coronal_slice, cmap='gray', origin='upper')
    axes[1].set_title('Coronal View')
    axes[1].axis('off')

    axes[2].imshow(sagittal_slice, cmap='gray', origin='upper')
    axes[2].set_title('Sagittal View')
    axes[2].axis('off')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

# Cell 12: Plot the mean views for each group
for label in group_labels.values():
    mean_img = mean_sums[label]
    plot_mean_views(mean_img, title_prefix=label)

# Cell 13: Select and visualize a random patient from each group

import random

# Function to select a random patient from each group
def select_random_patients(df, groups):
    random_patients = {}
    for group in groups:
        group_df = df[df['label'] == group]
        unique_patients = group_df['patient_id'].unique()
        if len(unique_patients) == 0:
            print(f"No patients found in group: {group}")
            continue
        selected_patient = random.choice(unique_patients)
        random_patients[group] = selected_patient
    return random_patients

# Define the groups
groups = ['PD', 'SWEDD', 'Control']

# Select random patients
random_patients = select_random_patients(df, groups)
print("Selected Random Patients:")
for group, patient in random_patients.items():
    print(f"{group}: Patient ID {patient}")

# Function to visualize a random image for a given patient
def visualize_random_patient(df, patient_id, label):
    """
    Select a random DICOM file for the given patient and plot its views.
    """
    patient_df = df[(df['patient_id'] == patient_id) & (df['label'] == label)]
    if patient_df.empty:
        print(f"No images found for Patient ID {patient_id} in group {label}.")
        return

    # Select a random image
    random_file = random.choice(patient_df['file_path'].tolist())
    print(f"Visualizing Patient ID {patient_id} - File: {random_file}")

    # Load the image
    img = load_dicom_image(random_file)

    # Plot the views
    plot_mean_views(img, title_prefix=f"{label} - Patient {patient_id}")

# Iterate over each group and visualize a random patient
for group, patient_id in random_patients.items():
    visualize_random_patient(df, patient_id, group)

"""# EDA"""

# Cell 14: Import additional libraries for advanced analysis
import torch
import torch.nn.functional as F
from sklearn.preprocessing import StandardScaler
from scipy import stats
import seaborn as sns
from nilearn import plotting
import nibabel as nib
from concurrent.futures import ThreadPoolExecutor
import gc
import psutil
import time
import gc

# Cell 15: Configure GPU settings and memory monitoring
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

def get_memory_usage():
    """
    Get current memory usage of the system and GPU if available
    """
    # System memory
    process = psutil.Process()
    system_memory = process.memory_info().rss / 1024 / 1024  # MB

    # GPU memory
    gpu_memory = None
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB

    return system_memory, gpu_memory

if torch.cuda.is_available():
    # Print GPU info
    print(f"GPU Name: {torch.cuda.get_device_name()}")
    print(f"GPU Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    # Set memory management options
    torch.cuda.empty_cache()
    torch.backends.cudnn.benchmark = True

# Cell 16: Enhanced image statistics computation with memory tracking
def compute_image_statistics(img):
    """
    Compute comprehensive statistics for a 3D image
    """
    stats_dict = {
        'mean': float(np.mean(img)),  # Convert to native Python types
        'std': float(np.std(img)),
        'min': float(np.min(img)),
        'max': float(np.max(img)),
        'median': float(np.median(img)),
        'skewness': float(stats.skew(img.flatten())),
        'kurtosis': float(stats.kurtosis(img.flatten())),
        'num_zeros': int(np.sum(img == 0)),
        'num_non_zeros': int(np.sum(img != 0)),
        'volume': int(img.size),
        'dimensions': img.shape
    }

    # Compute histogram data
    hist, bins = np.histogram(img.flatten(), bins=50)
    stats_dict['histogram'] = {
        'counts': hist.tolist(),  # Convert to list for better memory management
        'bins': bins.tolist()
    }

    return stats_dict

# Cell 17: Batch process images with improved memory management
def process_group_statistics(group_df, batch_size=5):
    """
    Process images in batches with memory monitoring
    """
    statistics = []

    # Create progress bar for the entire dataset
    with tqdm(total=len(group_df), desc="Processing images") as pbar:
        for start_idx in range(0, len(group_df), batch_size):
            end_idx = min(start_idx + batch_size, len(group_df))
            batch_df = group_df.iloc[start_idx:end_idx]

            for _, row in batch_df.iterrows():
                try:
                    img = load_dicom_image(row['file_path'])
                    stats = compute_image_statistics(img)
                    stats['patient_id'] = row['patient_id']
                    statistics.append(stats)
                    del img
                except Exception as e:
                    tqdm.write(f"Error processing {row['file_path']}: {e}")

                pbar.update(1)

            # Clean up memory after batch
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    return statistics

# Cell 18: Process statistics for each group with progress tracking
group_statistics = {}
for label in group_labels.values():
    print(f"\nProcessing statistics for {label} group...")
    start_time = time.time()

    group_df = df[df['label'] == label]
    group_statistics[label] = process_group_statistics(group_df)

    duration = time.time() - start_time
    print(f"Completed {label} group in {duration:.2f} seconds")
    print(f"Processed {len(group_statistics[label])} images")

# Cell 19: Visualize statistical distributions with efficient memory usage
def plot_group_statistics(group_statistics):
    """
    Create comparison plots for different statistical measures across groups
    """
    metrics = ['mean', 'std', 'skewness', 'kurtosis']
    fig, axes = plt.subplots(2, 2, figsize=(20, 15))

    for idx, (metric, ax) in enumerate(zip(metrics, axes.flatten())):
        plot_data = []
        group_names = []

        for group in group_labels.values():
            values = [s[metric] for s in group_statistics[group]]
            plot_data.extend(values)
            group_names.extend([group] * len(values))

        # Create DataFrame for seaborn
        import pandas as pd
        df_plot = pd.DataFrame({
            'Group': group_names,
            'Value': plot_data
        })

        # Create boxplot using the correct syntax
        sns.boxplot(data=df_plot, x='Group', y='Value', ax=ax)
        ax.set_title(f'{metric.capitalize()} Distribution by Group')
        ax.tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.show()

    # Clean up
    plt.close('all')
    gc.collect()

plot_group_statistics(group_statistics)

"""## Mean Distribution by Group

The average intensity values of voxels in the brain scans for each group (PD, SWEDD, Control).

- **Higher means** indicate brighter regions overall in the scan.
  - In DAT scans, this is particularly important because dopamine transporters show up as bright areas.
  - **Lower mean values** in PD patients often indicate loss of dopamine transporters.
  - SWEDD patients (Scans Without Evidence of Dopaminergic Deficit) should show values more similar to controls.
- The box shows where **50% of your data** falls, with the middle line being the **median**.
- Whiskers show the range of "normal" values, and dots are **outliers**.

## Standard Deviation (Std) Distribution by Group

How much variation or dispersion exists in the voxel intensities.

- **Higher std** means more contrast between different regions in the brain.
- **Lower std** suggests more uniform intensity across the scan.
- In PD patients:
  - Lower std may reflect loss of the normally bright dopamine transporter regions.
- **Controls** should show higher std due to clear distinction between regions with and without dopamine transporters.
- **SWEDD patients** should be similar to controls in this measure.

## Skewness Distribution by Group

The asymmetry of the intensity distribution.

- **Positive skewness** (value > 0) means there's a long tail of high values.
- **Negative skewness** (value < 0) means there's a long tail of low values.
- In DAT scans:
  - **Controls** often show positive skewness due to the presence of bright dopamine transporter regions.
  - **PD patients** might show less positive skewness due to loss of these bright regions.
  - **SWEDD** should be similar to controls.
- This measure can help identify patterns in how the disease affects certain brain regions.

## Kurtosis Distribution by Group

The "tailedness" of the intensity distribution.

- **Higher kurtosis** means more extreme values (outliers).
- **Lower kurtosis** means the data is more uniformly distributed.
- In DAT scans:
  - **Controls** might show higher kurtosis due to the distinct contrast between regions.
  - **PD patients** might show lower kurtosis due to more uniform (and reduced) signal.
  - **SWEDD patients** should again be more similar to controls.
- This can help identify how distinct the dopamine transporter regions are from background tissue.
"""

# Cell 20: Analyze spatial characteristics with memory optimization
def compute_spatial_features(img):
    """
    Analyze spatial characteristics of 3D images with memory optimization
    """
    # Compute gradients one at a time to save memory
    gradients = []
    for axis in range(3):
        grad = np.gradient(img, axis=axis)
        gradients.append(grad)

    gradient_magnitude = np.sqrt(sum(grad**2 for grad in gradients))
    del gradients  # Free memory

    # Compute edge information using Sobel
    from scipy import ndimage
    edges = []
    for axis in range(3):
        edge = ndimage.sobel(img, axis=axis)
        edges.append(edge**2)

    edge_magnitude = np.sqrt(sum(edges))
    del edges  # Free memory

    # Compute statistics
    spatial_stats = {
        'gradient_stats': compute_image_statistics(gradient_magnitude),
        'edge_stats': compute_image_statistics(edge_magnitude)
    }

    # Clean up
    del gradient_magnitude, edge_magnitude
    gc.collect()

    return spatial_stats

# Cell 21: Analyze ROI characteristics with memory efficiency
def analyze_roi_characteristics(img, threshold=0.5):
    """
    Analyze characteristics of regions of interest with memory optimization
    """
    # Create binary mask
    binary_mask = img > threshold
    del img  # Free original image memory if not needed

    # Label connected components
    labeled_array, num_features = ndimage.label(binary_mask)
    del binary_mask  # Free binary mask memory

    roi_properties = {
        'num_regions': num_features,
        'volumes': [],
        'centroids': [],
        'mean_intensities': []
    }

    # Process each ROI
    for label in range(1, num_features + 1):
        region_mask = labeled_array == label
        roi_properties['volumes'].append(int(np.sum(region_mask)))
        roi_properties['centroids'].append(tuple(map(float, ndimage.center_of_mass(region_mask))))
        roi_properties['mean_intensities'].append(float(np.mean(img[region_mask])))
        del region_mask  # Free mask memory after each iteration

    del labeled_array  # Free labeled array memory
    gc.collect()

    return roi_properties

# Cell 22: Visualize ROI distribution with batch processing
def plot_roi_distributions(group_statistics):
    plt.figure(figsize=(15, 5))

    for idx, (group, stats) in enumerate(group_statistics.items()):
        roi_volumes = []

        # Process in smaller batches
        batch_size = 10
        for i in range(0, len(stats), batch_size):
            batch_stats = stats[i:i + batch_size]

            for stat in batch_stats:
                img = load_dicom_image(df[df['patient_id'] == stat['patient_id']].iloc[0]['file_path'])
                roi_props = analyze_roi_characteristics(img)
                roi_volumes.extend(roi_props['volumes'])
                del img, roi_props
                gc.collect()

        plt.subplot(1, 3, idx+1)
        sns.histplot(roi_volumes, bins=30)
        plt.title(f'ROI Volume Distribution - {group}')
        plt.xlabel('Volume (voxels)')
        plt.ylabel('Count')

        del roi_volumes
        gc.collect()

    plt.tight_layout()
    plt.show()
    plt.close('all')

# Cell 23: Save processed statistics with compression
import pickle
import gzip

# Save statistics to compressed file for better storage
with gzip.open('group_statistics.pkl.gz', 'wb') as f:
    pickle.dump(group_statistics, f)

# Cell 24: Print summary report
print("\nEDA Summary Report")
print("-----------------")
for group, stats in group_statistics.items():
    print(f"\n{group} Group:")
    print(f"Number of samples: {len(stats)}")

    # Calculate aggregate statistics
    means = np.mean([s['mean'] for s in stats])
    stds = np.mean([s['std'] for s in stats])
    skew = np.mean([s['skewness'] for s in stats])
    kurt = np.mean([s['kurtosis'] for s in stats])

    print(f"Average intensity: {means:.2f} ± {stds:.2f}")
    print(f"Average skewness: {skew:.2f}")
    print(f"Average kurtosis: {kurt:.2f}")

    # Print memory usage
    sys_mem, gpu_mem = get_memory_usage()
    print(f"Current system memory usage: {sys_mem:.2f} MB")
    if gpu_mem is not None:
        print(f"Current GPU memory usage: {gpu_mem:.2f} MB")

"""## Statistical Analysis of DATSCAN Images Across Patient Groups

### Dataset Composition
The analysis encompasses a total of 3,879 DATSCAN images distributed across three groups:
- Parkinson's Disease (PD): 3,364 samples (86.7%)
- SWEDD: 137 samples (3.5%)
- Control: 378 samples (9.7%)

It's worth noting that there is a significant class imbalance in the dataset, with PD cases representing the vast majority of the samples. This imbalance should be considered during model development and validation phases.

### Intensity Analysis

#### Average Intensities (μ ± σ)
- PD Group: 0.18 ± 0.15
- SWEDD Group: 0.10 ± 0.10
- Control Group: 0.15 ± 0.13

The intensity patterns reveal several interesting findings:
1. PD patients show the highest average intensity (0.18), which is somewhat counterintuitive as we would typically expect lower dopamine transporter activity in PD patients. This might suggest:
   - Potential compensation mechanisms in the brain
   - Variations in image acquisition or normalization
   - The need for region-specific analysis rather than global intensity measurements

2. SWEDD cases show the lowest average intensity (0.10), despite being clinically similar to controls. This unexpected finding might:
   - Explain why these cases show no evidence of dopaminergic deficit in clinical assessment
   - Indicate different underlying pathophysiology
   - Suggest the need for more sophisticated analysis methods beyond simple intensity measures

3. Control cases show intermediate values (0.15), which:
   - Provides a useful baseline for comparison
   - Suggests complex patterns that might not be captured by simple intensity metrics alone

### Distribution Characteristics:

#### Skewness Analysis
- PD Group: 0.78
- SWEDD Group: 1.42
- Control Group: 1.29

The skewness values offer valuable insights:
1. All groups show positive skewness, indicating right-tailed distributions (more low-intensity values with a tail toward higher intensities)
2. SWEDD and Control groups show notably higher skewness (1.42 and 1.29 respectively) compared to PD (0.78)
3. This pattern suggests:
   - More uniform intensity distribution in PD cases, possibly due to loss of contrast in dopamine transporter regions
   - Similar intensity patterns between SWEDD and Control groups, despite differences in average intensity
   - Potential biomarker patterns in the intensity distribution shape

#### Kurtosis Analysis
- PD Group: 0.63
- SWEDD Group: 4.73
- Control Group: 4.16

The kurtosis values reveal striking differences:
1. PD cases show markedly lower kurtosis (0.63) compared to both other groups
2. SWEDD and Control groups show similar, higher kurtosis values (4.73 and 4.16 respectively)
3. These patterns indicate:
   - More uniform intensity distribution in PD cases (platykurtic)
   - More extreme values in both SWEDD and Control cases (leptokurtic)
   - Potential loss of distinct dopamine transporter regions in PD cases

## Clinical Implications

These statistical findings have several important implications for clinical practice and research:

1. **Diagnostic Potential**:
   - The distinct kurtosis values between PD and non-PD cases suggest potential diagnostic value
   - The similarity between SWEDD and Control distributions might help explain clinical misdiagnoses

2. **Group Characteristics**:
   - PD cases show more uniform intensity distributions (lower skewness and kurtosis)
   - SWEDD and Control cases show more varied distributions with more extreme values

3. **Future Directions**:
   - Region-specific analysis might reveal more detailed patterns
   - Machine learning models should consider these distribution characteristics
   - The class imbalance should be addressed in model development

# Preprocessing
"""

# Cell 25: Import additional preprocessing libraries
import numpy as np
import torch
import torch.nn.functional as F
from scipy.ndimage import zoom
from skimage import exposure
from nilearn.image import resample_img, load_img, new_img_like
from scipy.ndimage import gaussian_filter
from tqdm import tqdm

# Cell 26: Define preprocessing pipeline class
class DATSCANPreprocessor:
    def __init__(self, target_shape=(128, 128, 128), device='cuda'):
        """
        Initialize preprocessor with target shape and device

        Args:
            target_shape: Desired output shape for all images
            device: 'cuda' or 'cpu'
        """
        self.target_shape = target_shape
        self.device = device
        self.mean = None
        self.std = None

    def normalize_intensity(self, image):
        """
        Normalize image intensities using robust statistics
        """
        p2, p98 = np.percentile(image, (2, 98))
        image_normalized = exposure.rescale_intensity(image, in_range=(p2, p98), out_range=(0, 1))
        return image_normalized

    def resize_volume(self, image):
        """
        Resize 3D volume to target shape
        """
        try:
            # Calculate zoom factors
            factors = [t / s for t, s in zip(self.target_shape, image.shape)]

            # Apply zoom with anti-aliasing
            resized = zoom(image, factors, order=3, mode='reflect', prefilter=True)

            # Verify the output shape
            if resized.shape != self.target_shape:
                print(f"Warning: Resizing failed. Got shape {resized.shape}, expected {self.target_shape}")
                return None

            return resized
        except Exception as e:
            print(f"Error in resize_volume: {e}")
            return None

    def apply_gaussian_smoothing(self, image, sigma=0.5):
        """
        Apply Gaussian smoothing to reduce noise
        """
        return gaussian_filter(image, sigma=sigma)

    def standardize(self, image):
        """
        Standardize image using global statistics
        """
        if self.mean is None or self.std is None:
            raise ValueError("Global statistics not computed. Run compute_global_stats first.")

        return (image - self.mean) / (self.std + 1e-8)

    def compute_global_stats(self, image_paths):
        """
        Compute global mean and std across all images
        """
        print("Computing global statistics...")
        sum_vals = 0
        sum_sq_vals = 0
        count = 0

        for path in tqdm(image_paths):
            try:
                img = load_dicom_image(path)
                img = self.normalize_intensity(img)
                img = self.resize_volume(img)

                sum_vals += np.sum(img)
                sum_sq_vals += np.sum(img**2)
                count += img.size
            except Exception as e:
                print(f"Error processing {path}: {e}")
                continue

        self.mean = sum_vals / count
        self.std = np.sqrt(sum_sq_vals / count - self.mean**2)

        print(f"Global statistics computed - Mean: {self.mean:.4f}, Std: {self.std:.4f}")

    def preprocess_single_image(self, image):
        """
        Apply full preprocessing pipeline to a single image
        """
        # Normalize intensity
        image = self.normalize_intensity(image)

        # Resize to target shape
        image = self.resize_volume(image)

        # Apply Gaussian smoothing
        image = self.apply_gaussian_smoothing(image)

        # Standardize
        if self.mean is not None and self.std is not None:
            image = self.standardize(image)

        return image

    def preprocess_batch(self, image_paths, batch_size=32):
        """
        Preprocess a batch of images with memory efficiency
        """
        processed_images = []

        for i in tqdm(range(0, len(image_paths), batch_size), desc="Preprocessing batches"):
            batch_paths = image_paths[i:i+batch_size]
            batch_processed = []

            for path in batch_paths:
                try:
                    # Load and preprocess image
                    img = load_dicom_image(path)
                    processed = self.preprocess_single_image(img)

                    # Ensure the image has the correct shape
                    if processed.shape != self.target_shape:
                        print(f"Warning: Image {path} has shape {processed.shape}, expected {self.target_shape}")
                        continue

                    batch_processed.append(processed)
                except Exception as e:
                    print(f"Error processing {path}: {e}")
                    continue

            # Convert batch to tensor and move to device
            if batch_processed:
                # Ensure we have a complete batch
                if len(batch_processed) == batch_size:
                    batch_array = np.stack(batch_processed, axis=0)
                    batch_tensor = torch.tensor(batch_array, dtype=torch.float32, device=self.device)
                    processed_images.append(batch_tensor)
                else:
                    # Pad incomplete batch with zeros
                    batch_array = np.zeros((batch_size,) + self.target_shape, dtype=np.float32)
                    batch_array[:len(batch_processed)] = np.stack(batch_processed, axis=0)
                    batch_tensor = torch.tensor(batch_array, dtype=torch.float32, device=self.device)
                    processed_images.append(batch_tensor)

            # Clean up memory
            del batch_processed
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        return processed_images

# Cell 27: Create preprocessing pipeline and process images
def create_preprocessing_pipeline(df, save_path='preprocessed_data.pt'):
    """
    Create and run preprocessing pipeline for all images
    """
    # Initialize preprocessor
    preprocessor = DATSCANPreprocessor(target_shape=(128, 128, 128))

    # Compute global statistics
    image_paths = df['file_path'].tolist()
    preprocessor.compute_global_stats(image_paths)

    # Process all images in batches
    processed_images = preprocessor.preprocess_batch(image_paths)

    # Create labels tensor
    labels = torch.tensor(df['label'].map({'PD': 0, 'SWEDD': 1, 'Control': 2}).values,
                         dtype=torch.long)

    # Save processed data
    torch.save({
        'images': processed_images,
        'labels': labels,
        'mean': preprocessor.mean,
        'std': preprocessor.std
    }, save_path)

    return processed_images, labels

# Cell 28: Run preprocessing pipeline
processed_images, labels = create_preprocessing_pipeline(df)

# Cell 29: Visualize preprocessed images
def plot_preprocessed_samples(processed_images, labels, num_samples=3):
    """
    Visualize random samples from each group after preprocessing
    """
    group_names = ['PD', 'SWEDD', 'Control']

    plt.figure(figsize=(15, 5*num_samples))

    for group_idx, group in enumerate(group_names):
        # Get indices for current group
        group_indices = torch.where(labels == group_idx)[0]

        # Select random samples
        random_indices = np.random.choice(group_indices.cpu().numpy(),
                                        size=min(num_samples, len(group_indices)),
                                        replace=False)

        for sample_idx, idx in enumerate(random_indices):
            img = processed_images[idx // 32][idx % 32].cpu().numpy()

            plt.subplot(num_samples, 3, sample_idx*3 + group_idx + 1)
            plt.imshow(img[img.shape[0]//2, :, :], cmap='gray')
            plt.title(f'{group} - Sample {sample_idx+1}')
            plt.axis('off')

    plt.tight_layout()
    plt.show()

# Visualize samples
plot_preprocessed_samples(processed_images, labels)

# Cell 30: Print preprocessing summary
print("\nPreprocessing Summary")
print("-" * 20)
print(f"Total number of processed batches: {len(processed_images)}")
print(f"Images per batch: {processed_images[0].shape[0]}")
print(f"Final image dimensions: {tuple(processed_images[0].shape[1:])}")
print(f"Memory usage per batch: {processed_images[0].element_size() * processed_images[0].nelement() / 1024 / 1024:.2f} MB")